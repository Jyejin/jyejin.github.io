<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: 모델학습 - 개발계발 블로그</title><meta property="og:type" content="blog"><meta property="og:title" content="개발계발 블로그"><meta property="og:url" content="https://jyejin.github.io/"><meta property="og:site_name" content="개발계발 블로그"><meta property="og:locale" content="en_US"><meta property="article:author" content="Yejin Jeong"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://jyejin.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jyejin.github.io"},"headline":"개발계발 블로그","image":["https://jyejin.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Yejin Jeong"},"description":""}</script><link rel="icon" href="/img/berry.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/vs.css"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">개발계발</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">모델학습</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-12T09:28:10.000Z" title="2020-05-12T09:28:10.000Z">2020-05-12</time><span class="level-item"><a class="link-muted" href="/categories/Project/">Project</a><span> / </span><a class="link-muted" href="/categories/Project/DeepLearningFromForR/">DeepLearningFromForR</a></span><span class="level-item">7 minutes read (About 1107 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/12/project1-4/">역전파를 사용하여 모델 학습하기</a></h1><div class="content"><br/>

<p>오차역전파를 사용한 학습도 손실함수를 최소화하는 가중치를 찾는 것을 목표로합니다. 다만, 역전파는 가중치를 구함에 있어 연쇄법칙에 기반한 국소적 미분을 활용합니다. 순전파와 비교했을 때 훨씬 빠른 시간 안에 효울적으로 계산한다는 장점이 있습니다. 이번에는 역전파법을 사용하여 모델 학습을 진행해 보겠습니다.</p>
<p>먼저, 라이브러리와 공통함수를 읽어옵니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#install.packages("dslabs")</span></span><br><span class="line">    <span class="keyword">library</span>(dslabs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">source</span>(<span class="string">"./functions.R"</span>)</span><br><span class="line">    <span class="keyword">source</span>(<span class="string">"./utils.R"</span>)</span><br><span class="line">    <span class="keyword">source</span>(<span class="string">"./model.R"</span>)</span><br></pre></td></tr></table></figure>

<p>1개의 은닉층을 갖는 네트워크를 생성합니다. 네트워크는 순전파와 동일합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TwoLayerNet &lt;- <span class="keyword">function</span>(input_size, hidden_size, output_size, weight_init_std  =  <span class="number">0.01</span>) &#123;</span><br><span class="line">  W1 &lt;- weight_init_std * matrix(rnorm(n  =  input_size*hidden_size), nrow  =  input_size, ncol  =  hidden_size)</span><br><span class="line">  b1 &lt;- matrix(rep(<span class="number">0</span>,hidden_size), nrow = <span class="number">1</span>, ncol = hidden_size)</span><br><span class="line">  W2 &lt;- weight_init_std * matrix(rnorm(n  =  hidden_size*output_size), nrow  =  hidden_size, ncol  =  output_size)</span><br><span class="line">  b2 &lt;- matrix(rep(<span class="number">0</span>,output_size),nrow = <span class="number">1</span>, ncol = output_size)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> (list(W1 = W1, b1 = b1, W2 = W2, b2 = b2))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>데이터를 불러와 트레이닝셋과 테스트셋으로 분리하는 <code>init()</code>함수를 생성합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">init &lt;- <span class="keyword">function</span>()&#123;</span><br><span class="line">  mnist_data &lt;- get_data()</span><br><span class="line">  <span class="comment">#손글씨 데이터</span></span><br><span class="line">  x_train_normalize &lt;&lt;- mnist_data$x_train </span><br><span class="line">  x_test_normalize &lt;&lt;- mnist_data$x_test</span><br><span class="line">  <span class="comment">#정답 레이블</span></span><br><span class="line">  t_train_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_train,<span class="number">60000</span>, <span class="number">10</span>)</span><br><span class="line">  t_test_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_test,<span class="number">10000</span>, <span class="number">10</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>앞서 역전파에서는 국소적 미분을 사용한다고 했습니다. 순전파와 반대방향으로 국소적 미분을 곱하여 이전 노드들에 값을 전달하는 것인데, 국소적 미분은 순전파 때의 미분을 구한다는 뜻입니다. 다시 말해, 순전파 때의 미분 값을 구해 다음 노드에 전달하는 함수가 필요합니다.<br>다음 코드는 순전파 때와 마찬가지로 입력신호와 가중치를 계산하고 Relu함수를 거쳐 다음 노드로 전달합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">forward &lt;- <span class="keyword">function</span>(x)&#123;</span><br><span class="line">  Affine_1 &lt;- Affine.forward(network$W1, network$b1, x)</span><br><span class="line">  Relu_1 &lt;- Relu.forward(Affine_1$out)</span><br><span class="line">  Affine_2 &lt;- Affine.forward(network$W2, network$b2, Relu_1$out)</span><br><span class="line">  <span class="keyword">return</span>(list(x = Affine_2$out, Affine_1.forward = Affine_1, Affine_2.forward = Affine_2, Relu_1.forward = Relu_1))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>역전파도 마찬가지로 손실함수를 계산합니다. </p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss &lt;- <span class="keyword">function</span>(model.forward, x, t)&#123;</span><br><span class="line">  temp &lt;- model.forward(x)</span><br><span class="line">  y &lt;- temp$x</span><br><span class="line">  last_layer.forward &lt;- SoftmaxWithLoss.forward(y, t)</span><br><span class="line">  <span class="keyword">return</span>(list(loss = last_layer.forward$loss, softmax = last_layer.forward, predict =  temp))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>순전파와 달리 마지막 노드에서부터 거꾸로 계산해 기울기를 구합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">gradient &lt;- <span class="keyword">function</span>(model.forward, x, t) &#123;</span><br><span class="line">  <span class="comment"># 순전파</span></span><br><span class="line">  temp &lt;- loss(model.forward, x, t)</span><br><span class="line">  <span class="comment"># 역전파</span></span><br><span class="line">  dout &lt;- <span class="number">1</span></span><br><span class="line">  last.backward &lt;- SoftmaxWithLoss.backward(temp$softmax, dout)</span><br><span class="line">  Affine_2.backward &lt;- Affine.backward(temp$predict$Affine_2.forward, dout  =  last.backward$dx)</span><br><span class="line">  Relu_1.backward &lt;- Relu.backward(temp$predict$Relu_1.forward, dout  =  Affine_2.backward$dx)</span><br><span class="line">  Affine_1.backward &lt;- Affine.backward(temp$predict$Affine_1.forward, dout  =  Relu_1.backward$dx)</span><br><span class="line">  grads  &lt;- list(W1  =  Affine_1.backward$dW, b1  =  Affine_1.backward$db, W2  =  Affine_2.backward$dW, b2  =  Affine_2.backward$db)</span><br><span class="line">  <span class="keyword">return</span>(grads)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>다음은 학습을 실제로 진행하는 코드입니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">train_model &lt;- <span class="keyword">function</span>(batch_size, iters_num, learning_rate, debug=<span class="literal">FALSE</span>)&#123;</span><br><span class="line">  <span class="comment">#seperate train, test data</span></span><br><span class="line">  init()</span><br><span class="line">  train_size &lt;- dim(x_train_normalize)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  iter_per_epoch &lt;- max(train_size / batch_size)</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:iters_num)&#123;</span><br><span class="line">      batch_mask &lt;- sample(train_size ,batch_size)</span><br><span class="line">      x_batch &lt;- x_train_normalize[batch_mask,]</span><br><span class="line">      t_batch &lt;- t_train_onehotlabel[batch_mask,]</span><br><span class="line"></span><br><span class="line">      grad &lt;- gradient(model.forward=forward, x_batch, t_batch)</span><br><span class="line">      <span class="comment">#update weights and biases using SGD</span></span><br><span class="line">      network &lt;&lt;- sgd.update(network,grad,lr=learning_rate)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span>(debug == <span class="literal">TRUE</span>)&#123;</span><br><span class="line">          <span class="keyword">if</span>(i %% iter_per_epoch == <span class="number">0</span>)&#123;</span><br><span class="line">              train_acc &lt;- model.evaluate(forward, x_train_normalize, t_train_onehotlabel)</span><br><span class="line">              test_acc &lt;- model.evaluate(forward, x_test_normalize, t_test_onehotlabel)</span><br><span class="line">              print(c(train_acc, test_acc))</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  train_accuracy = model.evaluate(forward, x_train_normalize, t_train_onehotlabel)</span><br><span class="line">  test_accuracy = model.evaluate(forward, x_test_normalize, t_test_onehotlabel)</span><br><span class="line">  <span class="keyword">return</span>(c(train_accuracy, test_accuracy))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>train_model()</code>함수 중간에 <code>sg.update()</code>함수는 경사하강법으로 변경된 가중치를 업데이트하는 역할을 합니다.<br>코드는 아래와 같습니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sgd.update &lt;- <span class="keyword">function</span>(network, grads, lr = <span class="number">0.01</span>)&#123;</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> names(network))&#123;network[[i]] &lt;- network[[i]] - (grads[[i]]*lr)&#125;</span><br><span class="line">  <span class="keyword">return</span>(network)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>이제 모든 준비를 마쳤습니다. 네트워크를 생성한 후 모델을 학습시켜봅니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">network &lt;&lt;- TwoLayerNet(input_size = <span class="number">784</span>, hidden_size = <span class="number">50</span>, output_size = <span class="number">10</span>)</span><br><span class="line">train_model(<span class="number">100</span>, <span class="number">10000</span>, <span class="number">0.1</span>, <span class="literal">TRUE</span>)</span><br></pre></td></tr></table></figure>

<p>위 코드를 실행시키고 3분 정도 지나면 아래와 같은 출력화면이 나올 것입니다. 한 행의 첫 번째 숫자는 훈련데이터 셋에 대한 정확도, 두 번째 숫자는 테스트 셋에 대한 정확도를 나타냅니다. 그리고 하나의 행은 1에폭(epoch)을 의미합니다. 에폭을 진행할수록 정확도가 높아지는 것을 확인할 수 있습니다!</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span>] <span class="number">0.9048</span> <span class="number">0.9059</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9228</span> <span class="number">0.9247</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9355833</span> <span class="number">0.9343000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9436167</span> <span class="number">0.9416000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9496167</span> <span class="number">0.9470000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9563167</span> <span class="number">0.9519000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9602167</span> <span class="number">0.9555000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9629167</span> <span class="number">0.9558000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9664833</span> <span class="number">0.9603000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9680333</span> <span class="number">0.9619000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9711167</span> <span class="number">0.9635000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.97315</span> <span class="number">0.96520</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.97445</span> <span class="number">0.96570</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9754167</span> <span class="number">0.9659000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9771167</span> <span class="number">0.9698000</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9779</span> <span class="number">0.9679</span></span><br><span class="line">[<span class="number">1</span>] <span class="number">0.9776833</span> <span class="number">0.9680000</span></span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-04T04:30:25.000Z" title="2020-05-04T04:30:25.000Z">2020-05-04</time><span class="level-item"><a class="link-muted" href="/categories/Project/">Project</a><span> / </span><a class="link-muted" href="/categories/Project/DeepLearningFromForR/">DeepLearningFromForR</a></span><span class="level-item">7 minutes read (About 1073 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/04/project1-3/">순전파를 사용하여 모델 학습하기</a></h1><div class="content"><br/>
순전파법을 사용하여 손글씨 추론 모델을 만들어보겠습니다. 순전파법의 기본 원리는 손실함수 값을 최소화 시키는 것입니다. 손실함수 값을 최소화 시키는 방법으로는 경사하강법(SGD)를 사용합니다. 순전파의 기본 설명은 다음 링크를 참고하세요.

<ul>
<li><a href="https://jyejin.github.io/2020/04/11/book1-3/">신경망 학습하기-1 (손실함수, 교차엔트로피오차)</a></li>
<li><a href="https://jyejin.github.io/2020/04/11/book1-4/">CH5. 신경망 학습하기-2 (경사하강법)</a></li>
</ul>
<p>먼저, 학습할 네트워크를 만듭니다. W1,W2는 각 층별 가중치이며 b1,b2는 편향 값을 의미합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TwoLayerNet &lt;- <span class="keyword">function</span>(input_size, hidden_size, output_size, weight_init_std  =  <span class="number">0.01</span>) &#123;</span><br><span class="line">  W1 &lt;- weight_init_std * matrix(rnorm(n  =  input_size*hidden_size), nrow  =  input_size, ncol  =  hidden_size)</span><br><span class="line">  b1 &lt;- matrix(rep(<span class="number">0</span>,hidden_size), nrow = <span class="number">1</span>, ncol = hidden_size)</span><br><span class="line">  W2 &lt;- weight_init_std * matrix(rnorm(n  =  hidden_size*output_size), nrow  =  hidden_size, ncol  =  output_size)</span><br><span class="line">  b2 &lt;- matrix(rep(<span class="number">0</span>,output_size),nrow = <span class="number">1</span>, ncol = output_size)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> (list(W1 = W1, b1 = b1, W2 = W2, b2 = b2))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>TwoLayerNet</code> 네트워크는 아래와 같이 은닉층을 1개 갖습니다.</p>
<img src="/gallery/project1-3-1.png">

<p>입력층에서 <code>input_size</code> 개수만큼의 노드를 갖고 은닉층에서는 <code>hidden_size</code> 개수만큼의 노드, 출력층에서는 <code>output_size</code>만큼의 노드를 갖습니다. <code>W1</code>과 <code>b1</code>은 입력층에서 은닉층으로 갈 때의 가중치와 편향이며 <code>W2</code>와 <code>b2</code>는 은닉층에서 출력층으로 갈 때 사용하는 가중치와 편향입니다. 그리고 <code>weight_init_std</code>는 가중치 초기값이 큰 값이 되는 것을 방지하는 파라미터입니다.</p>
<p>다음으로, 데이터를 불러오고 트레이닝 셋과 테스트 셋으로 분류합니다. 데이터는 MNIST 라이브러리의 손글씨 이미지입니다. R에서는 dslabs를 임포트합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(dslabs)</span><br><span class="line"><span class="keyword">source</span>(<span class="string">"./functions.R"</span>)</span><br><span class="line"><span class="keyword">source</span>(<span class="string">"./utils.R"</span>)</span><br><span class="line"><span class="keyword">source</span>(<span class="string">"./model.R"</span>)</span><br><span class="line"></span><br><span class="line">init &lt;- <span class="keyword">function</span>()&#123;</span><br><span class="line">  mnist_data &lt;- get_data()</span><br><span class="line">  <span class="comment">#손글씨 데이터</span></span><br><span class="line">  x_train_normalize &lt;&lt;- mnist_data$x_train </span><br><span class="line">  x_test_normalize &lt;&lt;- mnist_data$x_test</span><br><span class="line">  <span class="comment">#정답 레이블</span></span><br><span class="line">  t_train_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_train,<span class="number">60000</span>, <span class="number">10</span>)</span><br><span class="line">  t_test_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_test,<span class="number">10000</span>, <span class="number">10</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>손실함수는 교차엔트로피오차 함수를 사용합니다. 교차엔트로피오차 함수는 아래와 같이 구현합니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model.forward &lt;- <span class="keyword">function</span>(x)&#123;</span><br><span class="line">  z1 &lt;- sigmoid(sweep((x %*% network$W1),<span class="number">2</span>, network$b1,<span class="string">'+'</span>))</span><br><span class="line">  <span class="keyword">return</span>(softmax(sweep((z1 %*% network$W2),<span class="number">2</span>, network$b2,<span class="string">'+'</span>)))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cross_entropy_error &lt;- <span class="keyword">function</span>(y, t)&#123;</span><br><span class="line">    delta &lt;- <span class="number">1e-7</span></span><br><span class="line">    batchsize &lt;- dim(y)[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span>(-sum(t * log(y + delta))/batchsize)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">loss &lt;-<span class="keyword">function</span>(x,t)&#123;</span><br><span class="line">  <span class="keyword">return</span>(cross_entropy_error(model.forward(x),t))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>기본 교차엔트로피 함수식에 <code>delta</code>값을 추가하였는데, 이는 log0이 되면 -Inf가 되는 문제를 방지하기 위해서 입니다.</p>
<p>다음으로 경사하강법은 손실함수 값을 최소화 시키기 위해 사용합니다. </p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">numerical_gradient_W &lt;- <span class="keyword">function</span>(f,x,t,weight)&#123;</span><br><span class="line">    h &lt;- <span class="number">1e-4</span></span><br><span class="line">    vec &lt;- matrix(<span class="number">0</span>, nrow = nrow(network[[weight]]) ,ncol = ncol(network[[weight]]))</span><br><span class="line">    <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:length(network[[weight]]))&#123;</span><br><span class="line">        origin &lt;-  network[[weight]][i]</span><br><span class="line">        network[[weight]][i] &lt;&lt;- (network[[weight]][i] + h)</span><br><span class="line">        fxh1 &lt;- f(x, t)</span><br><span class="line">        network[[weight]][i] &lt;&lt;- (network[[weight]][i] - (<span class="number">2</span>*h))</span><br><span class="line">        fxh2 &lt;- f(x, t)</span><br><span class="line">        vec[i] &lt;- (fxh1 - fxh2) / (<span class="number">2</span>*h)</span><br><span class="line">        network[[weight]][i] &lt;&lt;- origin</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>(vec)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">numerical_gradient &lt;- <span class="keyword">function</span>(f,x,t) &#123;</span><br><span class="line">  grads  &lt;- list(W1 = numerical_gradient_W(f,x,t,<span class="string">"W1"</span>), </span><br><span class="line">                 b1 = numerical_gradient_W(f,x,t,<span class="string">"b1"</span>), </span><br><span class="line">                 W2 = numerical_gradient_W(f,x,t,<span class="string">"W2"</span>), </span><br><span class="line">                 b2 = numerical_gradient_W(f,x,t,<span class="string">"b2"</span>))</span><br><span class="line">  <span class="keyword">return</span>(grads)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>마지막으로 학습시키는 함수입니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">train_model &lt;- <span class="keyword">function</span>(batch_size, iters_num, learning_rate, debug=<span class="literal">FALSE</span>)&#123;</span><br><span class="line">  <span class="comment">#seperate train, test data</span></span><br><span class="line">  init()</span><br><span class="line">  train_size &lt;- dim(x_train_normalize)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">  iter_per_epoch &lt;- max(train_size / batch_size)</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:iters_num)&#123;</span><br><span class="line">    batch_mask &lt;- sample(train_size,batch_size)</span><br><span class="line">    x_batch &lt;- x_train_normalize[batch_mask,]</span><br><span class="line">    t_batch &lt;- t_train_onehotlabel[batch_mask,]</span><br><span class="line"></span><br><span class="line">    grad &lt;- numerical_gradient(loss, x_batch, t_batch)</span><br><span class="line">    network &lt;&lt;- sgd.update(network,grad,lr=learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(debug)&#123;</span><br><span class="line">        <span class="keyword">if</span>(i %% iter_per_epoch == <span class="number">0</span>)&#123;</span><br><span class="line">            train_acc &lt;- model.evaluate(model.forward, x_train_normalize, t_train_onehotlabel)</span><br><span class="line">            test_acc &lt;- model.evaluate(model.forward, x_test_normalize, t_test_onehotlabel)</span><br><span class="line">            print(c(train_acc, test_acc))</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    train_accuracy = model.evaluate(model.forward, x_train_normalize, t_train_onehotlabel)</span><br><span class="line">    test_accuracy = model.evaluate(model.forward, x_test_normalize, t_test_onehotlabel)</span><br><span class="line">    <span class="keyword">return</span>(c(train_accuracy, test_accuracy))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>train_model()</code>함수 중간에 <code>sg.update()</code>함수는 경사하강법으로 변경된 가중치를 업데이트하는 역할을 합니다.<br>코드는 아래와 같습니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sgd.update &lt;- <span class="keyword">function</span>(network, grads, lr = <span class="number">0.01</span>)&#123;</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> names(network))&#123;network[[i]] &lt;- network[[i]] - (grads[[i]]*lr)&#125;</span><br><span class="line">  <span class="keyword">return</span>(network)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>이제 모든 준비를 마쳤습니다. 네트워크를 생성한 후 모델을 학습시켜봅니다.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">network &lt;&lt;- TwoLayerNet(input_size = <span class="number">784</span>, hidden_size = <span class="number">50</span>, output_size = <span class="number">10</span>)</span><br><span class="line">train_model(<span class="number">100</span>, <span class="number">10000</span>, <span class="number">0.1</span>, <span class="literal">TRUE</span>)</span><br></pre></td></tr></table></figure>



</div></article></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Book/"><span class="level-start"><span class="level-item">Book</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Book/%EB%A6%AC%EC%96%BC%EC%9B%94%EB%93%9C-HTTP/"><span class="level-start"><span class="level-item">리얼월드 HTTP</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Book/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">밑바닥부터 시작하는 딥러닝</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Book/%EC%9D%B8%EC%82%AC%EC%9D%B4%EB%93%9C-%EC%9E%90%EB%B0%94%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/"><span class="level-start"><span class="level-item">인사이드 자바스크립트</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Project/"><span class="level-start"><span class="level-item">Project</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Project/Deep-Django/"><span class="level-start"><span class="level-item">Deep Django</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Project/DeepLearningFromForR/"><span class="level-start"><span class="level-item">DeepLearningFromForR</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Project/Roadmap2020/"><span class="level-start"><span class="level-item">Roadmap2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Study/"><span class="level-start"><span class="level-item">Study</span></span><span class="level-end"><span class="level-item tag">19</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Study/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Study/ETC/"><span class="level-start"><span class="level-item">ETC</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Study/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Study/TIL/"><span class="level-start"><span class="level-item">TIL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Study/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/"><span class="level-start"><span class="level-item">운영체제</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2021-07-19T14:26:22.000Z">2021-07-19</time></p><p class="title is-6"><a class="link-muted" href="/2021/07/19/TIL3/">TIL 3. 프로그래머스 타겟넘버</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-07-18T06:06:16.000Z">2021-07-18</time></p><p class="title is-6"><a class="link-muted" href="/2021/07/18/TIL2/">TIL 2. 데코레이터 패턴, 알고리즘 문제</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-07-17T13:34:44.000Z">2021-07-17</time></p><p class="title is-6"><a class="link-muted" href="/2021/07/17/TIL1/">TIL 1. 전략 패턴, 옵저버 패턴</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Study/">Study</a> / <a class="link-muted" href="/categories/Study/TIL/">TIL</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-07-09T02:22:27.000Z">2021-07-09</time></p><p class="title is-6"><a class="link-muted" href="/2021/07/09/study11/">Nginx에 SSL 인증서 설정하기</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Study/">Study</a> / <a class="link-muted" href="/categories/Study/Network/">Network</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-07-01T14:49:20.000Z">2021-07-01</time></p><p class="title is-6"><a class="link-muted" href="/2021/07/01/study10/">CGI 개념 및 설명</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Study/">Study</a> / <a class="link-muted" href="/categories/Study/ETC/">ETC</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2021/07/"><span class="level-start"><span class="level-item">July 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/06/"><span class="level-start"><span class="level-item">June 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">August 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/CGI/"><span class="tag">CGI</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FastCGI/"><span class="tag">FastCGI</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TIL/"><span class="tag">TIL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/async/"><span class="tag">async</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/authentication/"><span class="tag">authentication</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/backend/"><span class="tag">backend</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/book/"><span class="tag">book</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/conf/"><span class="tag">conf</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cookie/"><span class="tag">cookie</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/django/"><span class="tag">django</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/dns/"><span class="tag">dns</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/domain/"><span class="tag">domain</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/http/"><span class="tag">http</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/https/"><span class="tag">https</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ipc/"><span class="tag">ipc</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/js/"><span class="tag">js</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/login/"><span class="tag">login</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/logparser/"><span class="tag">logparser</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/memory/"><span class="tag">memory</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/network/"><span class="tag">network</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nginx/"><span class="tag">nginx</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/poll/"><span class="tag">poll</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/programming/"><span class="tag">programming</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/project/"><span class="tag">project</span><span class="tag is-grey-lightest">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/push/"><span class="tag">push</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytest/"><span class="tag">pytest</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/roadmap/"><span class="tag">roadmap</span><span class="tag is-grey-lightest">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/server/"><span class="tag">server</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/session/"><span class="tag">session</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ssl/"><span class="tag">ssl</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/static/"><span class="tag">static</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/study/"><span class="tag">study</span><span class="tag is-grey-lightest">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sutdy/"><span class="tag">sutdy</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/til/"><span class="tag">til</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/uWSGI/"><span class="tag">uWSGI</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/view/"><span class="tag">view</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%8B%A4%EC%8B%9C%ED%92%80%EC%96%B4%EB%B3%B4%EA%B8%B0/"><span class="tag">다시풀어보기</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4/"><span class="tag">디자인패턴</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="tag">딥러닝</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%AA%A8%EB%8D%B8%EB%A7%81/"><span class="tag">모델링</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%AA%A8%EB%8D%B8%ED%95%99%EC%8A%B5/"><span class="tag">모델학습</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B0%B1%EC%97%94%EB%93%9C/"><span class="tag">백엔드</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%88%9C%EC%A0%84%ED%8C%8C/"><span class="tag">순전파</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%97%AD%EC%A0%84%ED%8C%8C/"><span class="tag">역전파</span><span class="tag is-grey-lightest">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%94%84%EB%A1%A0%ED%8A%B8%EC%97%94%EB%93%9C/"><span class="tag">프론트엔드</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">개발계발</a><p class="size-small"><span>&copy; 2021 Yejin Jeong</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://jyejin.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: false,
                    fold: ''
                }
            }
        };</script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>