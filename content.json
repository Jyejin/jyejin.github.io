{"pages":[{"title":"Tags","text":"","link":"/tags/index.html"},{"title":"About","text":"","link":"/about/index.html"},{"title":"Project","text":"","link":"/project/index.html"}],"posts":[{"title":"백준 2293번 동전1","text":"백준 2293번 동전1 1234567891011n, k = map(int, input().split())c = []dp = [0 for i in range(k + 1)]dp[0] = 1for i in range(n): c.append(int(input()))for i in c: for j in range(1, k + 1): if j - i &gt;= 0: dp[j] += dp[j - i]print(dp[k]) 핵심 아이디어 k길이의 배열을 만들고, 각 원소 별 경우의 수를 계산하여 k가 되는 경우의 수를 구한다. 설명 dp 배열에서 원소를 dp[key] = value 라고 한다면, key : 1, 2, 3, … kvalue : key를 만들 수 있는 경우의 수 예를 들어 [1, 2, 5] coin을 가지고 k = 4라면, 우리는 약간의 계산으로 경우의 수가 3개인 걸 알 수 있는데, 코드로 보면 i = 1, j = 1 일 때, $j - i ≥ 0$이므로 $dp[1] += dp[0]$ 이 된다. 이 때 dp[0]은 1이므로 dp[1]도 1이다.i = 1, j =2,3,4일 때도 모두 j - i ≥ 0이므로 dp[2], dp[3], dp[4] 역시 모두 1이다.i =2, j = 2 일 때, j - i ≥ 0이므로 dp[2] += dp[0] 이 된다. dp[2]는 2이다. 왜냐하면 누적값이기 때문에i = 2, j =3 일 때, j -i ≥ 0이므로, dp[3] += dp[1]에서 dp[1]은 1이므로, dp[3]도 1이다.i = 2, j = 4일 때, j - i ≥0이므로, dp[4] += dp[2]에서 dp[2]는 2이므로 dp[4]도 3이다. 왜냐하면 dp[4]가 앞서 1이었기 때문에 이로써 dp[4] = 3이므로, 경우의 수가 3개가 나온다.","link":"/2021/05/25/algo-1/"},{"title":"백준 10815번 숫자 카드","text":"백준 10815번 숫자 카드 내가 푼 코드 시간 초과! 1234567891011121314151617181920212223242526def exsitCard(card, my_card): checked_card = my_card while(True): if len(checked_card) == 1: return 1 if card == checked_card[0] else 0 elif len(checked_card) &lt; 1: return 0 else: center_num = len(checked_card)//2 if card == checked_card[center_num]: return 1 elif card &lt; checked_card[center_num]: checked_card = checked_card[:center_num] elif card &gt; checked_card[center_num]: checked_card = checked_card[center_num+1:]num1 = int(input())my_card = list(map(int, input().split()))my_card.sort()num2 = int(input())card_list = list(map(int, input().split()))for card in card_list: print(exsitCard(card,my_card)) 정답 123456789101112131415161718192021222324252627import sysdef existCard(card, checked_card): start_idx = 0 end_idx = len(checked_card) - 1 while(start_idx &lt;= end_idx): idx = (start_idx + end_idx) //2 if card == checked_card[idx]: return \"1\" elif card &lt; checked_card[idx]: end_idx = idx -1 else: start_idx = idx + 1 return 0num1 = int(input())my_card = list(map(int, sys.stdin.readline().split()))my_card.sort()num2 = int(input())card_list = list(map(int, sys.stdin.readline().split()))result = []for card in card_list: result.append(existCard(card,my_card))print(\" \".join(result)) 시간 초과 발생한 이유는, idx가 아닌 배열 자체를 잘랐기 때문에! 배열 자체를 반 씩 자르고 저장하고 이래서 시간 초과가 발생했다.이진 탐색을 할 때에는 배열은 그대로 두고 인덱스를 바꿔가면서 찾도록 하자!while은 true말고 조건을 달아주자! 이번의 경우는 start_idx는 계속 늘어나고 end_idx는 계속 줄어드니까 + end_idx가 무조건 같거나 커야하므로 start_idx ≤ end_idx로 설정 idx에 +1, -1을 하는 이유는, idx가 반복되는 일을 방지하기 위해서다.idx가 될 수 있는 수는 start_idx보다 크거나 같은 경우인데idx가 start_idx보다 큰 경우, idx가 start_idx보다 제일 작은 1만큼 더 크다고 했을 때, idx+1을 하게 되면 2차이가 나므로 나누기 2를 하면, 이전 idx와 항상 다르게 된다. idx가 start_idx와 같은 경우, (start,end,idx)라고 할 때 (2, 2, 2)나 (2, 3, 2)를 예로 들어보자.(2, 2, 2)의 경우, idx+1을 만나면 (3,2,2)가 되어 start &gt; end가 되므로 while이 끝나 버린다. idx-1을 만나도 마찬가지이다. 그리고 (2, 3, 2)의 경우, idx+1을 만나면 (3,3,2)가 되어 idx가 바뀐다. idx-1을 만나면 (2, 1, 2)가 되어 while이 끝나 버린다!계속 이어서 end_idx = idx-1도 살펴보면, idx가 될 수 있는 수는 idx와 같거나 작은 수인데,idx가 end_idx보다 작은 경우, idx - 1을 하면 최소 2이상의 차이가 나므로 이전 idx와 항상 다르게 된다.idx가 end_idx와 같은 경우, (2, 2, 2)가 있는데 idx-1을 하면 while이 끝나 버린다.","link":"/2021/05/25/algo4/"},{"title":"백준 1406번 에디터","text":"백준 1406번 에디터 내가 푼 답 ⇒ 시간 초과 12345678910111213141516171819202122import sys#input = sys.stdin.readlinerow = list(input().rstrip())num = int(input())p = len(row)for i in range(num): req = input().rstrip().split(\" \") if len(req) &gt; 1: row.insert(p, req[1]) p += 1 else: req = req[0] if req == \"L\": p = p - 1 if p &gt; 0 else 0 elif req == \"D\": p = p + 1 if p &lt; len(row) else p elif req == \"B\": if p &gt; 0: p = p -1 row.pop(p)print(''.join(row)) 다른방법 고민.. 방법 1: 스택 2개를 만들고, 한 쪽의 top이 포인터가 되어 스택끼리 값을 넣었다 뺐다 해준다.방법 2: collections 의 deque를 사용한다.방법1 ⇒ 이것도 시간 초과 남 ;; 12345678910111213141516171819202122stack1 = list(input().rstrip())stack2 = []num = int(input())for i in range(num): req = input().rstrip().split(\" \") if len(req) &gt; 1: stack1.append(req[1]) else: req = req[0] if req == \"L\": if len(stack1) &gt; 0: stack2.insert(0, stack1.pop()) elif req == \"D\": if len(stack2) &gt; 0: stack1.append(stack2.pop(0)) elif req == \"B\": if len(stack1) &gt; 0: stack1.pop()stack1.extend(stack2)print(\"\".join(stack1)) 이건 블로그 복붙 방식은 같은데 이건 통과 123456789101112131415161718from sys import stdinstk1 = list(stdin.readline().strip())stk2 = []n = int(input())for line in stdin: if line[0] == 'L': if stk1: stk2.append(stk1.pop()) else: continue elif line[0] == 'D': if stk2: stk1.append(stk2.pop()) else: continue elif line[0] == 'B': if stk1: stk1.pop() else: continue elif line[0] == 'P': stk1.append(line[2])print(''.join(stk1 + list(reversed(stk2)))) 이유! insert() 메서드가 시간 초과의 원인이었다. 위 블로그 방식은 그냥 append() 후에 reveresed하는 방식으로 했다.","link":"/2021/05/25/algo3/"},{"title":"백준 17299번 오등큰수","text":"백준 17299번 오등큰수 123456789101112131415161718192021import sysnum = int(input())a = list(map(int, input().split(\" \")))result = [\"-1\" for _ in range(num)]stack = [0]count = dict()for i in a: try: count[i] += 1 except: count[i] = 1for i in range(num): while stack and count[a[stack[-1]]] &lt; count[a[i]]: result[stack[-1]] = str(a[i]) stack.pop() stack.append(i) i+=1print(\" \".join(result)) [17298]오큰수와 같은 유형의 문제이다. 다만, 오등큰수는 각 원소 별 합에 대한 크기를 비교한다. count에 원소를 키로 해서 키 별 원소 개수를 저장한다. stack에는 a의 인덱스 값을 저장할 건데, for문을 돌면서 count[a] 값이 작은 a의 인덱스를 stack에 push하다가 stack[-1]보다 큰 count[a]를 만나면 stack에서 인덱스를 pop한다.","link":"/2021/05/25/algo2/"},{"title":"CH4. 신경망 학습하기-1 (손실함수, 교차엔트로피오차)","text":"이번 챕터에서는 신경망 학습 방법에 대해 알아본다. 우리는 “5”라고 쓴 손글씨 이미지를 입력하면 컴퓨터가 “5”라고 인식하는 모델을 만들고 싶다. 이 모델을 만들기 위해서 신경망을 학습시킬 것이다. (이를 모델링이라고도 한다.) 신경망은 학습을 통해 손글씨 값을 가장 잘 인식하는 가중치와 편향의 최적값을 찾아준다. 우리는 최적값을 가지고 숫자를 얼마나 잘 맞추는지 성능을 테스트 할 것이다. 우리가 사용할 데이터는 MNIST 패키지의 손글씨 이미지이다. 이미지는 다음과 같다. 손글씨로 쓴 숫자 5의 이미지이다. 이미지를 넘파이 배열로 변환하여 학습시킬 것이다. 해당 이미지는 28 * 28 사이즈로, 픽셀별로 쪼개어 배열로 만든다. 회색조 이미지에서 각 픽셀은 색상에 따라 0에서 255까지의 값을 취한다. 위 이미지를 배열로 만들면 아래와 같으며 배열의 shape는 (1,784)이다. 하나의 데이터는 위의 배열과 같다. 이제 신경망 학습법을 살펴보자. (데이터 전처리는 따로 또 포스팅할 예정입니다.) 신경망 학습 절차는 아래와 같다. 우리는 이 과정을 짚어보며 신경망 학습 방법을 이해할 것이다. 훈련데이터와 시험데이터 분리 훈련데이터 중 배치 돌릴 배치 데이터 랜덤 선택 배치 데이터로 손실함수 값 구하기 경사하강법으로 가중치 값 개선하기 2,3,4 반복하며 최적값 찾기 테스트 데이터로 성능 테스트 해보기 훈련데이터와 시험데이터 분리 MNIST 패키지의 손글씨 이미지는 7만장이다. 7만장을 훈련데이터와 시험데이터로 나눠 학습과 성능 테스트를 수행할 것이다. 훈련 데이터를 사용하여 최적의 매개변수를 찾은 다음, 시험데이터로 성능 테스트를 진행한다. 이는 범용능력을 위한 것으로, 다른 데이터가 들어왔을 때도 효과적인 값을 출력하는지 테스트하기 위함이다. 만약, 학습모델이 훈련데이터는 정확히 맞추더라도 시험데이터가 들어왔을 때 엉망이라면, 이 모델은 다른 데이터에는 사용할 수 없을 것이다. 이처럼 특정데이텅에 맞춰서 만들어진 모델을 오버피팅이라고 하며, 이 문제를 방지하기 위해 훈련데이터와 시험데이터를 분리한다. 여기서는 훈련데이터 6만장, 시험데이터를 1만장으로 분리할 것이다. 데이터를 분리하는 코드는 아래와 같다. 123456789101112131415import sys, osimport numpy as nppath = \"./deep-learning-from-scratch-master\"sys.path.append(path)from dataset.mnist import load_mnist(x_train, t_train), (x_test, t_test) = \\ load_mnist(normalize=True, one_hot_label=True)print(\"x_train shape is: \"+ str(x_train.shape)) #훈련데이터print(\"t_train shape is: \"+ str(t_train.shape)) #훈련데이터 레이블print(\"x_test shape is: \"+ str(x_test.shape)) #시험데이터print(\"t_test shape is: \"+ str(t_test.shape)) #시험데이터 레이블 여기서 x_train과 x_test는 훈련데이터, 시험데이터이다. 한장 데이터의 shape는 (1, 784)인데, 6만장이 있으므로 (60000, 784)이다. 시험데이터는 1만장이므로 (10000,784)이다. 그리고 t_train과 t_test는 각각 훈련데이터 레이블과 시험데이터 레이블이다. 레이블은 정답표를 배열로 나타낸 것이다. 만약 특정 손글씨 숫자의 실제값이 “2”라면, 레이블은 [0,0,1,0,0,0,0,0,0,0]가 된다. 맨 앞에서부터 0,1,2 …9까지 총 10개의 정답표이며 실제 값에만 1을 표시한다. 하나의 정답 레이블의 shape는 (1,10)이며 이미지만큼 정답표가 있기 때문에 (60000,10),(10000,10)이다. 훈련데이터 중 배치 돌릴 배치 데이터 랜덤 선택 훈련 데이터 x_train은 6만개이다. 6만개 전체를 학습 한 번에 전부 사용하면 시간이 너무 오래 걸린다. 더 많은 데이터의 경우 그 시간은 더 오래 걸릴 것이다. 이런 경우 데이터 일부를 추려 전체의 근사치로 사용한다. 가령 6만개의 훈련 데이터 중에서 100개를 무작위로 뽑아 그 100개 만을 사용하여 학습하고 다시 또 100개를 추출하여 학습하는 것을 반복한다. 이러한 학습 방법을 미니 배치 학습이라고 한다. 이렇게 무작위로 추출한 데이터를 배치 데이터라고 부르겠다. 훈련 데이터에서 지정한 수의 데이터를 무작위로 골라오는 코드를 작성해 보자. 1234567train_size = x_train.shape[0]batch_size = 100batch_mask = np.random.choice(train_size, batch_size)x_batch = x_train[batch_mask]t_batch = t_train[batch_mask]print(batch_mask) 배치 데이터로 손실함수 값 구하기 학습에 사용할 데이터 추출까지 모두 끝났다. 이제는 이 배치 데이터를 가지고 이미지 데이터의 숫자값을 예측한 후, 손실함수 값을 구할 것이다. 먼저 이미지 데이터 예측부터 살펴보자. 123W = np.random.randn(784,10)def predict(x): return np.dot(x, W) W는 가중치 매개변수로, 신경망의 최종목표인 가중치 최적값 찾기가 바로 이 W 변수이다. 신경망은 학습을 통해 W변수의 최적값을 찾을 것이다. 첫 예측에는 가중치 값이 없으므로 정규분포 값으로 랜덤추출하였다. 입력할 배치 데이터의 shape는 (100, 784)이므로 이미지당 예측값을 추정하기 위해서 가중치는 (784,10)형태여야 한다. 이는 행렬 곱을 위해서는 앞 행렬의 열과 뒤 행렬의 행이 같아야 하는 계산 방식 때문이다. 이렇게 하면 예측값의 shape는 (100,10)이며 이는 원소가 10개인 리스트가 100행이 있음을 의미한다. 다시 말해 predict()함수의 리턴 값의 shape는 (100,10)이 된다. 앞서 구한 배치 데이터(x_batch)를 가지고 predict 리턴 값의 한 줄을 출력해보자. 1predict(x_batch)[0] 위 배열이 신경망이 이미지 데이터를 보고 생성한 추정치이다. 이 추정치가 100개가 있다. 추정치를 설명하면, 이미지 데이터가 0일 가능성이 14, 1일 가능성이 11, 9일 가능성이 10을 나타낸다. 그러면 최종 선택은 요소 중 가장 큰 값으로 숫자를 추정한다. 1np.argmax(predict(x_batch)[0]) 최종적으로 신경망이 추정한 값여기서는 0일 때의 추정치가 값이 제일크기 때문에 이미지 데이터를 0으로 추정했다고 본다. 여기까지가 신경망의 예측이다. 이제 우리는 손실함수로 이 신경망의 성능이 얼마나 나쁜지 확인할 것이다. 손실함수 먼저, 손실함수란 신경망 성능의 ‘나쁨’을 나타내는 지표이다. 성능의 나쁨을 나타내는 손실함수의 값이 가장 작은 곳에 가중치 최적값이 있다. 신경망은 손실함수가 최저가 되게 만드는 가중치 값을 찾는다. 손실함수로는 오차제곱합과 교차 엔트로피 오차가 있는데 가장 유명한 교차 엔트로피 오차만 살펴 보겠다. 교차 엔트로피 오차 교차엔트로피오차 식은 다음과 같다. 여기서 log는 자연로그이며 yk는 신경망이 학습을 통해 이미지를 추정한 값, tk는 앞서 살펴본 정답레이블이다. 예를 들면 다음과 같다. 123t = [0,0,1,0,0,0,0,0,0,0]y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]#참고 : t, y값은 예시를 위해 직접 작성한 값입니다. 변수 t는 정답레이블로, 손글씨 데이터의 실제 숫자가 “2”임을 의미한다. 이는 원-핫 인코딩 방식으로 정답에 해당하는 값만 1로 나타낸 것이다. 그리고 변수 y는 신경망이 학습을 통해 이미지를 추정한 값이다. 0.6이 제일 높으므로 신경망은 손글씨 이미지가 “2”라고 추정하고 있다. 교차 엔트로피 오차 식을 다시 살펴보면, 정답레이블(tk)을 곱하기 때문에 답이 아닌경우(=tk가 0인 경우) 는 값이 0이고 정답인 경우에만 값이 있으므로 실질적으로 정답일 때의 자연로그를 계산하는 식이 된다. 교차 엔트로피 오차 수식은 다음과 같이 구현한다. 1234567import numpy as npdef cross_entropy_error(y, t): delta = 1e-7 return -np.sum(t * np.log(y + delta)) cross_entropy_error(np.array(y), np.array(t)) 2가 정답일 때 신경망의 추정치는 0.6이며 이 때의 교차 엔트로피 오차는 약 0.51이다. 하나 더 살펴보자. 123y = [0.1, 0.05, 0.2, 0.1, 0.05, 0.1, 0.1, 0.1, 0.1, 0.1]cross_entropy_error(np.array(y), np.array(t)) 이번에는 2가 정답일 때 2에 대한 신경망의 추정치는 0.2이다. 이 때의 교차 엔트로피 오차는 1.61이다. 추정치가 정답과 멀어질수록 오차값이 큰 것을 알 수 있다. 여기까지 전체 데이터를 훈련데이터와 시험데이터로 분리하고 훈련데이터에서 배치 데이터 100개을 랜덤 추출했다. 그리고 이 배치 데이터를 예측하여 예측 값에 대한 손실함수를 구하는 것까지 살펴보았다. 다음 챕터에서 이 손실함수 예측값을 갖고 가중치 매개변수 최적값을 구하는 방법을 살펴볼 것이다. 그럼 안뇽~!","link":"/2020/04/11/book1-3/"},{"title":"CH2.딥러닝의 시작, 퍼셉트","text":"퍼셉트론 알고리즘 퍼셉트론은 딥러닝의 기원이 되는 알고리즘으로, 다수의 신호를 입력으로 받아 처리한 후 하나의 신호를 출력한다. 좀 더 구체적으로 설명하면 입력 받은 신호에 가중치를 곱해서 신호의 총합이 정해진 한계(임계값)를 넘어설 때만 1을 출력한다. 이 동작 원리를 수식으로 나타내면 아래와 같다. 퍼셉트론 수식위 식의 x1,x2는 입력신호, w1,w2는 가중치를 나타낸다. 그리고 계산식의 합이 임계값(θ)를 넘는 경우에만 1을 출력한다. 입력신호(x1,x2)는 우리가 결정할 수 없는, 그저 받는 값이지만, 가중치와 임계값은 조절할 수 있다. 계산식에서 가중치(w1,w2)로 입력신호의 중요도를 조절하고, 임계값으로 얼마나 쉽게 1을 출력할 것인지를 설정한다. 가중치는 높을수록 입력신호의 값이 커져 영향력이 커지게 되며 낮을수록 그 입력신호는 영향력이 작아진다. 그리고 임계값이 낮을수록 1은 쉽게 출력될 것이다. 이처럼 가중치와 임계값은 각 신호가 결과에 주는 영향력을 조절한다. 이번에는 임계값을 좌변으로 옮겨 아래와 같이 수식으로 나타낼 수 있다. 가중치와 편향임계값을 좌변으로 넘기고(b) 임계값을 더한 계산식의 합이 0이 넘는 경우에만 1을 출력한다. 항상 계산식이 0보다 크면 1을 출력하므로 이해하기 훨씬 간편하다. 우리는 이 b를 편향이라고 부른다. 논리 회로 구현하기 앞서 작성한 퍼셉트론 식으로 논리 회로를 구현해 보자. 논리 회로는 하나 이상의 논리 값이 들어오면 게이트에 따라 출력 논리 값을 반환한다. 게이트로는 AND게이트, OR게이트, XOR게이트, NAND게이트를 살펴 볼 것이다. AND 게이트아래 표는 AND논리회로의 진리표이다. 입력 값이 둘 다 1인 경우에만 1을 반환한다. 이 진리표를 퍼셉트론으로 표현하려면 가중치와 편향을 어떻게 설정해야 할까? 입력값을 x1, x2에 대한 가중치를 w1, w2라고 했을 때 (w1,w2,b)는 (0.5,0.5,-0.7), (1.0,1.0,-1.0)등이 될 수 있을 것이다.이처럼 가중치와 편향을 적절히 하여 AND 논리회로를 구현해보자. 12345678910import numpy as npdef AND(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0 : return 0 else: return 1 OR, NAND게이트 다음으로 OR, NAND게이트도 마저 구현해 본다. OR게이트는 입력값이 모두 0인 경우를 제외하고 1을 반환하고 NAND게이트는 입력값이 모두 1인 경우에 0을 반환한다. 1234567891011121314151617181920def OR(x1, x2): x = np.array([x1, x2]) w = np.array([0.5, 0.5]) b = -0.2 tmp = np.sum(w*x) + b if tmp &lt;= 0 : return 0 else: return 1OR 함수 결과def NAND(x1, x2): x = np.array([x1, x2]) w = np.array([-0.5, -0.5]) b = 0.7 tmp = np.sum(w*x) + b if tmp &lt;= 0 : return 0 else: return 1 NAND 함수 결과XOR 논리회로는? 아래는 XOR논리회로의 진리표이다. XOR 논리회로 진리표XOR 논리회로는 x1,x2가 다른 경우에만 1을 반환한다. 마찬가지로 코드로 구현하려니 앞서 다른 논리회로와 같은 방식으로는 구현할 수가 없다. 왜 그럴까? 그래프로 살펴보자 먼저 OR진리표를 그래프로 나타낸 것이다. OR그래프는 0과 1을 분리하기 위해서 1차식으로 나타낼 수 있다. AND와 NAND논리회로 역시 1차식으로 나타낼 수 있다. 직접 그려보기 바란다. 다음으로 XOR그래프를 살펴보자 XOR논리회로 그래프XOR 그래프는 0과 1을 분리하기 위해 1차식으로 구현할 수 없다. 1과 0을 분리하기 위해서는 곡선이 들어가게 된다. 정리하면 AND,OR,NAND가 선형 문제인 반면에 XOR은 비선형 문제이므로 1차식으로 문제를 해결할 수 없는 것이다. 비선형 문제 해결하기 : 다층 퍼셉트론그렇다면 퍼셉트론 식만으로 비선형 문제를 어떻게 해결해야 할까? XOR같은 비선형 문제를 해결하는 것이야 말로 퍼셉트론의 진가이다. 1차식 만으로 해결할 수 없는 비선형 문제는 층을 쌓아 해결한다. 이것을 다층 퍼셉트론이라고 부른다. 다층 퍼셉트론을 그림으로 나타내면 다음과 같다. 다층 퍼셉트론하나의 처리과정을 한 층이라고 부른다. 해당 퍼셉트론은 처리 과정이 2개이므로 2층 퍼셉트론이다. 그림을 설명하면 입력신호(x1,x2)에 대한 처리를 하고 처리된 신호(s1,s2)를 다시 처리하여 y를 출력한다. 기존의 1층 처리 방식과 달리 처리된 것을 다시 처리하여 출력한다. 이 방식을 XOR에 적용해보자. 먼저 XOR 방식을 해결하기 위한 처리 과정은 아래와 같다. 입력 신호(x1, x2)는 다른 논리회로와 같다. 다만 입력신호를 NAND로 처리한 s1과 OR로 처리한 s2(1층)를 다시 AND 신호(2층)로 처리한다. 이를 수식으로 나타내면 아래와 같다. 12345def XOR(x1, x2): s1 = NAND(x1, x2) s2 = OR(x1, x2) y = AND(s1, s2) return y XOR 함수 결과이처럼 퍼셉트론은 층을 쌓아 더 다양한 것을 표현할 수 있다.","link":"/2020/04/11/book1-1/"},{"title":"JavaScript 실행 컨텍스트","text":"1. 실행 컨텍스트특정 프로그램(크롬,엑셀…)을 실행하면 프로세스도 같이 실행되듯이 코드를 실행하면 실행 컨텍스트도 같이 실행된다. 코드 진행과 컨텍스트는 불가분의 관계이며, 컨텍스트에는드 실행 순서 등 실행에 필요한 메타 정보를 담고 있다. 컨텍스트 단위는 전역 코드에 대한 컨텍스트, 함수에 대한 컨텍스트, eval() 함수로 실행되는 코드로 나뉜다. 여기서는 전역 코드에 대한 컨텍스트, 함수에 대한 컨텍스트로 살펴 보겠다. 123456789101112131415161718console.log(\"This is global context\");function ExContext1(){ console.log(\"This is ExContext1\");}fucntion ExContext2(){ ExContext1(); console.log(\"This is ExContext2\");}ExContext2();/*resultThis is global contextThis is ExContext1This is ExContext2*/ 컨텍스트는 실행전 스택으로 쌓이고 후입선출로 하나씩 실행된다. 위 코드로 순서를 살펴보면, 가장 먼저 전역 컨텍스트가 만들어지고 ExContext2() 컨텍스트, ExContext1() 컨텍스트가 만들어 지고 나서 실행과 종료를 거친 후 전역 실행 컨텍스트의 실행이 완료되면 모든 실행이 끝난다. 실행 컨텍스트 고려한 코드 실행 과정은 다음과 같다. 1) 활성 객체 생성 2) arguments 객체 생성 3) 스코프 정보 생성 4) 변수 생성 5) this 바인딩 6) 코드실행 1) 활성 객체 생성 실행에 필요한 메타정보를 담고 있는 객체로, 사용자가 정의한 변수 및 객체를 저장하며 새로 만들어진 컨텍스트로 접근 가능하게 되어 있다. 2) arguments 객체 생성 arguments 객체는 함수를 호출할 때 넘긴 인자들이 배열 형태로 저장된 객체를 의미하며, 1)에서 만들어진 활성 객체가 arguments 객체를 참조한다. 구체적으로 살펴보기 위해 아래처럼 add함수에 arguments객체를 찍어보면, 결과 값은 아래와 같다. arguments객체를 살펴보면, 전달된 인자 값, 인자의 개수(length), 함수의 참조값(callee)를 확인할 수 있다. 3) 스코프 정보 생성 컨텍스트의 유효 범위를 나타내는 스코프 정보를 생성한다. 유효 범위 안에서 변수와 함수가 존재한다. 예를 들어 C언어의 경우 if문,for문, 함수 안에서 선언된 변수는 해당 블록 안에서만 유효하므로 밖에서 접근할 수 없다. 그러나 자바스크립트의 경우 for문,if문은 유효 범위가 없고 함수만이 유효 범위를 갖는다. 함수의 유효범위는 [[scope]]프로퍼티에서 정의되는데 각각의 함수는 [[scope]]프로퍼티로 컨텍스트의 스코프 체인을 참조한다. 정리하면 실행 컨텍스트는 실행된 함수의 [[scope]]프로퍼티를 기반으로 새로운 스코프 체인을 만든다. 4) 변수 생성 코드 실행에 사용되는 변수의 생성이 이루어진다. 함수 인자의 경우 각각의 프로퍼티가 만들어지고 그 값이 할당된다. 만약 값이 없다면 undefined가 할당 된다. 5) this 바인딩 this 키워드를 사용하는 값이 할당된다. 여기서 this가 참조하는 객체가 없으면 전역 객체를 참조한다. 6) 코드 실행 코드 실행 ~^_^","link":"/2020/04/12/book2-2/"},{"title":"CH3. 딥러닝의 시작2, 신경망 - 활성화 함수","text":"앞선 글에서 퍼셉트론, 가중치, 편향, 비선형, 다중퍼셉트론을 살펴보았다. 퍼셉트론 식을 구현하는 데 있어 가중치와 편향을 적절한 값으로 직접 설정했다. 그러나 층이 많아질수록 직접 설정할 수 없을 것이다. 신경망은 학습을 통해 가중치, 편향에 대한 적절한 값을 찾아준다. 신경망 신경망 네트워크신경망 네트워크는 입력층 - 은닉층 - 출력층으로 구성되는데, 은닉층의 경우 처리 과정을 확인할 수 없다. 신경망의 구조는 다층 퍼셉트론과 유사하다. 퍼셉트론에서 신경망으로 나아가 보자. 앞서 정의한 퍼셉트론 식을 다시 보자. 단층 퍼셉트론 식x1,x2는 입력신호, w1,w2는 가중치, b는 편향이다. 이 3가지를 네트워크로 나타내보자. 단층 퍼셉트론 네트워크익숙한 그림이지만 편향이 추가됐다. 이 그림은 위 퍼셉트론 식을 1b + w1x1 + w2*x2라고 풀어서 나타낸 것이다. 우리는 이 식을 새로 정의하여 아래처럼 간략화할 수 있다. 이 식을 설명하면 기존의 계산식(b+w1x1+w2x2)이 h(x) 함수를 거쳐 출력신호 y를 반환한다. 이 때, h(x)함수는 입력이 0을 넘으면 1을 반환하고 있다. h(x)함수는 활성화 함수라 부르며, 입력 신호의 총합을 처리하여 출력 값을 정하는 역할을 한다. 다시 말해, 기존의 단층 퍼셉트론 식은 입력신호의 총합을 갖고 출력신호를 반환했지만, 이제는 입력신호의 총합이 활성화 함수를 거쳐서 출력신호를 반환한다. 이렇게 활성화 함수를 추가하는 이유는 비선형성을 추가하기 위함이다. 바로 살펴보겠지만 활성화 함수들은 모두 비선형성 함수이다. 활성화 함수가 선형 함수라면 층을 깊게 하는 의미가 없어진다. 왜냐하면 복합함수로 설명될 수 있기 때문이다. f(x) * f(x) * f(x) 이런 식으로… 즉, 은닉층이 없는 네트워크가 된다. 그래서 다층 퍼셉트론에서는 활성화 함수가 필요하다. 활성화 함수를 네트워크 그림에 포함하면 아래와 같다. 입력 신호의 총합(a)은 활성화함수(h())를 거쳐 출력값(y)를 반환한다. 활성화 함수활성화 함수의 역할을 하는 함수가 여럿있는데 대표적으로는 계단함수, 시그모이드함수, ReLu함수가 있다. 이 함수가 어떻게 활성화시키는지 살펴보자. 계단 함수 계단 함수는 임계값 이전에는 출력값이 0이 었다가 임계값을 넘으면 1이 되는 함수이다. 계단 함수를 구현한 식은 아래와 같다. 여기서 임계값은 0이다. 1234import numpy as npdef step_function(x): return np.array(x&gt;0, dtype=np.int) 구현한 식을 가지고 그래프를 그려보자. 1234567import matplotlib.pylab as pltx = np.arange(-5.0, 5.0, 0.1)y = step_function(x)plt.plot(x, y)plt.ylim(-0.1, 1.1)plt.show() 계단 함수 그래프그래프와 같이 x &lt;= 0 이면, y값은 계속 0이다가, x &gt; 0 이면 y값이 1이 된다. 앞서 언급한 단층 퍼셉트론이 이 경우에 해당한다. 시그모이드 함수 시그모이드 함수는 신경망에서 자주 이용하는 활성화 함수로 수식은 다음과 같다. exp()는 지수함수를 의미한다. 시그모이드 함수는 아래와 같이 구현할 수 있다. 12def sigmoid(x): return 1/ (1+np.exp(-x)) 시그모이드 함수를 그래프로 나타내보자. 12345x = np.arange(-5.0, 5.0, 0.1)y = sigmoid(x)plt.plot(x, y)plt.ylim(-0.1, 1.1)plt.show() 계단함수처럼 이분적이지 않고 x값에 따라 y값이 계속 달라진다. ReLu 함수ReLu 함수도 신경망에서 주로 이용하는 함수중 하나로, 입력이 0을 넘으면 입력을 그대로 출력하고 0이하이면 0을 출력한다. 수식과 그래프는 다음과 같다. 1234567def relu(x): return np.maximum(0, x)x = np.arange(-5.0, 5.0, 0.1)y = relu(x)plt.plot(x, y)plt.ylim(-0.1, 1.1)plt.show() 출력층 활성화 함수 앞서 신경망은 입력층 - 은닉층 - 출력층으로 구성되어 있다고 언급했는데, 출력층에서의 활성화 함수는 다른 함수를 사용한다. 일반적으로신경망이 어떤 문제를 해결하느냐에 따라 다른 함수를 사용하는데, 분류 문제를 해결하는 경우 softmax함수를 사용하고 회귀에서는 항등함수를 사용한다. 항등 함수부터 살펴보자. 항등 함수(identity function) 항등 함수는 간단하다. 입력 값을 그대로 출력한다. f(x) = x 이다. 그래서 출력층에서 항등 함수를 사용하면 입력 신호가 그대로 출력 신호가 된다. 소프트맥스 함수(softmax function) 소프트맥스 함수의 식은 다음과 같다. 소프트맥수 함수의 분자는 입력 신호 ak의 지수함수, 분모는 모든 입력 신호의 지수 함수의 합으로 구성된다. 소프트맥스 함수를 그림으로 나타내면 다음과 같은데, 소프트맥스의 출력은 모든 입력 신호로부터 화살표를 받는다. 식의 분모에서 보듯, 출력층은 모든 입력 신호에서 영향을 받기 때문이다.","link":"/2020/04/11/book1-2/"},{"title":"JavaScript 클로저","text":"1. 클로저 이해클로저는 함수 안에 있는 함수이다. 함수 안에 있어서 외부 함수, 내부 함수(클로저)라고 구분해서 부른다. 클로저의 특징은 외부 함수의 변수를 참조한다는 점이다. 예제를 한 번 살펴보자. 123456789function outerFunc(){ var x = 10; var innerFunc = function() {console.log(x);} return innerFunc; var inner = outerFunc();inner()//result//10 예제에서 innerFunc() 함수가 클로저이다. inner 변수 객체를 생성한 뒤, inner()를 실행하면 outerFunc()이 끝나고 나서 innerFunc()을 실행시킨다. innerFunc()은 외부 함수인 outerFunc의 변수 x를 참조하여 10을 출력했다. outerFunc() 함수가 끝났음에도 변수 x를 참조하여 10을 출력한 것이다. 어떻게 가능할까? 이 원리를 스코프 체인으로 이해해 보면, innerFunc()의 [[scope]]가 outerFunc의 변수객체와 전역 객체를 가지기 때문이다. 다시 말해, outerFunc 실행 컨텍스트는 사라졌지만 outerFunc 변수 객체는 innerFunc()의 [[scope]]에 계속 남아있으므로 x를 출력할 수 있는 것이다. 그래서 클로저를 이미 생명 주기가 끝난 외부함수의 변수를 참조하는 함수라고 정의할 수 있다. 그리고 x와 같이 클로저로 참조되는 외부 변수를 자유 변수라고 한다. 2. 클로저 활용클로저는 성능 저하나 메모리 부담의 원인이 되기도 한다. 그럼에도 불구하고 고급 기술에서는 클로저가 많이 쓰이기 때문에 제대로 이해하고 활용하는 것이 중요하다. 클로저의 활용 예제를 살펴보자. 2-1) 특정 함수에 사용자가 정의한 객체의 메서드 연결하기 먼저 예제 하나를 살펴보자. 123456789101112131415161718function HelloFunc(func){ this.greeting = \"hello\";}HelloFunc.prototype.call = function(func){ func? func(this.greeting) : this.func(this.greeting);}var userFunc = function(greeting){ console.log(greeting);}var objHello = new HelloFunc();objHello.func = userFunc;objHello.call();//resulthello 예제의 실행 코드부터 보면 HelloFunc() 생성자 함수로 objHello 변수 객체를 생성했다. objHello에 func 프로퍼티를 userFunc으로 할당했다. objHello의 call함수를 실행시키면, HelloFunc에는 call함수가 없으므로 HelloFunc prototype객체에서 찾는데 call 메서드가 있으므로 실행시킨다. call 함수 호출 시, 매개 변수가 없으므로 this.func(this.greeting)이 실행되며 func 프로퍼티는 userFunc이라고 정의했으므로 userFunc(this.greeting)이 실행되고 결과적으로 hello가 출력된다. 여기서 call함수가 받는 인자는 greeting하나뿐이다. 만약 call() 함수 변경 없이 인자를 더 넣어서 호출하려면 어떻게 해야 할까? 아래 예제를 보자. 1234567891011121314151617function saySomething(obj, methodName, name){ return (function(greeting){ return obj[methodName](greeting, name); });}function newObj(obj, name){ obj.func = saySomething(this, \"who\", name); return obj;}newObj.prototype.who = function(greeting, name){ console.log(greeting + \" \" + (name || \"everyone\") );}var obj1 = new newObj(objHello, \"zzoon\");obj1.call(); 이번에는 newObj() 생성자 함수로 obj1 변수 객체를 생성했다. 매개변수 값으로 objHello 객체와 “zzoon” 문자를 전달했다. 그러면 objHello 객체의 func 프로퍼티로 saySomething(this,”who”,name);에서 반환되는 함수를 참조한다. saySomething의 매개변수 값을 살펴보면, obj = this로, newObject 객체 methodName = “who” name = “zzoon” 이 된다. 그리고 function(greeting){} 함수를 반환하는 데 이것이 HelloFunc 객체의 func으로 참조된다. 결과적으로 bj1.call()로 실행되는 것은 newObj.prototype.who()가 된다. 3. 클로저 주의사항3-1) 자유 변수 값은 변경 가능하다. 123456789101112131415function outerFunc(argNum){ var num = argNum; return function(x){ num += x; console.log('num: ' + num); } } var exam = outerFunc(40); exam(5); exam(-10); //result//45//35 자유 변수 num의 값은 계속 변화하기 때문에 주의해야 한다. 3-2) 루프 안에서 사용할 때 123456789function countSeconds(howMany){ for(var i = 1;i &lt;= howMany; i++){ setTimeout(function(){ console.log(i); }, i * 1000); }}countSeconds(3); 1, 2, 3을 1초 간격으로 출력하는 예제이지만 결과는 4가 연속 3번 1초 간격으로 출력된다. 왜냐하면 setTimeout 함수의 인자로 들어가는 함수는 자유 변수 i를 참조한다. 하지만 setTimeout함수가 실행되는 시점은 countSeconds() 함수의 실행이 종료된 이후이고, i 값은 이미 4가 된 상태이다 그러므로 모두 4를 출력하게 된다. 원하는 결과를 얻고 싶으면 아래와 같이 하면 된다. 1234567891011function countSeconds(howMany){ for (var i = 1; i &lt;= howMany; i++) { (function (currentI) { setTimeout(function() { console.log(currentI); }, currentI * 1000); }(i)); }};countSeconds(3); 구현 방법은 (function ( currentI){})라는 함수를 정의함과 동시에 바로 실행되는 즉시 실행 함수(immediate function)로 setTimeout을 감싸는 것이다. 루프 i 값을 currentI에 복사해 사용하면 원하는 결과를 얻을 수 있다. 끝 ^_^","link":"/2020/04/12/book2-1/"},{"title":"XMLHttpRequest 와 Fetch API","text":"&lt;리얼월드 HTTP&gt; 도서의 내용을 요약 정리하고 관련 내용을 추가하였습니다. XMLHttpRequestcurl 커맨드의 기능을 자바스크립트로 사용할 수 있게 해주는 기능이 XMLHttpRequest이다. http 통신과 마찬가지로 클라이언트가 서버에 요청을 보내고, 그 응답으로 서버가 클라이언트에 데이터를 보낼 수 있다. 단, http처럼 서버 측에서 클라이언트에 요청을 보낼 수는 없다.(?) XMLHttpRequest 와 브라우저의 http요청 차이 송수신할 때 html화면이 새로 고침되지 않는다. GET과 POST 이외의 메서드도 전송할 수 있다. 폼의 경우 키와 값이 일대일이 되는 형식의 데이터만 전송할 수 있고, 응답은 브라우저로 표시되어 버리지만, 플레인텍스트,json,binary data,xml등 다양한 형식을 송수신할 수 있다. http의 경우, 파일 다운로드를 제외하면 서버의 응답을 받을 때는 화면이 일단 지워지고 브라우저 내에서 새로운 페이지가 렌더링된다. 하지만 XMLHttpRequest를 사용하면 자바스크립트 내에서 송수신이 완결되므로 화면이 지워지지 않아도 최신 정보를 가져올 수 있다. 이처럼 화면을 지우지않고 웹페이이지를 갱신할 수 있는 아키텍처를 ajax라고 한다. XMLHttpRequest의 보안XMLHttpRequest의 보안 제어는 액세스할 수 있는 정보 제한과 전송 제한이라는 두가지 제한으로 구성된다. 액세스할 수 있는 정보의 제한으로는 쿠키가 있다. 스크립트로 document.cookie 속성에 엑세스하면 브라우저에서 여는 페이지에 관한 쿠키를 모두 읽을 수 있다. 이 때, httponly 속성을 쿠키에 부여하면, 스크립트로 액세스할 수 없어지므로 외부로 유출될 위험이 줄어든다. 전송 제한에는 도메인, 메서드, 헤더 세 종류가 있다. 스크립트로 어느 웹사이트에나 자유롭게 액세스할 수 있게 되면, 악의가 있는 웹사이트로 정보를 전송해 버릴 수 있다. 이를 방지하기 위해 기본적으로 브라우저 액세스하고 있는 호스트에만 접근할 수 있다. 그 밖의 사이트에 액세스하는 방법으로서 xmlhttprequest뿐만 아니라 브라우저에서 널리 이용되는 CORS라는 액세스 제한 시스템이 있다. Fetch API","link":"/2020/06/02/book3-3/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/04/05/hello-world/"},{"title":"Javascript 객체 지향[2] - class 상속&#x2F;super&#x2F;object 상속&#x2F;__proto__ vs prototype","text":"1. class 상속클래스를 생성할 때 다른 클래스를 상속 받을 수 있는데, 새로 만들어지는 클래스가 자식 클래스, 상속하는 클래스가 부모 클래스가 된다. 자바스크립트에서 상속은 extends를 쓴다. 123456789101112131415161718192021class Person{ constructor(name, first, second){ this.name = name; this.first = first; this.second = second; } sum(){ return this.first + this.second }}class PersonPlus extends Person{ avg(){ return (this.first + this.second)/2; }}var kim = new PersonPlus('kim',10,20);console.log(\"kim.sum()\",kim.sum()); //kim.sum() 30console.log(\"kim.avg()\",kim.avg()); //kim.avg() 15 PersonPlus 클래스에 sum()메서드가 없음에도 불구하고 kim 객체에 sum()을 호출하니 에러없이 결과값이 나왔다. 이는 PersonPlus의 부모 클래스 Person의 sum()메서드를 사용한 것이다. 약간 옆길로 새서 만약 Person과 PersonPlus 모두 sum()이 있었다면 PersonPlus 클래스의 sum()을 사용한다. 부모 클래스와 같은 함수명을 새로 정의하는 것을 오버라이딩이라고 한다. 2. super클래스를 생성할 때, 부모 클래스의 기능을 활용해서 메서드나 변수를 선언하고 싶다면 super를 사용하면 된다. 1234567891011121314151617181920212223242526272829class Person{ constructor(name, first, second){ this.name = name; this.first = first; this.second = second; } sum(){ return this.first+this.second; }}class PersonPlus extends Person{ constructor(name,first,second,third){ super(name,first,second); this.third = third; } sum(){ return super.sum() + this.third; } avg(){ return (super.sum() + this.third)/3; }}var kim = new PersonPlus('kim',10,20,30);console.log(\"kim.sum()\", kim.sum()); //kim.sum() 60console.log(\"kim.avg()\", kim.avg()); //kim.avg() 20 PersonPlus constructor에 super()를 사용해서 Person constructor에 선언된 name,first,second 변수를 가져다 썼으며, 정의되지 않은 third는 새로 선언했다. 그리고 sum()과 avg메서드에서는 Person sum()메서드를 활용해서 함수를 정의하고 있다. 3. object 상속중괄호{}로 표현하는 object도 상속이 가능하다. 123456789101112131415var superObj = {superVal:'super'};//case1var subObj = {subVal:'sub'};subObj.__proto__ = superObj;//case2var subObj = Object.create(superObj);//공통subObj.subVal = 'sub';console.log('subObj.subVal =&gt;', subObj.subVal); //subObj.subVal =&gt; subconsole.log('subObj.superVal =&gt;', subObj.superVal); //subObj.superVal =&gt; supersubObj.superVal = 'sub';console.log('superObj.superVal =&gt;', superObj.superVal); //superObj.superVal =&gt; super case1과 case2의 결과값은 같다. superObj객체에는 superVal, subObj 객체에는 subVal이 있는데 상속을 통해 subObj에서도 superVal을 호출할 수 있었다. 단 subObj에서 superVal 값을 변경했을 때 subObj에서만 변경될 뿐, 참조하고 있는 SuperObj의 값은 변하지 않는다. 4. __proto__ vs prototype객체가 생성될 때 객체가 참조하는 prototype 타입 객체도 함께 생성된다. 객체의 __proto__는 prototype 객체를 참조하고, prototype 객체의 constructor 프로퍼티는 생성된 객체를 참조한다. 즉 서로가 서로를 참조하는 것이다.","link":"/2020/04/12/book2-4/"},{"title":"쿠키, 세션, 캐시","text":"&lt;리얼월드 HTTP&gt; 도서의 내용을 요약 정리하고 관련 내용을 추가하였습니다. 콘텐트 니고시에이션서버와 클라이언트는 따로 개발되어 운용되므로 양쪽이 기대하는 형식이나 설정이 항상 일치한다고 할 수는 없다. 통신 방법을 최적화하고자 하나의 요청 안에서 서버와 클라이언트가 서로 최고의 설정을 공유하는 시스템을 콘텐트 니고시에이션이라고 한다. 니고시에이션에 사용하는 헤더는 다음 4개이다. Accept ⇒ MIME 타입 Accept-language ⇒ 표시 언어 Accept-charset ⇒ 문자의 문자셋 Accept-encoding ⇒ 바디 압축 Accept에서 q는 품질 계수로 0~1까지의 값이다. 기본은 1.0이며, 우선 순위를 나타낸다. 우선 순위대로 파일 형식을 체크하고 지원하지 않으면 다음 우선 순위로 넘어가는 방식이다. 쿠키쿠키란 웹사이트의 정보를 브라우저 쪽에 저장하는 작은 파일이다. 쿠키도 http 헤더를 기반으로 구현됐다. 서버에서는 다음과 같이 응답 헤더를 보낸다. Set-cookie: last_access_date=jul/31/2019 HTTP는 스테이트리스(언제 누가 요청해도 요청이 같으면 결과가 같음)을 기본으로 개발 됐지만, 쿠키를 이용하면 서버가 상태를 유지하는 스테이트풀처럼 보이게 서비스를 제공할 수 있다. 쿠키의 잘못된 사용법 영속성 문제 : 브라우저의 비밀모드, 보안 설정에 따라 세션이 끝나면 초기화 되거나 쿠키를 보관하라는 서버의 지시를 무시하기도 한다. 사라지더라도 문제가 없는 정보나 서버 정보로 복원할 수 있는 자료를 저장하는 용도에 적합하다. 용량 문제 : 쿠키의 최대 크기는 4kb 제한되어 있다. 보안 문제 : secure 속성을 부여하면 https프로토콜로 암호화된 통신에서만 쿠키가 전송되지만, http통신에서는 쿠키가 평문으로 전송된다. 매 요청 시 쿠키가 전송되는데 노출될 위험성이 있다. 정보를 넣을 때는 서명이나 암호화 처리가 필요하다. 쿠키에 제약을 주다Http클라이언트는 쿠키를 제어하는 속성을 해석해 쿠키 전송을 제어할 책임이 있다. 속성은 세미클론으로 구분해 얼마든지 나열할 수 있다. Expires, max-age속성 : 쿠키의 수명을 설정한다. 각각 특정날짜와 초단위로 제한 Domain : 클라이언트에서 쿠키를 전송할 대상 서버. 생략하면 쿠키를 발행한 서버가 된다. Secure : https로 프로토콜을 사용한 보안 접속일 때만 클라이언트에서 서버로 쿠키를 전송한다. Http접속일 때는 브라우저가 경고를 하고 접속하지 않아 정보 유출을 막는다. Httponly : 자바스크립트 엔진으로부터 쿠키를 감출 수 있다. Samesite : 크롬 브라우저에서 도입한 속성으로, 같은 오리진의 도메인에 전송하게 된다. 인증과 세션 Basic인증과 digest인증 Basic인증은 유저명과 패스워드를 base64로 인코딩한 것이다. Base64는 복호화가 가능하므로 서버로부터 복원해 원래 유저명과 패스워드를 추출할 수 있다. 추출된 정보는 서버의 db와 비교해서 정상 사용자인지 검증한다. Digest 인증은 해시함수를 이용한다. 쿠키를 사용한 세션 관리지금은 basic, digest인증 모두 거의 사용되지 않는다. 최근 많이 사용되는 방식은 폼을 이용한 로그인과 쿠키를 이용한 세션관리 조합이다. 설명하면, 클라이언트는 폼으로 id,password를 전송한다. Digest인증과 달리 직접 송신하므로 ssl/tls 방식이 필수다. 서버 측에서는 유저id와 패스워드로 인증하고 문제가 없으면 세션 토큰을 발행한다. 서버는 세션 토큰을 관계형 db나 키-밸류형 db에 저장해둔다. 토큰은 쿠키로 클라이언트에 되돌아간다. 두번째 이후 접속에서는 쿠키를 재전송해 로그인된 클라이언트임을 서버가 알 수 있다. 프록시프록시는 http등의 통신을 중계한다. 때로는 중계만 하지 않고 각종 부가 기능을 구현한 경우도 있다. 또한 외부공격으로부터 네트워크를 보호하는 방화벽 역할도 한다. 중계되는 프록시는 중간의 호스트ip주소를 특정 헤더에 기록해 간다. X-forwarded-for: client, proxy1, proxy2… 프록시와 비슷한 것으로는 게이트웨이가 있다. 이 둘은 http/1.0에서 다음과 같이 정의되어 있다. 프록시 : 통신 내용을 이해한다. 필요에 따라서 콘텐츠를 수정하거나 대신 응답한다. 게이트 웨이: 통신 내용을 그대로 전송한다. 내용의 수정도 불허한다. 클라이언트에서는 중간에 존재하는 것을 알아채서는 안된다. 캐시콘텐츠가 변경되지 않았을 땐 로컬에 저장된 파일을 재사용함으로써 다운로드 횟수를 줄이고 성능을 높인다. Get/head메서드 이외에는 캐시되지 않는다. 갱신 일자에 따른 캐시기본적으로 last-modified가 있으면 콘텐츠를 캐시한다. 서버는 캐시 시간과 컨텐츠 갱신 일자를 비교해서 컨텐츠가 업데이트됐으면 200 ok를 반환하고 바디에 콘텐츠를 실어 보내지만, 업데이트 안됐으면 304 not modified를 반환하고 바디를 응답에 포함하지 않는다…! Expires앞서 설명한 갱신 일시를 이용하여 캐시하는 경우 캐시의 유효성을 확인하기 위한 통신이 발생한다. 이 통신 자체를 없애기 위해 헤더에 expires를 추가한다. Expires헤더에는 날짜와 시간이 들어간다. Expires기간 이내라면 캐시가 유효하다고 판단해 요청을 아예 전송하지 않는다. 지정한 기간 이내의 변경 사항은 모두 무시되기 때문에 좀처럼 변경되지 않는 정적 콘텐츠에 사용하는 것이 바람직하다. Pragma:no-cache이 헤더는 프록시 서버에 요청한 컨텐츠가 이미 저장돼 있어도, 원래 서버에서 가려오라고 지시한다. No-cache는 http/1.1에 이르러 cache-contorl로 통합됐지만, 아직 남아 있다. 그다지 적극적으로 사용되지는 않는다. Etag추가동적으로 바뀌는 요소가 늘어날수록 어떤 날짜를 근거로 캐시의 유효성을 판단해야 하는지 판단하기 어려워진다. Etag는 순차적인 갱신 일시가 아니라 파일의 해시값으로 비교한다. 일시를 이용해 확인할 때처럼 서버는 응답에 etag 헤더를 부여한다. 두번째 이후 다운로드 시 클라이언트는 if-none-match헤더에 다운로드된 캐시에 들어 있던 etag값을 추가해 요청한다. 서버는 보내려는 파일의 etag와 비교해서 같으면 304 not modified로 응답한다. 오호! Etag는 서버가 자유롭게 그 값을 정할 수 있다. 예를 들어 아마존s3의 경우 콘텐츠 파일의 해시 값이 사용된다. Cahce-controlEtag와 같은시기에 1.1에 추가된 것이 cache-control헤더이다. Expires보다 우선해서 처리된다. 리퍼러리퍼러는 사용자가 어느 경로로 웹사이트에 도달했는지 서버가 파악할 수 있도록 클라이언트가 서버에 보내는 헤더이다. 웹서비스는 리퍼러 정보를 수집함으로써 어떤 페이지가 자신의 서비스에 링크를 걸었는지도 알 수 있다. 리퍼러 정책으로서 설정할 수 있는 값은 다음과 같다. No-referrer:전혀 보내지 않는다. No-referrer-when-downgrade:기본 동작과 마찬가지로 https→http일 때는 전송하지 않는다. Same-origin:동일 도메인 내의 링크에 대해서만 리퍼러를 전송한다. Origin:상세 페이지가 아니라 톱페이지에서 링크된 것으로 해 도메인 이름만 전송한다. Strict-origin:origin과 같지만 https→http일 때는 전송하지 않는다. Origin-when-crossorigin: 같은 도메인내에서는 완전 리퍼러를, 다른 도메인에는 도메인 이름만 전송한다. Unsafe-url: 항상 전송한다. 검색 엔진용 콘텐츠 접근 제어크롤러, 로봇, 봇, 스파이더와 같은 정보를 수집하는 자동 순회 프로그램이 많이 운용되게 되었다. 이 크롤러의 접근을 제어하는 방법으로는 주로 2가지 방법이 쓰인다. Robots.txt 사이트맵 Robots.txtRobots.txt는 서버 콘텐츠 제공자가 크롤러에 접근 허가 여부를 전하기 위한 프로토콜이다. 파일 내에서는 읽기를 금지할 크롤러의 이름과 장소를 지정한다. 123User-agent:*Disallow:/cgi-bin/Disallow:/tmp/ Robots.txt가 블랙리스트처럼 사용된다면, 사이트맵은 화이트리스트처럼 사용된다..","link":"/2020/05/31/book3-2/"},{"title":"pytest 사용기 - fixture, scope","text":"파이썬에서 제공하는 테스팅 모듈로는 unittest, pytest가 유명한데, 둘 중 어느걸 사용해 볼까 하다가 pytest가 간단해 보여서 pytest로 작업을 진행했습니다. 빠른 진행을 위해서는 테스팅 모듈이 간편한게 좋을 것 같다는 생각이 들었기 때문입니다. pytest 어떻게 사용했는지 살펴보겠습니다. 설치pytest는 pip 로 설치하며 기초 설명은 공식 홈페이지에서 확인 가능합니다. 1pip install pytest 프로젝트 구조 테스트 코드를 작성한 프로젝트의 구조는 다음과 같습니다. 1234567891011121314.├── logparser│ ├── __init__.py│ ├── models.py│ └── parser.py├── logs│ ├── elb1.log.gz│ ├── elb2.log.gz├── pytest.ini└── test ├── __init__.py ├── conftest.py ├── logs/ └── test_parser.py pytest를 위해 작성한 파일은 pytest.ini와 test폴더 하위의 파일들입니다. 먼저, pytest.ini에는 테스트에 사용할 파일과 테스트 옵션을 추가합니다. 일반적으로 test_*.py 또는 *_test.py를 테스트 파일로 인식하지만 직접 지정해줄 수도 있습니다. 파일이 여러 개인 경우 스페이스로 구분합니다. 12[pytest]python_files = test_parser.py test_*.py 테스트는 pytest 명령어를 사용해 실행합니다. 실행하는 경로에 상관없이 pytest용 파일을 찾아 실행합니다. q옵션을 사용하면 로그를 간략하게 볼 수 있습니다. 123(venv) yejinui-MacBook-Pro:logparser yejin$ pytest -q..... [100%]5 passed in 31.78s 테스트 코드 작성테스트 함수에는 아래와 같이 함수명에 접두사로 test_ 를 붙여야 합니다. 접두사가 없으면 그 함수는 실행하지 않고 넘어갑니다. count 함수와 sequence 함수를 테스트 하기 위해 각각 test_count, test_sequnce함수를 만들었습니다. test_count는 로그 수가 맞는지를 확인하고 test_sequence는 ‘type’ 별 집계가 일치하는지 확인합니다. 123456789101112#test_parser.pydef test_count(): logs = log_parser(get_test_log) assert count(logs) == 87060def test_sequence(): logs = log_parser(get_test_log) assert sequence(logs, 'type', reverse=True) == [ ('http', 82719), ('h2', 3398), ('https', 943) ] 두 함수에서는 공통적으로 log_parser()함수를 사용해 로그를 읽어옵니다. 예시 이외에도 로그를 읽어 오는 테스트가 더 있어 클래스를 정의하는 방식으로 변경하였습니다. self.logs를 사용하는 방식으로 코드를 수정했습니다. 12345678910111213class TestParserClass: def __init__(self, get_test_log): self.logs = list(log_parser(get_test_log)) def test_count(self): assert count(self.logs) == 87060 def test_sequence(self): assert sequence(self.logs, 'type', reverse=True) == [ ('http', 82719), ('h2', 3398), ('https', 943) ] 그런데 에러가 발생했습니다. 클래스에 __init__를 정의한 것이 문제가 되었습니다. 공식 홈페이지를 확인해보니 __init__를 정의하는 경우 클래스가 인스턴스화 되지 않는다고 하네요. 12345678(venv) yejinui-MacBook-Pro:logparser yejin$ pytest -q=============================================================================== warnings summary ================================================================================test/test_parser.py:9 /Users/yejin/Sites/project/logparser/test/test_parser.py:9: PytestCollectionWarning: cannot collect test class 'TestParserClass' because it has a __init__ constructor (from: test/test_parser.py) class TestParserClass:-- Docs: https://docs.pytest.org/en/stable/warnings.html1 passed, 1 warning in 0.03s 그래서 fixture를 사용했습니다. fixture란, 테스트 시 사용하는 함수들을 미리 정의하는 기능입니다. fixture함수는 test/conftest.py에 작성합니다. 12345#test/conftest.py@pytest.fixture(scope=\"module\")def test_log_parse(): return list(log_parser(get_log('./logs/'))) test_ 함수에서 사용할 때에는 따로 conftest를 임포트할 필요없이 매개변수로 지정하기만 하면됩니다. 12345678910#test_parser.pydef test_count(test_log_parse): assert count(test_log_parse) == 87060def test_sequence(test_log_parse): assert sequence(test_log_parse, 'type', reverse=True) == [ ('http', 82719), ('h2', 3398), ('https', 943) ] 굳이 fixture를 사용하지 않고 test_log_parse 함수를 만들어도 되는게 아닌가 생각할 수도 있습니다. 그렇게도 가능합니다. 그러나 깨끗한 테스트 코드를 위해 변하지 않는 기능은 한 곳에 넣어두고 자주 변경되며 확장할 기능을 만들도록 하는 것이 관리에 좋아 보입니다. 클래스 상속 개념처럼요🙂 그리고 무엇보다도 fixture를 사용하면 fixture가 제공하는 부가 옵션들을 사용할 수 있습니다. 여기서는 scope를 사용했습니다. scope를 사용해 fixture를 모듈, 클래스, 세션 단위로 공유합니다. 다시 말해, test_ 함수를 실행할 때마다 fixture함수를 재호출하지 않고 사용할 수 있다는 것입니다. scope를 module 단위로 지정했더니, test_log_parse 한 번 호출 후 계속 재사용하기 때문에 아래와 같이 실행 시간이 단축됩니다. 123456789//scope 사용(venv) yejinui-MacBook-Pro:logparser yejin$ pytest -q..... [100%]5 passed in 34.24s//scope 미사용(venv) yejinui-MacBook-Pro:logparser yejin$ pytest -q..... [100%]5 passed in 131.13s (0:02:11)","link":"/2020/08/09/project-3/"},{"title":"프로젝트 오픈!","text":"손으로 쓴 숫자이미지를 판별하는 딥러닝을 R로만 구현하기 프로젝트를 1차 오픈했습니다.앞으로 과정을 기록해 보겠습니다. 링크 공유드려요. 구경오세요 링크 : https://github.com/LOPES-HUFS/DeepLearningFromForR","link":"/2020/04/12/project1-1/"},{"title":"딥러닝에 쓰이는 함수를 R과 Python으로 구현하기","text":"딥러닝 책 『밑바닥부터 시작하는 딥러닝』 을 공부하면서, 책에 있는 Python코드를 R로 구현하는 프로젝트를 진행하고 있습니다. Python으로 구현한 딥러닝 함수 코드와 R로 구현한 함수 코드를 동시에 살펴 보고자 합니다. 1. 시그모이드(Sigmoid) 함수 시그모이드 함수는 활성화 함수역할을 하는 대표 함수입니다. 함수 식은 다음과 같습니다. 파이썬의 경우, Numpy의 지수함수인 exp()를 사용해서 구현합니다. 12def sigmoid(x): return 1/ (1+np.exp(-x)) 시그모이드 함수를 그래프로 나타내기 위해 임의의 x값을 정하고 matplotlib으로 나타냅니다. 여기서 x는 [-5.0, -4.9, -4.8, …. 4.9]가 됩니다. 12345x = np.arange(-5.0, 5.0, 0.1)y = sigmoid(x)plt.plot(x, y)plt.ylim(-0.1, 1.1)plt.show() R은 행렬 계산을 기본으로 하기 때문에 다른 라이브러리를 임포트할 필요 없이 exp()를 사용할 수 있습니다. 1234sigmoid &lt;- function(x){ return(1 / (1 + exp(-x)))} 마찬가지로, 임의의 x값을 정하고 ggplot2 라이브러리로 그래프를 그립니다. 1234567library(ggplot2)x &lt;- seq(from = -5, to = 4.9, by = 0.1)y &lt;- sigmoid(x)data &lt;- data.frame(x, y)ggplot(data, aes(x, y)) + geom_line() 2. 렐루(Relu) 함수 렐루 함수 역시 마찬가지로 활성화 함수의 대표 함수 중 하나입니다. 시그모이드 함수와의 차이점은 임계점을 기준으로 0 또는 입력 값을 출력한다는 것입니다. 12345678def relu(x): return np.maximum(0, x)x = np.arange(-5.0, 5.0, 0.1)y = relu(x)plt.plot(x, y)plt.ylim(-0.1, 1.1)plt.show() R도 간단하게 구현합니다. 123456789relu &lt;- function(x){ return(ifelse(x &gt; 0, x, 0))}x &lt;- seq(from = -5, to = 4.9, by = 0.1)y &lt;- relu(x)data &lt;- data.frame(x, y)ggplot(data, aes(x, y)) + geom_line() 아래의 결과를 보면 0보다 작은 x값에 대해서는 결과값이 0 이고, 0보다 큰 x값에 대해서는 x값을 출력하고 있음을 확인할 수 있습니다. 3. 소프트맥스(Softmax) 함수 소프트 맥스 함수는 활성화 함수 중에서도 출력층에서 사용하는 활성화 함수입니다. 소프트 맥스 함수는 결과 값에 대해 0에서~1 사이의 값으로 변환해 주는 역할만 할 뿐, 결과가 바뀌는 등의 영향을 미치지는 않습니다. 결과에 영향을 미치지 않아 실제 추록 과정에서는 사용하지 않지만, 학습 단계에서 영향도를 확인하는 척도로 사용합니다. 소프트 맥스 함수식은 다음과 같습니다. 함수식을 조금 살펴보면, 분모는 모든 입력값(a)의 지수함수에 대한 총합이고 분자는 입력값(a)의 지수함수입니다. 이 식을 파이썬에서는 아래와 같이 구현합니다. 1234567def softmax(a): c = np.max(a) exp_a = np.exp(a-c) sum_exp_a = np.sum(exp_a) y = exp_a / sum_exp_a return y exp_a는 소프트맥스 함수 식에 없는 처리를 하고 있는데, 입력값 중(a) 최대값(c)를 구한 후 최대값(c)을 일괄적으로 뺀 지수함수를 구하고 있습니다. 이같은 처리를 하는 이유는 지수함수의 특징 때문입니다. 지수함수는 쉽게 큰 값을 출력합니다. 이 때는 숫자 값이 아닌 무한대를 뜻하는 inf값을 출력하게 됩니다. 이 문제를 방지하고자 최댓값을 빼는 것이 일반적입니다. 지수 함수는 일괄적으로 더하거나 빼도 결과가 바뀌지 않습니다. 결과는 다음과 같습니다. 1234a = np.array([0.3, 2.9, 4.0])y = softmax(a)print(y) 소프트 맥스 함수는 결과 값의 합이 항상 1인 것이 특징입니다. R에서도 마찬가지로 최댓값을 빼는 방법으로 소프트맥스 함수를 구현합니다. 123456softmax &lt;- function(a){ exp_a &lt;- exp(a - max(a)) sum_exp_a &lt;- sum(exp_a) return(exp_a / sum_exp_a)} 4. 교차 엔트로피 오차 함수 교차 엔트로피 오차 함수는 손실함수에 사용하는 함수이다. 딥러닝 학습 시에 손실함수를 최소화하는 매개변수를 찾는 것을 목표로 한다. 교차 엔트로피 오차 식은 다음과 같다. 파이썬으로 다음과 같이 구현한다. 123def cross_entropy_error(y, t): delta = 1e-7 return -np.sum(t * np.log(y + delta)) delta변수 역시 소프트맥스 함수와 비슷한 이유로 추가했는데, np.log() 함수에 0을 입력하면 마이너스 무한대를 뜻하는 -inf가 출력됩니다. 이문제를 방지하기 위해 아주 작은 값인 delta를 추가하게 됩니다. 교차엔트로피 오차는 다음과 같은 값을 출력합니다. 1234t = [0,0,1,0,0,0,0,0,0,0]y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]cross_entropy_error(np.array(y), np.array(t)) 1234t = [0,0,1,0,0,0,0,0,0,0]y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]cross_entropy_error(np.array(y), np.array(t)) 설명하면, t는 정답 레이블이고 y는 예측값입니다. 예측 값(y)을 정답레이블(t)로 채점하고 얼마나 틀렸나 확인해주는 것입니다. 첫번째 t에서 정답은 3번째=1)입니다. 그리고 y는 3번째가 정답일 확률을 0.6이라고 나타낸 것입니다. 이 때의 교차 엔트로피 오차값은 0.51입니다. 반면, 두번째와 같이 t에서 정답이 3번째(=1)인데, y는 3번째가 정답일 확률을 0.1로 나타냈더니, 교차 엔트로피 오차값은 2.30이 되었습니다. 정리하면, 오차율이 낮을 수록 교차 엔트로피 오차값이 낮아지며, 오차값이 낮을 수록 정확도가 높다는 것을 의미하게됩니다. R에서는 다음과 같이 구현합니다. 1234cross_entropy_error_single &lt;- function(y, t) { return(-sum(t*log(y+1e-7)))} 마찬가지로 파이썬과 같이 y와 t값을 넣어보면 같은 결과를 확인할 수 있습니다. 지금까지 딥러닝 함수에서 기본적으로 사용하는 함수들을 파이썬과 R로 구현해보며 살펴 보았습니다.기본 함수에 있어서는 언어 표현 방식의 차이일 뿐 같은 방식으로 구현하는 것을 확인할 수 있었습니다:)","link":"/2020/04/25/project1-2/"},{"title":"역전파를 사용하여 모델 학습하기","text":"오차역전파를 사용한 학습도 손실함수를 최소화하는 가중치를 찾는 것을 목표로합니다. 다만, 역전파는 가중치를 구함에 있어 연쇄법칙에 기반한 국소적 미분을 활용합니다. 순전파와 비교했을 때 훨씬 빠른 시간 안에 효울적으로 계산한다는 장점이 있습니다. 이번에는 역전파법을 사용하여 모델 학습을 진행해 보겠습니다. 먼저, 라이브러리와 공통함수를 읽어옵니다. 123456#install.packages(\"dslabs\") library(dslabs) source(\"./functions.R\") source(\"./utils.R\") source(\"./model.R\") 1개의 은닉층을 갖는 네트워크를 생성합니다. 네트워크는 순전파와 동일합니다. 12345678TwoLayerNet &lt;- function(input_size, hidden_size, output_size, weight_init_std = 0.01) { W1 &lt;- weight_init_std * matrix(rnorm(n = input_size*hidden_size), nrow = input_size, ncol = hidden_size) b1 &lt;- matrix(rep(0,hidden_size), nrow = 1, ncol = hidden_size) W2 &lt;- weight_init_std * matrix(rnorm(n = hidden_size*output_size), nrow = hidden_size, ncol = output_size) b2 &lt;- matrix(rep(0,output_size),nrow = 1, ncol = output_size) return (list(W1 = W1, b1 = b1, W2 = W2, b2 = b2))} 데이터를 불러와 트레이닝셋과 테스트셋으로 분리하는 init()함수를 생성합니다. 123456789init &lt;- function(){ mnist_data &lt;- get_data() #손글씨 데이터 x_train_normalize &lt;&lt;- mnist_data$x_train x_test_normalize &lt;&lt;- mnist_data$x_test #정답 레이블 t_train_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_train,60000, 10) t_test_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_test,10000, 10)} 앞서 역전파에서는 국소적 미분을 사용한다고 했습니다. 순전파와 반대방향으로 국소적 미분을 곱하여 이전 노드들에 값을 전달하는 것인데, 국소적 미분은 순전파 때의 미분을 구한다는 뜻입니다. 다시 말해, 순전파 때의 미분 값을 구해 다음 노드에 전달하는 함수가 필요합니다.다음 코드는 순전파 때와 마찬가지로 입력신호와 가중치를 계산하고 Relu함수를 거쳐 다음 노드로 전달합니다. 123456forward &lt;- function(x){ Affine_1 &lt;- Affine.forward(network$W1, network$b1, x) Relu_1 &lt;- Relu.forward(Affine_1$out) Affine_2 &lt;- Affine.forward(network$W2, network$b2, Relu_1$out) return(list(x = Affine_2$out, Affine_1.forward = Affine_1, Affine_2.forward = Affine_2, Relu_1.forward = Relu_1))} 역전파도 마찬가지로 손실함수를 계산합니다. 123456loss &lt;- function(model.forward, x, t){ temp &lt;- model.forward(x) y &lt;- temp$x last_layer.forward &lt;- SoftmaxWithLoss.forward(y, t) return(list(loss = last_layer.forward$loss, softmax = last_layer.forward, predict = temp))} 순전파와 달리 마지막 노드에서부터 거꾸로 계산해 기울기를 구합니다. 123456789101112gradient &lt;- function(model.forward, x, t) { # 순전파 temp &lt;- loss(model.forward, x, t) # 역전파 dout &lt;- 1 last.backward &lt;- SoftmaxWithLoss.backward(temp$softmax, dout) Affine_2.backward &lt;- Affine.backward(temp$predict$Affine_2.forward, dout = last.backward$dx) Relu_1.backward &lt;- Relu.backward(temp$predict$Relu_1.forward, dout = Affine_2.backward$dx) Affine_1.backward &lt;- Affine.backward(temp$predict$Affine_1.forward, dout = Relu_1.backward$dx) grads &lt;- list(W1 = Affine_1.backward$dW, b1 = Affine_1.backward$db, W2 = Affine_2.backward$dW, b2 = Affine_2.backward$db) return(grads)} 다음은 학습을 실제로 진행하는 코드입니다. 12345678910111213141516171819202122232425262728train_model &lt;- function(batch_size, iters_num, learning_rate, debug=FALSE){ #seperate train, test data init() train_size &lt;- dim(x_train_normalize)[1] iter_per_epoch &lt;- max(train_size / batch_size) for(i in 1:iters_num){ batch_mask &lt;- sample(train_size ,batch_size) x_batch &lt;- x_train_normalize[batch_mask,] t_batch &lt;- t_train_onehotlabel[batch_mask,] grad &lt;- gradient(model.forward=forward, x_batch, t_batch) #update weights and biases using SGD network &lt;&lt;- sgd.update(network,grad,lr=learning_rate) if(debug == TRUE){ if(i %% iter_per_epoch == 0){ train_acc &lt;- model.evaluate(forward, x_train_normalize, t_train_onehotlabel) test_acc &lt;- model.evaluate(forward, x_test_normalize, t_test_onehotlabel) print(c(train_acc, test_acc)) } } } train_accuracy = model.evaluate(forward, x_train_normalize, t_train_onehotlabel) test_accuracy = model.evaluate(forward, x_test_normalize, t_test_onehotlabel) return(c(train_accuracy, test_accuracy))} train_model()함수 중간에 sg.update()함수는 경사하강법으로 변경된 가중치를 업데이트하는 역할을 합니다.코드는 아래와 같습니다. 1234sgd.update &lt;- function(network, grads, lr = 0.01){ for(i in names(network)){network[[i]] &lt;- network[[i]] - (grads[[i]]*lr)} return(network)} 이제 모든 준비를 마쳤습니다. 네트워크를 생성한 후 모델을 학습시켜봅니다. 12network &lt;&lt;- TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)train_model(100, 10000, 0.1, TRUE) 위 코드를 실행시키고 3분 정도 지나면 아래와 같은 출력화면이 나올 것입니다. 한 행의 첫 번째 숫자는 훈련데이터 셋에 대한 정확도, 두 번째 숫자는 테스트 셋에 대한 정확도를 나타냅니다. 그리고 하나의 행은 1에폭(epoch)을 의미합니다. 에폭을 진행할수록 정확도가 높아지는 것을 확인할 수 있습니다! 1234567891011121314151617[1] 0.9048 0.9059[1] 0.9228 0.9247[1] 0.9355833 0.9343000[1] 0.9436167 0.9416000[1] 0.9496167 0.9470000[1] 0.9563167 0.9519000[1] 0.9602167 0.9555000[1] 0.9629167 0.9558000[1] 0.9664833 0.9603000[1] 0.9680333 0.9619000[1] 0.9711167 0.9635000[1] 0.97315 0.96520[1] 0.97445 0.96570[1] 0.9754167 0.9659000[1] 0.9771167 0.9698000[1] 0.9779 0.9679[1] 0.9776833 0.9680000","link":"/2020/05/12/project1-4/"},{"title":"JavaScript 객체 지향[1] - this&#x2F;constructor&#x2F;prototype","text":"자바스크립트는 객체지향 스크립트 언어이다. 객체지향을 내 기준에서 간단하게 설명하면 자주 사용하는 걸 구조화해놓는 것이다. 그러면 필요할 때마다 만들지 않아도 되고 이미 만들어진 걸 가져다 쓰기만 하면 된다. 여기서 미리 만들어 놓는다는 개념이 자바스크립트에서는 함수,클래스가 된다. 자바스크립트가 객체지향 언어인 만큼 객체 관련 기능들을 제공한다. 이번에는 this, constructor, prototype을 알아본다. *생활 코딩 javascript 객체지향 내용을 공부하며 정리한 것입니다. 1.this 자신을 가리키는 특수한 키워드로 오브젝트, 클래스 안에서 선언한 변수 및 함수를 자기 안에서 호출할 때 사용한다. 12345678910111213141516171819202122var fisrt = 5;var second = 10;var kim = { name:\"kim\", first:10, second:20, sum:function(){ return this.first+this.second; }};var lee = { name:\"lee\", first:10, second:20, sum:function(){ return first+second; }}; console.log(\"kim.sum()\", kim.sum()); //kim.sum() 30 console.log(\"lee.sum()\", lee.sum()); //lee.sum() 15 위 코드를 보면 kim은 오브젝트로써 name과 점수를 나타내는 first, second, 그리고 그 합계를 구하게 해주는 sum()이 있다. kim의 합계를 알고 싶을 때는 kim의 메서드 함수인 sum()을 호출해서 확인하면 된다. (= kim.sum()) sum()을 살펴보면, first, second 변수를 더한 값을 리턴하는데, 이 때 first, second 앞에 this가 붙어서 객체 안의 first, second 임을 명시하고 있다. 그렇기 때문에 리턴 값은 30 이 된다. 반면에, lee의 sum() this 없이 first와 second의 합을 리턴하고 있는데 결과 값은 30이 아닌 15가 된다. lee 내의 first와 second가 아닌 전역변수의 fisrt, second의 합을 구했기 때문이다. 생성자(constructor) 만약 kim,lee 처럼 똑같은 구조를 가진 변수가 1억 개 필요하다고 한다면 1억 번 다 똑같이 정의해야 할까? 결국 1억 번을 다 정의했는데 3번째 점수인 third가 생긴다면 각각의 변수에 third를 추가하는 1억 번의 작업을 해야 할까? 같은 구조의 변수라면 구조를 미리 정의해놓고 가져다 쓸 수 있는데 그 방법이 constructor이다. 12345678910111213function Person(name, first, second){ this.name=name; this.first=first; this.second=second; this.sum = function(){ return this.first+this.second; }}var kim = new Person('kim', 10, 20);var lee = new Person('lee', 10, 10);console.log(\"kim.sum()\", kim.sum()); //kim.sum() 30console.log(\"lee.sum()\", lee.sum()); //lee.sum() 20 먼저, 같은 구조를 정의하는 Person 함수를 만든다. 구조는 같아도 이름,점수는 다르기 때문에 값을 받는 파라미터도 추가한다. 그리고 Person 앞에 new를 붙이고 변수를 선언하면 된다. new를 붙이면 새로운 객체를 생성하는 생성자 함수가 된다. 즉, 함수로 객체를 생성한다는 말은 생성자 함수로 선언한다와 같다고 보면 된다. third를 추가하고 싶으면 Person 내에다가 한 번만 추가하면 된다. prototype 앞서 정의한 Person 함수에 new를 붙이면 함수로 객체(kim, lee)를 생성할 수 있었다. 그런데 생성자 함수를 호출할 때마다 공통적으로 사용하는 sum()을 계속 생성하는데, 이는 메모리를 차지하게 된다. 공통적으로 사용하는 함수는 한 번만 선언하어 좋지 않을까? 이럴 때 사용해 볼 수 있는 것이 prototype이다. 1234567891011121314151617function Person(name, first, second, third){ this.name=name; this.first=first; this.second=second; } Person.prototype.sum = function(){ return 'prototype : '+(this.first+this.second);} var kim = new Person('kim', 10, 20);kim.sum = function(){ return 'this : '+(this.first+this.second);}var lee = new Person('lee', 10, 10);console.log(\"kim.sum()\", kim.sum());console.log(\"lee.sum()\", lee.sum()); 위 코드처럼 prototype을 사용해 sum 함수를 정의하면 된다. 그런데 저렇게 하면 Person에 sum()이 추가돼서 똑같아지는 거 아닌가 생각했는데, 확인해보니 아래와 같았다. sum을 추가하고 나서 다시 확인해봤을 때 sum이 추가되지는 않았다…! 호오… 하지만 Person의 prototype을 확인해 보면, sum()이 정의되어 있다. 이 부분을 간단하게 설명하면 함수를 생성할 때 함수의 prototype object도 같이 생성되는데 생성자 함수로 만들어진 객체도 이 prototype에 접근할 수 있다. 그렇기 때문에 prototype의 속성을 사용할 수 있는 것이다. 여기서는 sum()이 된다. 생성자 함수로 객체가 여러 개 만들어져도 하나의 prototype을 공유하고 있기 때문에 공통적으로 적용할 수 있고 메모리를 객체 개수만큼 사용하지 않는다. prototype은 내용이 많아 보여서 좀 더 알아봐야겠다.","link":"/2020/04/12/book2-3/"},{"title":"순전파를 사용하여 모델 학습하기","text":"순전파법을 사용하여 손글씨 추론 모델을 만들어보겠습니다. 순전파법의 기본 원리는 손실함수 값을 최소화 시키는 것입니다. 손실함수 값을 최소화 시키는 방법으로는 경사하강법(SGD)를 사용합니다. 순전파의 기본 설명은 다음 링크를 참고하세요. 신경망 학습하기-1 (손실함수, 교차엔트로피오차) CH5. 신경망 학습하기-2 (경사하강법) 먼저, 학습할 네트워크를 만듭니다. W1,W2는 각 층별 가중치이며 b1,b2는 편향 값을 의미합니다. 12345678TwoLayerNet &lt;- function(input_size, hidden_size, output_size, weight_init_std = 0.01) { W1 &lt;- weight_init_std * matrix(rnorm(n = input_size*hidden_size), nrow = input_size, ncol = hidden_size) b1 &lt;- matrix(rep(0,hidden_size), nrow = 1, ncol = hidden_size) W2 &lt;- weight_init_std * matrix(rnorm(n = hidden_size*output_size), nrow = hidden_size, ncol = output_size) b2 &lt;- matrix(rep(0,output_size),nrow = 1, ncol = output_size) return (list(W1 = W1, b1 = b1, W2 = W2, b2 = b2))} TwoLayerNet 네트워크는 아래와 같이 은닉층을 1개 갖습니다. 입력층에서 input_size 개수만큼의 노드를 갖고 은닉층에서는 hidden_size 개수만큼의 노드, 출력층에서는 output_size만큼의 노드를 갖습니다. W1과 b1은 입력층에서 은닉층으로 갈 때의 가중치와 편향이며 W2와 b2는 은닉층에서 출력층으로 갈 때 사용하는 가중치와 편향입니다. 그리고 weight_init_std는 가중치 초기값이 큰 값이 되는 것을 방지하는 파라미터입니다. 다음으로, 데이터를 불러오고 트레이닝 셋과 테스트 셋으로 분류합니다. 데이터는 MNIST 라이브러리의 손글씨 이미지입니다. R에서는 dslabs를 임포트합니다. 1234567891011121314library(dslabs)source(\"./functions.R\")source(\"./utils.R\")source(\"./model.R\")init &lt;- function(){ mnist_data &lt;- get_data() #손글씨 데이터 x_train_normalize &lt;&lt;- mnist_data$x_train x_test_normalize &lt;&lt;- mnist_data$x_test #정답 레이블 t_train_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_train,60000, 10) t_test_onehotlabel &lt;&lt;- making_one_hot_label(mnist_data$t_test,10000, 10)} 손실함수는 교차엔트로피오차 함수를 사용합니다. 교차엔트로피오차 함수는 아래와 같이 구현합니다. 1234567891011121314model.forward &lt;- function(x){ z1 &lt;- sigmoid(sweep((x %*% network$W1),2, network$b1,'+')) return(softmax(sweep((z1 %*% network$W2),2, network$b2,'+')))}cross_entropy_error &lt;- function(y, t){ delta &lt;- 1e-7 batchsize &lt;- dim(y)[1] return(-sum(t * log(y + delta))/batchsize)}loss &lt;-function(x,t){ return(cross_entropy_error(model.forward(x),t))} 기본 교차엔트로피 함수식에 delta값을 추가하였는데, 이는 log0이 되면 -Inf가 되는 문제를 방지하기 위해서 입니다. 다음으로 경사하강법은 손실함수 값을 최소화 시키기 위해 사용합니다. 12345678910111213141516171819202122numerical_gradient_W &lt;- function(f,x,t,weight){ h &lt;- 1e-4 vec &lt;- matrix(0, nrow = nrow(network[[weight]]) ,ncol = ncol(network[[weight]])) for(i in 1:length(network[[weight]])){ origin &lt;- network[[weight]][i] network[[weight]][i] &lt;&lt;- (network[[weight]][i] + h) fxh1 &lt;- f(x, t) network[[weight]][i] &lt;&lt;- (network[[weight]][i] - (2*h)) fxh2 &lt;- f(x, t) vec[i] &lt;- (fxh1 - fxh2) / (2*h) network[[weight]][i] &lt;&lt;- origin } return(vec)}numerical_gradient &lt;- function(f,x,t) { grads &lt;- list(W1 = numerical_gradient_W(f,x,t,\"W1\"), b1 = numerical_gradient_W(f,x,t,\"b1\"), W2 = numerical_gradient_W(f,x,t,\"W2\"), b2 = numerical_gradient_W(f,x,t,\"b2\")) return(grads)} 마지막으로 학습시키는 함수입니다. 123456789101112131415161718192021222324252627train_model &lt;- function(batch_size, iters_num, learning_rate, debug=FALSE){ #seperate train, test data init() train_size &lt;- dim(x_train_normalize)[1] iter_per_epoch &lt;- max(train_size / batch_size) for(i in 1:iters_num){ batch_mask &lt;- sample(train_size,batch_size) x_batch &lt;- x_train_normalize[batch_mask,] t_batch &lt;- t_train_onehotlabel[batch_mask,] grad &lt;- numerical_gradient(loss, x_batch, t_batch) network &lt;&lt;- sgd.update(network,grad,lr=learning_rate) if(debug){ if(i %% iter_per_epoch == 0){ train_acc &lt;- model.evaluate(model.forward, x_train_normalize, t_train_onehotlabel) test_acc &lt;- model.evaluate(model.forward, x_test_normalize, t_test_onehotlabel) print(c(train_acc, test_acc)) } } train_accuracy = model.evaluate(model.forward, x_train_normalize, t_train_onehotlabel) test_accuracy = model.evaluate(model.forward, x_test_normalize, t_test_onehotlabel) return(c(train_accuracy, test_accuracy)) }} train_model()함수 중간에 sg.update()함수는 경사하강법으로 변경된 가중치를 업데이트하는 역할을 합니다.코드는 아래와 같습니다. 1234sgd.update &lt;- function(network, grads, lr = 0.01){ for(i in names(network)){network[[i]] &lt;- network[[i]] - (grads[[i]]*lr)} return(network)} 이제 모든 준비를 마쳤습니다. 네트워크를 생성한 후 모델을 학습시켜봅니다. 12network &lt;&lt;- TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)train_model(100, 10000, 0.1, TRUE)","link":"/2020/05/04/project1-3/"},{"title":"게시글","text":"5월 게시글 DNS와 작동원리 HTTP 1장 HTTP 2장 6월 게시글 HTTP 5장 CORS 8월 게시글 메모리 관리 IPC","link":"/2020/05/04/project2-1/"},{"title":"제네릭 뷰(Generic View) 살펴보기","text":"장고의 제네릭 뷰를 살펴보고 예제를 작성해 보자. 장고는 모델(Model), 템플릿(Template), 뷰(View)로 구성된 MTV패턴 웹프레임워크이다.이 중 뷰는 사용자 요청을 처리하고 응답을 반환하는 역할을 한다.뷰는 함수로도, 클래스로도 구현할 수 있는데, 클래스로 구현하면 제네릭 뷰를 사용할 수 있다. 뷰를 작성하며, 제네릭 뷰의 역할 과 종류, 믹스인 뷰 등을 살펴보자! 제네릭 뷰(Generic View)제네릭 뷰는 장고에서 기본적으로 제공하는 뷰 클래스를 의미한다. 용도에 따라 다양한 제네릭 뷰를 제공하고 있으며, 우리는 이 제네릭 뷰를 상속하고 메서드를 재정의하여 좀 더 편리하게 작업할 수 있다.제너릭 뷰에는 용도에 따라 ListView, DetailView, FormView, TemplateView 등이 있는데, 전부 View 클래스를 상속받고 있다. 그렇기 때문에 View 클래스 메서드를 이해하면, 다른 제너릭 뷰들의 공통 메서드도 이해할 수 있을 것이다. View앞서 언급했듯이, 다른 제너릭 뷰가 상속받는 기본 제너릭 뷰이다. 메서드는 다음과 같다. 1. setup(request, args, *kwargs)dispatch()전에 초기화를 수행한다. 이 메서드를 재정의하는 경우 super()를 호출해야 한다. 아래는 View에 정의된 setup() 코드이다. 12345def setup(self, request, *args, **kwargs): \"\"\"Initialize attributes shared by all view methods.\"\"\" self.request = request self.args = args self.kwargs = kwargs 2. dispatch(request, args, *kwargs)요청을 받고 HTTP 응답을 반환하는 메서드이다. GET 요청은 get()으로, POST 요청은 post() 메서드로 호출한다. 123456789def dispatch(self, request, *args, **kwargs): # Try to dispatch to the right method; if a method doesn't exist, # defer to the error handler. Also defer to the error handler if the # request method isn't on the approved list. if request.method.lower() in self.http_method_names: handler = getattr(self, request.method.lower(), self.http_method_not_allowed) else: handler = self.http_method_not_allowed return handler(request, *args, **kwargs) 3. http_method_not_allowed(request, args, *kwargs)뷰가 지원하지 않는 HTTP 메서드를 호출한 경우, http_method_not_allowed() 메서드가 대신 호출된다. 123456def http_method_not_allowed(self, request, *args, **kwargs): logger.warning( 'Method Not Allowed (%s): %s', request.method, request.path, extra={'status_code': 405, 'request': request} ) return HttpResponseNotAllowed(self._allowed_methods()) 4. options(request, args, *kwargs)HTTP OPTIONS 요청에 대한 응답을 처리한다. 123456def options(self, request, *args, **kwargs): \"\"\"Handle responding to requests for the OPTIONS HTTP verb.\"\"\" response = HttpResponse() response['Allow'] = ', '.join(self._allowed_methods()) response['Content-Length'] = '0' return response 기본 View 메서드를 살펴 보았으니, 다른 제너릭 뷰들을 살펴보자.","link":"/2021/05/16/project4-1/"},{"title":"2020 개발자 로드맵 따라가기 프로젝트!","text":"이것저것 구글링을 하다가 프론트엔드,백엔드,데브옵스 개발자를 위한 로드맵이 있다는 것을 알게 되었습니다. 무엇을 공부할지, 무엇부터 공부할지, 그리고 내가 부족한게 무엇인지 잘 모르겠다면 이 로드맵을 한번 훑어보시는걸 추천드립니다. 로드맵을 살펴보니 들어는 봤어도 개념을 명확하게 모르는게 많더라구요 ㅠ.ㅠ 그래서 저도 로드맵을 따라 공부해보려 합니다!저는 프론트엔드 로드맵 1/3, 백엔드 로드맵 1/3부터 공부해 나갈 예정입니다. 공부 내용은 블로그에 올리도록 하겠습니다. 같이 공부해요.:) 로드맵 링크 : https://github.com/devJang/developer-roadmap로드맵 공부 : https://roadmap.sh/frontend/resources","link":"/2020/05/01/project2/"},{"title":"static 파일 캐시 처리하기","text":"templatetags를 사용하여 static 파일이 캐시되는 이슈를 해결합니다. 유지 보수 작업을 하고 서버에 배포 했는데, 정적(static) 파일(js, css..)들이 바로 반영되지 않는 이슈가 있다. 그 이유는 파일들이 캐시 처리되었기 때문이다. 캐시된 파일들은 로컬에서 가져오기 때문에 서버에 배포해도 반영되지 않는다. 이 문제를 해결하기 위해서는 새로운 파일이라는 표시를 해주어야 한다. 아래와 같이 파라미터를 추가하면 캐시된 파일을 사용하지 않고 서버에서 가져온다. 1&lt;script src=\"https://static.velog.io/static/js/20.c4f442fa.chunk.js?v=&lt;RANDOM_NUM&gt;👈\"&gt;&lt;/script&gt; 배포 시마다&lt;RANDOM_NUM&gt;을 달리하면, 캐시로 인해 반영되지 않는 문제를 해결할 수 있다. 그렇다면 장고에서는 이 처리를 어떻게 하는게 좋을까? 새로운 정적 파일을 로드할 때마다 파라미터를 추가할 수도 있지만, 장고에서 제공하는 tempatetags와 템플릿 태그인 static 태그를 사용하면 좀 더 간단하게 해결할 수 있다. static 태그를 사용하여 파일을 로드하면 자동으로 파라미터가 붙도록 작업할 것이다.이 작업은 정적 파일을 아래와 같이 static 태그로 로드한다는 전제가 필요하다. 1&lt;script src=\"{% static js/20.c4f442fa.chunk.js %}\"&gt;&lt;script&gt; templatetagstempatetags는 장고에서 커스텀 템플릿 태그를 만들 때 사용한다. app 하위에 templatetags 폴더를 만들고 폴더 하위에 파일을 정의하면 된다. 12345678910111213141516.├── app│ ├── migrations│ ├── templatetags 👈│ └── views│ ├── __init__.py│ ├── admin.py│ ├── apps.py│ ├── models.py├── djangoseries│ ├── __init__.py│ ├── __pycache__│ ├── settings.py│ ├── urls.py│ └── wsgi.py└── manage.py static 템플릿 태그 커스텀하기templatetags 폴더 하위에 static.py를 만든다. 그리고 아래와 같이 코드를 작성한다. 1234567891011121314151617#templatetags/static.pyfrom django import templatefrom django.templatetags.static import StaticNoderegister = template.Library()class CustomStaticNode(StaticNode): def url(self, context): version = #랜덤 값으로 하거나 날짜로 작업할 수 있음. path = f'{super().url(context)}?v={version}' return path@register.tag('static')def do_static(parser, token): node = CustomStaticNode.handle_token(parser, token) return node register = template.Library() : Library에 등록하기 위해 register를 선언해야 한다. @register.tag('static') : static태그 호출 시, 아래 함수를 호출하고 결과를 반환한다. ** 코드 출처 코드는 단순한데, 장고에서 기본적으로 제공하는 static 태그의 StaticNode 클래스를 상속 받아 CustomStaticNode로 재정의 하는 것이다. 부모 url() 메서드의 url을 받고 ?v={version}를 추가해서 새로 반환한다. StaticNode의 url()메서드는 아래와 같다. 12345class StaticNode(template.Node): ... def url(self, context): path = self.path.resolve(context) return self.handle_simple(path) 그리고 기존 static 태그는 아래와 같이 태그를 등록하였다. 12345678910111213@register.tag('static')def do_static(parser, token): \"\"\" Join the given path with the STATIC_URL setting. Usage:: {% static path [as varname] %} Examples:: {% static \"myapp/css/base.css\" %} {% static variable_with_path %} {% static \"myapp/css/base.css\" as admin_base_css %} {% static variable_with_path as varname %} \"\"\" return StaticNode.handle_token(parser, token) 마찬가지로, 기존 static 등록 코드에서 StaticNode 대신, CustomStaticNode로 변경해 주면 된다! 파라미터 값의 경우, 호출할 때마다 값이 바뀌면 파일 변경이 없어도 서버에서 파일을 계속 새로 받기 때문에 날짜로 하거나 다른 파일에 파라미터 값을 따로 관리하는 방식을 추천하는 바이다. 끝!","link":"/2021/05/16/project4-2/"},{"title":"요청에서 응답까지의 프로세스 살펴보기","text":"장고에서 요청을 받고 응답하기까지의 프로세스를 살펴보자. 아래 이미지는 프로세스를 도식화했다. 요청을 받으면 가장 먼저 웹 애플리케이션 서버인 wsgi 서버를 만난다. 1. WSGIWSGI는 웹 서버(apache, nginx)와 장고 프로젝트 간의 중계 역할을 한다. 웹 서버에서의 명령을 프레임워크가 이해할 수 없으니 그 사이를 메꿔주는 역할을 하는 것이다. gunicorn나 uWSGI가 wsgi 서버들이다. wsgi 서버에서 요청을 처리하기 위해 애플리케이션을 실행하고, 애플리케이션이 처리한 응답을 반환하는 역할을 한다. wsgi 서버는 보통 운영에서 사용되며 개발할 때는 runserver 명령어로 대신한다. 장고 내장 서버 (runserver)는 단일 프로세스를 사용하기 때문에 운영보다는 디버깅에 적합하다. 운영에서는 멀티프로세싱이 가능한 gunicorn이나 uWSGI등을 사용하여 많은 트래픽을 처리할 수 있도록 한다. 2. MiddlewareMiddleware는 뷰에서 요청 받기 전, 사용자에게 응답을 넘기기 전 등에 호출되어 다양하게 사용된다. 미들웨어를 활성화하기 위해서는 settings.py에 MIDDLEWARE를 추가한다. 아래는 예시 값이다. 123456789101112#공식 문서 참고#https://docs.djangoproject.com/en/3.1/topics/http/middleware/MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware',] 요청이 발생하면, wsgi 핸들러는 settings.py 파일을 임포트하고 MIDDELWARE를 찾아 모든 미들웨어 클래스를 로드한다. 미들웨어에서 다음과 같은 메서드 등을 사용할 수 있다. process_request -요청이 들어오자 마자 처리하는 메서드(로그인 여부 확인 등) -process_request 응답 후, urls.py에서 요청을 처리할 뷰를 찾는다. process_view: -뷰를 확인한 후, 뷰(views.py)에 접근하기 전에 호출 되는 메서드(csrf확인 등) -None(뷰 호출) 또는 HttpResponse(그대로 응답) 반환 process_exception -process_view에서 예외를 발생시키면 호출되는 메서드 process_tempate_response 응답 객체에 render 메서드가 있는 경우에 호출되는 메서드 process_response 뷰에서 반환된 객체를 응답하기 전에 호출되는 메서드 3. View요청을 처리하고 응답 객체HttpRequest를 반환하는 것은 뷰이다. 뷰에서 DB를 읽거나 하여 요청에 필요한 처리를 한다. 템플릿을 반환하는 경우 아래처럼 render()를 포함하여 응답한다. 12...return HttpResponse(template.render(context, request)) 4. Template템플릿은 html을 반환한다. 템플릿 경로는 settings.py에서 아래와 같이 지정할 수 있다. 12345678910111213#공식 문서 참고#https://docs.djangoproject.com/ko/3.1/topics/templates/TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [], 'APP_DIRS': True, 'OPTIONS': { # ... some options here ... }, },] BACKEND -템플릿 엔진 API 지정. 기본 옵션으로는 django.template.backends.django.DjangoTemplates와 django.template.backends.jinja2.Jinja2 가 있음 DIRS : template 디렉토리 위치 APP_DIRS : 엔진이 설치된 애플리케이션 내에서 템플릿 소스 파일을 찾을지에 대한 여부 마지막으로 미들웨어의 process_response까지 호출하고 나면 응답을 반환한다. 끝!요청부터 응답까지 프로세스를 간략하게 살펴 보았는데, 상세 내용은 시리즈로 계속 추가할 예정이다. 끝! 참고 : https://medium.com/@adamking0126/django-middlewares-and-the-request-response-cycle-fcbf8efb903f","link":"/2021/05/16/project4/"},{"title":"프로젝트 App이 여러 개일 때 URL 분기 처리하기","text":"앱이 여러 개 있을 때, URL에 따라 앱 별로 요청을 전달하는 방법에 대해 살펴보자. 장고의 한 프로젝트 안에는 여러 개의 앱을 만들 수 있다. 아래처럼 만들고 싶은 앱의 개수만큼 명령어를 실행해주면 된다. 123$ python manage.py startapp blogs$ python manage.py startapp reviews$ python manage.py startapp polls 이번 포스팅에서는 앱이 여러 개 있을 때, URL에 따라 앱 별로 요청을 전달하는 방법에 대해 살펴볼 것이다. 프로젝트에는 아래와 같이 3개의 앱(blogs, polls, reviews)이 있다. 1234567.└── mysite ├── blogs ├── manage.py ├── mysite ├── polls └── reviews 앱을 추가한 뒤에는 INSTALLED_APP에 앱 config 정보를 추가해야 한다. config 명은 앱 하위의 apps.py를 확인하면 된다. 123456INSTALLED_APPS = [ ... 'blogs.apps.BlogsConfig', 'polls.apps.PollsConfig', 'reviews.apps.ReviewsConfig'] 방법1. PATH로 분기 처리앱별로 시작하는 PATH를 다르게 하여 분기 처리할 수 있다.각각의 앱 디렉토리 하위에 urls.py를 두고 프로젝트 세팅 디렉토리인 mysite에도 urls.py가 있어야 한다. 12345678910111213# mysite/urls.pyfrom django.contrib import adminfrom django.urls import path, includefrom xcapp.views import *from django.contrib.auth import views as auth_viewsurlpatterns = [ path('admin/', admin.site.urls), path('blogs/', include('blogs.urls')), path('polls/', include('polls.urls')), path('reviews/', include('reviews.urls'))] 앱 별로 blogs, polls, reviews라는 프리픽스를 설정하여, 해당 PATH로 시작하는 요청이 들어오면 앱 하위의 urls.py를 임포트하는 방식이다. 앱 별 urls.py는 아래와 같을 것이다. 123456789#polls/urls.pyfrom django.urls import pathfrom polls.views import *urlpatterns = [ path('', IndexView.as_view(), name='polls'), #127.0.0.1:8000/polls/ path('test/', TestView.as_view(), name='polls_test'), #127.0.0.1:8000/polls/test/] 확인해보면, 아래와 같이 잘 처리되는 것을 확인할 수 있다. 방법2. 도메인으로 분기 처리 - Middleware다음은 Middleware를 사용하여 앱 별로 다른 도메인을 두는 방법을 소개한다.장고 공식 문서의 요청을 처리하는 법을 살펴보면 아래와 같이 나와있다. Django는 사용할 루트 URLconf 모듈을 결정합니다. 일반적으로 이것은 ROOT_URLCONF설정 의 값 이지만 들어오는 HttpRequest개체에 urlconf 속성 (미들웨어에 의해 설정 됨)이있는 경우 해당 값이 ROOT_URLCONF설정 대신 사용됩니다 . 기본적으로 ROOT_URLCONF 설정 값을 사용하지만 HttpRequest에 urlconf 속성이 있으면, ROOT_URLCONF 대신에 사용한다고 설명하고 있다. 이 같은 처리 방식을 사용하여 미들웨어에서 도메인을 확인하고, 도메인에 따라 urlconf 값을 지정할 것이다. 먼저, settings.py에 앱 별 도메인을 정의한다.(도메인 대신 로컬호스트로 테스트하는 경우, 포트를 달리하여 확인할 수 있습니다.) 12345#mysite/settings.pyBLOGS_DOMAIN = 'blog-dev.com'REVIEWS_DOMAIN = 'reviews-dev.com'POLLS_DOMAIN = 'polls-dev.com' ALLOWED_HOST에도 해당 도메인을 추가한다. 1ALLOWED_HOSTS = [BLOGS_DOMAIN, REVIEWS_DOMAIN, POLLS_DOMAIN] 그리고 나서, 미들웨어(Middleware)를 작성한다. 미들웨어 명은 VirtualHostMiddleware로 두었다. 1234567891011121314151617181920#mysite/middlewares/virtualhostmiddleware.pyfrom django.conf import settingsvirtual_hosts = { settings.BLOGS_DOMAIN : 'blogs.urls', settings.REVIEWS_DOMAIN : 'reviews.urls', settings.POLLS_DOMAIN : 'polls.urls' }class VirtualHostMiddleware: def __init__(self, get_response): self.get_response = get_response def __call__(self, request): host = request.get_host() request.urlconf = virtual_hosts.get(host) response = self.get_response(request) return response 미들웨어는 request 전/후, response 전/후에 호출되어 요청 및 응답에 대한 후크 프레임 워크이다.self.get_response() 전후로 요청에 대한, 응답에 대한 처리를 할 수 있다. 우리가 해야할 것은 도메인에 따른 분기처리 이므로 view를 호출하기 전에 작업이 필요하다. 그러므로 self.get_response(request) 전에 작업을 처리한다.코드가 짧으니 살펴보면,request의 get_host()메서드로 요청한 도메인 명을 가져온 뒤, 호스트 별 url 모듈을 urlconf 값으로 지정한다.정말 간단하다! 새로 작성한 미들웨어는 settings.py에 추가해 준다.미들웨어는 리스트에 정의된 순서대로 미들웨어를 적용하기 때문에 순서를 고려해야 하는데, 도메인에 따른 분기처리가 필요하기 때문에 맨 위에 두었다. SSL을 적용하는 경우 SecuretiryMiddleware를 가장 위에 두라니, 2번 째에 두는게 나을 수 것 같기도 하다. 1234567891011MIDDLEWARE = [ 'mysite.middlewares.virtualhostmiddleware.VirtualHostMiddleware', ... 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware',] 도메인으로 호출해 보면, 프리픽스 없이도 분기 처리되는 것을 확인할 수 있다. 최종 프로젝트 구조 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950.├── blogs│ ├── __init__.py│ ├── admin.py│ ├── apps.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── templates│ │ └── blogs│ │ └── index.html│ ├── tests.py│ ├── urls.py│ └── views.py├── db.sqlite3├── manage.py├── mysite│ ├── __init__.py│ ├── asgi.py│ ├── middlewares│ │ └── virtualhostmiddleware.py│ ├── settings.py│ ├── urls.py│ └── wsgi.py├── polls│ ├── __init__.py│ ├── admin.py│ ├── apps.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── templates│ │ └── polls│ │ └── index.html│ ├── tests.py│ ├── urls.py│ └── views.py└── reviews ├── __init__.py ├── admin.py ├── apps.py ├── migrations │ └── __init__.py ├── models.py ├── templates │ └── reviews │ └── index.html ├── tests.py ├── urls.py └── views.py 정리하며장고 프로젝트에 앱이 여러개일 때 PATH 별로, 도메인 별로 분기 처리하는 방법을 살펴 보았다. PATH 별은 간단하지만, 도메인 별로 분기처리 하는 방법의 경우, 로컬에서 개발 작업을 진행할 때 앱의 개수 만큼 포트를 열어줘야 돼서 번거로움이 생길 수 있다. 그래서 개발할 때는 PATH로, 스테이징/운영 환경에 배포할 때는 도메인 별로 사용하는 방법도 괜찮을 것 같다.settings.py 대신, settings/dev.py 와 settings/prod.py로 환경을 나누고 prod.py에서만 미들웨어를 사용하게 하는 것이다. 개발 환경에서는 ROOT_URLCONF 값인 mysite.url 를 그대로 사용하기 때문에, 프리픽스로 URL에 접근할 수 있을 것이다. 끝:)","link":"/2021/05/16/project4-3/"},{"title":"CORS(Cross Origin Resource Sharing)","text":"&lt;리얼월드 HTTP&gt; 도서의 내용을 요약 정리하고 관련 내용을 추가하였습니다. CORS란, 오리진(출처, 도메인) 사이에 리소스(자원)를 공유하는 방법을 말한다. 여기서 리소스 공유는 XMLHttpRequest나 Fetch API를 통하여 다른 출처의 자원에 접근하는 것이다. 보안을 위해 모든 서버에서 누구나 접근하는 것을 막고 클라이언트에서 서버로 액세스하기 직전까지의 권한을 확인한다. 보안 상의 이유로, 브라우저는 스크립트에서 시작한 서로 다른 출처의 HTTP 요청을 제한한다. XMLHttpRequest와 Fetch API를 사용하는 웹 애플리케이션은 자신의 출처와 동일한 리소스만 불러올 수 있으며, 예외적으로 다른 출처의 리소스를 불러오려면 자신의 출처를 증명할 수 있는 올바른 CORS 헤더를 포함해야 한다. CORS에는 프리플라이트 요청을 하지않는 simple cross-origin request와 프리플라이트 요청이 필요한 actual request로 나뉜다. 프리플라이트(prefligt) 요청은 실제 통신 전에 권한을 확인하려 보내는 요청이다. Simple Cross-Origin Requestsimple cross-origin request가 되는 조건은 다음 3가지이다. http 요청 메서드가 단순 메서드(GET, POST, HEAD) 헤더가 모드 심플 헤더(accept, accept-language, content-language, content-type 이외는 제외) Content-type을 포함하는 경우, 그 값이 applicatin/x-www-form-urlencoded, multipart/form-data, text-plain 중 하나 프리플라이트 요청simple cross-origin request 조건에 맞지 않는 경우 프리플라이트 요청이 필수이다. 프리플라이트를 할 때 클라이언트는 아래 헤더를 붙여 OPTIONS메서드로 전송한다. Access-control-request-method 요청헤더 : 통신을 허용하길 원하는 메서드 지정 Access-control-reqeust-headers 요청 헤더: 허용하길 원하는 헤더를 쉼표로 구분해 나열 Origin 요청 헤더 : 통신 출처 웹 페이지의 도메인 이름을 지정 프리플라이트 요청을 받고 나면, 서버측은 허용하는 통신 내용을 아래 헤더를 사용해 브라우저 측에 전달한다. 허용하지 않는 경우 각각의 헤더가 부여되지 않거나 stauts = 401 forbidden으로 반환되기도 한다. Access-control-allow-origin 응답헤더 : 통신을 허용할 오리진 이름. 쿠키를 이용하지 않을 때는 와일드카드(*)로 모든 도메인을 일괄적으로 허용하기도 한다. Access-control-allow-method 응답헤더 : 대상 url에 허용되는 메서드 이름. Access-control-allow-header 응답헤더 : 대상 url에 허용되는 헤더 이름 목록. 플라이트요청이 필요없는 간단한 헤더는 생략될 수 있다. Access-control-allow-credentials 응답헤더: 쿠키 등의 자격 증명을 서버가 받는 것을 허용할 때 부여된다. 값으로는 true만 설정할 수 있다. Access-control-expose-header 응답헤더 : 허용이 아니라 서버에서 반환하는 응답 헤더 중 스크립트에서 참조할 수 있는 헤더 이름목록을 반환한다. 통신 내용을 일정 기간 캐시해서 통신을 생략하는 방법도 사양에 포함되어 있다. 이 지시에는 다음 헤더를 사용한다. Access-control-max-age 응답 헤더 : cahce-control을 사용한 캐시와 마찬가지로 캐시 가능한 초 수를 서버에서 클라이언트로 전달한다. 프리플라이트 요청이 허용되면 실제 요청을 전송한다. 참고https://developer.mozilla.org/ko/docs/Web/HTTP/CORS","link":"/2020/06/06/study1-2/"},{"title":"DNS와 작동원리","text":"DNS에 대해 알아보자. DNS는 Domanin Name System의 약자로, IP주소를 도메인으로 변환하고 도메인을 IP주소로 변환함으로써 통신하게 하는 시스템입니다.온라인 상의 네트워킹을 하는 모든 단말은 IP주소를 갖고 있고 이 IP를 통해 서로 통신합니다. 참고: IP주소는 인터넷에 내 IP라고 검색하면 확인할 수 있습니다. IP주소는 숫자로 되어있기 때문에 이를 하나씩 기억하고 사용하기란 매우 불편합니다. 그래서 IP주소에 도메인 네임을 붙여서 통신하게 합니다. 네이버에 접근할 때, IP주소가 아닌 www.naver.com 이라고 치는 것처럼 말이죠.여기서 naver.com이 네이버의 도메인입니다. 도메인의 IP주소는 nslookup명령어로 확인할 수 있습니다. 1234567891011121314 $ nslookup naver.comServer: 8.8.8.8Address: 8.8.8.8#53Non-authoritative answer:Name: naver.comAddress: 125.209.222.142Name: naver.comAddress: 125.209.222.141Name: naver.comAddress: 210.89.160.88Name: naver.comAddress: 210.89.164.90 결과에 대한 IP주소로 접근 시, 네이버로 접속되는 것을 확인할 수 있습니다. 정리하면, 사용자가 www.naver.com을 치면 DNS 서버는 도메인에 해당하는 IP주소를 찾고 IP주소로 서버에 접속하게 되는 것이죠. 동작원리구체적인 DNS 동작원리를 살펴보겠습니다. 사용자가 www.example.com을 주소창에 입력합니다. 서버에 접근하는 행위는 요청(request)이라고 표현합니다. 가장 먼저, Local DNS 정보를 확인합니다. Local DNS에 정보가 없으면 도메인을 DNS루트 이름 서버에 질의합니다. DNS루트 이름 서버로부터 .com 도메인을 관리하는 TLD(Top-Level Domain) 서버 정보를 전달받고, TLD 서버에 다시 질의하게 됩니다. TLD 서버로부터 example.com 정보를 관리하는 도메인 서버 정보를 받고, 해당 서버로 부터 도메인에 ip주소를 취득하게 됩니다. IP주소로부터 응답받고 웹브라우저에 페이지를 표시합니다. 이처럼 루트 도메인 서버부터 차례대로 질의하며 도메인의 IP주소를 취득하는 것을 쿼리라고 합니다. 서버에 질의하기 전 Local DNS 먼저 확인을 하는데, 이 정보는 /etc/hosts에서 확인 가능합니다. 1234567891011$ vi /etc/hosts### Host Database## localhost is used to configure the loopback interface# when the system is booting. Do not change this entry.##127.0.0.1 localhost255.255.255.255 broadcasthost::1 localhost 우리가 127.0.0.1 또는 localhost라고 둘 다 사용가능했던 것도 Local DNS에 등록되어 있었기 때문입니다. 또한 우리가 특정 IP를 도메인으로 접속하고 싶다면 /etc/hosts에다 등록하면 됩니다. 단, 본인 PC에 한정되서 사용 가능합니다. 123456789101112$ vi /etc/hosts### Host Database## localhost is used to configure the loopback interface# when the system is booting. Do not change this entry.##127.0.0.1 localhost255.255.255.255 broadcasthost::1 localhost123.45.67.78 naver.com 이처럼 naver.com 도메인을 Local DNS에 특정 IP로 등록해 놓으면, naver.com을 서버에 질의하기 전에 먼저 확인하므로, 네이버 페이지가 아닌 내가 설정한 IP주소로 접속하게 됩니다. 신기하죵?ㅎㅎ 앞서 로트 도메인/최상위 도메인(Top-Level Domain)을 언급했는데, 이 내용은 도메인 생성 규칙과 연관되어 있습니다. naver.com의 경우 com이 최상위 도메인입니다. 가장 오른쪽 레이블이 최상위 도메인이며, 도메인 naver.com은 최상위 도메인에 포함됩니다. 오른쪽에서 왼쪽으로 갈수록 그 범위가 좁아집니다. 예를들어, 네이버 지도는 네이버 서비스 중 하나이므로 map.naver.com으로 나타냅니다. 루드 도메인은 어떤 값을 지칭하는 것은 아니고 모든 도메인의 시작점으로 보시면 됩니다. 서브 도메인아직 설명하지 않은 www는 서브 도메인입니다. 서브 도메인이란, 메인 도메인에서 파생된 도메인으로 map.naver.com에서 naver가 메인 도메인, map이 서브 도메인이 됩니다. 다중의 웹서비스를 만들 때 주로 사용합니다. www의 경우, 메인 도메인 페이지로 접속하게 하는 서브 도메인이라고 보면 됩니다. CNAMECNAME은 하나의 도메인에 또다른 도메인을 추가하는 것입니다.예를 들어 살펴보겠습니다. 123.45.67.89 -&gt; test.com test.com -&gt; test2.com위의 경우처럼, 하나의 IP주소에 test.com도메인이 있음에도, test2.com을 추가해 test2.com 도메인으로부터 123.45.67.89의 응답을 받는것입니다. CNAME은 보통 기존의 도메인을 대체할 때 사용합니다. 예를 들어 AWS에서 인스턴스를 생성하면 인스턴스 도메인 주소는 amazonelinux~.com 이런식으로 되는데 이 주소를 보통 그냥 사용하지 않고 CNAME을 통해서 웹페이지에 적합한 도메인이름을 붙입니다.","link":"/2020/05/01/study1/"},{"title":"CGI 개념 및 설명","text":"CGI : Common Gateway Interface CGI 개념 설명초창기의 웹 서버는 단순히 클라이언트의 요청에 정적 파일을 응답했다. 하지만 이제는 동적인 사이트가 확대됨에 따라 PHP, Python 같은 애플리케이션으로 처리된다. 웹 서버는 요청을 받아 애플리케이션에 전달하고, 애플리케이션에서 요청을 처리한 후 응답을 웹 서버에 반환하며, 이 응답을 클라이언트에 보낸다. 이 처럼 웹 서버와 애플리케이션이 연동될 수 있도록 CGI 규약이 개발됐다. 즉, CGI는 웹 서버와 게이트웨이 애플리케이션 간에 정보를 교환할 방법을 기술한 규약이다. CGI의 동작 방식은 다음과 같은 결점을 가진다. 요청마다 새로운 프로세스를 생성하기 때문에 상태 정보가 요청과 요청 사이에 상실된다. 요청 수 만큼 프로세스가 생성되기 때문에 쉽게 부하가 발생한다. Fast CGICGI의 결점을 보완한 Fast CGI는 다음과 같은 개선점을 가진다. 영구적으로 지속되는 프로세스가 여러 요청을 처리하게 된다. 웹 서버와 게이트웨이 애플리케이션은 TCP나 IPC 소켓 같은 소켓을 사용해서 통신한다. 그렇기 때문에 두 컴퓨터로 분산 배치할 수 있다. 이어지는 요청에 대해 부가 생성하지 않고도 이어서 처리할 수 있다. 소켓 기반의 프로토콜인 만큼 어떤 언어를 사용해도 구현할 수 있다. uWSGI와 SCGIuWSGI 모듈은 엔진엑스와 애플리케이션이 uwsgi 프로토콜로 통신하게 해준다. uwsgi 프로토콜은 WSGI(웹 서버 게이트웨이 인터페이스)에서 파생됐다. WSGI는 웹 서버와 웹 애플리케이션의 인터페이스를 위한 파이썬 프레임워크이다.SCGI는 Simple Common Gateway Interface의 약자로, FastCGI와 유사하다.","link":"/2021/07/01/study10/"},{"title":"&lt;클린 코드&gt; 좋았던 내용 기록하기(1-3장)","text":"&lt; Clean Code &gt; 도서의 내용을 공부하며 요약 정리하였습니다. 1장. 깨끗한 코드시간에 쫓겨서 급하게 나쁜 코드를 짠 적이 있을 것이다. 나중에 다시 짜야지라는 생각으로 급하게 코드를 짜고는 하지만 나중은 오지 않는다. 깨끗한 코드를 짜기 위해서는 코드 감각이 필요하다. 깨끗한 코드란 그 정의도 다양하지만 대충의 의견은 다음과 같다. 논리가 간단해서 버그가 숨어들지 한다. 한 가지를 제대로 한다. 잘 쓴 문장처럼 읽힌다. 작성자가 아닌 사람도 읽기 쉽고 고치기 쉽다. 테스트 코드가 없는 코드는 깨끗한 코드가 아니다. 중복을 피해야 한다. 정리 : 중복을 피하라. 한 기능만 수행해라. 제대로 표현하라. 작게 추상화하라 2장. 의미있는 이름의도를 분명하게 밝혀라 Int d; ⇒ int daysSincedCreation; List ⇒ group, bunch 의미 있게 구분하라 차이를 알도록 이름을 지어야 한다. 나쁜 예시 : GetActiveAccount(), GetActiveAccounts(), GetActiveAccountInfo() 나쁜 예시2 : CustomerInfo/customer, accountdata/account 문자 하나만 사용하는 변수 이름은 문제가 있다. 루프에서 반복 횟수를 세는 i,j,k는 괜찮다(l은 절대 안됨). 단, 루프 범위가 아주 작고 다른 이름과 충돌하지 않을 때만 괜찮다. 해법 영역에서 가져온 이름을 사용하라 코드를 읽는 사람도 프로그래머이다. 그러므로 전산용어, 알고리즘 이름 등을 사용해도 괜찮다. 모든 명칭을 문제 영역에서 가져올 것이 아니라, 기술 개념에는 기술 이름을 가져오는 것이 가장 적합한 선택이다. 적합한 프로그래머 용어가 없을 때, 문제 영역에서 이름을 가져온다. ** 문제 영역이란, 코드를 짜려는 프로젝트에 쓰이는 명칭 들을 말하는 것으로 보임. 예를 들면, 금리 관련 프로젝트에서는 정액제, 만기 등을 사용하는 것. 의미있는 맥락을 추가하라예를 들어, firstName, city, street, houseNumber, state, zipcode라는 변수가 있다. 변수를 전체적으로 보면 주소라는 사실을 알 수 있지만 state변수 하나만으로는 쉽게 알아채기 어렵다. 이럴 때는 addr이라는 접두어를 추가해 addrFirstName, addrLastName, addrState라 쓰면 맥락이 좀 더 분명해진다. 3장. 함수작게 만들어라!함수를 만드는 첫째 규칙은 ‘작게!’다. 둘 째 규칙은 ‘더 작게!’이다. 함수는 100줄을 넘어서는 안된다. 20줄도 길다… 다시 말해, if문/else문/while문 등에 들어가는 블록은 한 줄이어야 한다는 의미이다. 대개 거기서 함수를 호출한다. 한 가지만 해라!충고 : 함수는 한 가지를 해야 한다. 그 한가지를 잘해야 한다. 그 한가지 만을 해야한다. 이 충고의 문제는 한 가지가 무엇인지 알기가 어렵다는 점이다. 3-3을 보자. 1234567//3-3public static String renderPageWithSetupsAndTeardowns(PageData PageData,boolean isSuite) throws Exception{ if(isTestPage(pageData)) includeSetupAndTeardownPages(pageData, isSuite); return pageData.getHtml()} 목록 3-3은 한가지만 하는가? 세가지를 한다고 주장할 수도 있다. 페이지가 테스트페이지인지 판단한다. 그렇다면 설정 페이지와 해제 페이지를 넣는다. 페이지를 HTML로 렌더링한다. 위에서 언급하는 세 단계는 지정된 함수 이름 아래에서 추상화 수준이 하나다. 함수는 간단한 TO문단으로 기술할 수 있다. ** TO : LOGO 언어에서 사용하는 함수 선언 방식으로, 파이썬이나 루비의 def와 같다. 123TO RenderPageWithSetupAndTeardowns, 페이지가 테스트 페이지인지 확인한 후 테스트 페이지라면 설정 페이지와 해제 페이지를 넣는다.테스트 페이지든 아니든 페이지를 HTML로 렌더링한다. 정리하면, 지정된 함수 이름 아래에서 추상화 수준이 하나인 단계만 수행한다면 그 함수는 한가지 작업만 한다고 볼 수 있다. 또 다른 방법은, 단순히 다른 표현이 아니라 의미있는 이름으로 다른 함수를 추출할 수 있다면 그 함수는 여러작업을 하는 셈이다. 함수 당 추상화 수준은 하나로!⭐함수가 확실히 한 가지 작업만 하려면 함수 내 모든 문장의 추상화 수준이 동일해야한다. 함수 호출 getHtml() 은 추상화 수준이 높다. 그리고 모듈을 사용한 변수 선언(?) String pagePathName = PathParser.render(pagepath);는 추상화 수준이 중간이다. 그리고.append(“\\n”)와 같은 코드는 추상화 수준이 낮다. 한 함수내의 추상화 수준을 섞으면. 코드를 읽는 사람이 헷갈린다. 내려가기 규칙코드는 위에서 아래로 이야기처럼 읽혀야 좋다. 한 함수 다음에는 추상화 수준이 한 단계 낮은 함수가 온다. 즉, 위에서 아래로 프로그램을 읽으면서 추상화 수준이 한 단계씩 낮아지는 것이다. 서술적인 이름을 사용하라!함수 이름은 함수 내용이 짐작 가능할 수 있어야 한다. 함수 이름이 길어도 괜찮다. 길고 서술적인 이름이 짧고 어려운 이름보다 좋다. 길고 서술적인 이름이 길고 서술적인 주석보다 좋다. 이름을 정하느라 시간을 들여도 괜찮다. 함수 인수함수에서 이상적인 인수 개수는 0개이다. 4개이상은 사용하지 않는게 좋다. 인수가 1개인 경우 인수에 질문을 던지는 경우 Boolean fileExists(“MyFile”) 인수를 뭔가로 변환해 결과를 반환하는 경우 InputStream fileOpen(“MyFile”) 이벤트 발생 ⇒ 출력 인수 없이 시스템 상태를 바꾼다. 플래그 인수 플래그 인수는 추하다. 함수로 부울 값을 넘기는 관례는 정말로 끔찍하다. 함수가 한꺼번에 여러 가지를 처리한다고 대놓고 공표하는 셈이니까…! 인수가 2개인 함수 2개가 적절한 경우도 있지만(예, 좌표를 찍는 함수 x축,y축) 단항 함수로 바꾸도록 애써야 한다. 인수가 3개인 함수 이해하기 어렵다. 신중히 고려하라.. 인수 객체가 2-3개 필요하다면 일부를 독자적인 클래스 변수로 선언할 가능성을 짚어보자. 12Circle makeCircle(double x, double y, double radius)Circle makeCircle(Point center, double radius) 명령과 조회를 분리해라!함수는 뭔가를 수행하거나 뭔가에 답하거나 둘 중하나만 해야한다. 아래 코드는 명령과 조회를 함께한다. 1if(set(\"username\", \"unclebob\")) 명령과 조회를 분리해 혼란을 없애야 한다. 123if(attributeExists(\"username\")){ setAttribute(\"username\", \"unclebob\");} 오류 코드보다 예외를 사용하라!1if(deletePage(page) == E_OK) 위 코드는 여러 단계로 중첩되는 코드를 야기한다. 오류 코드를 반환하면 호출자는 오류 코드를 바로 처리해야 한다. 반면 예외를 사용하면 오류 처리 코드가 원래 코드에서 분리되므로 코드가 깔끔해진다.","link":"/2020/06/14/study2-1/"},{"title":"&lt;클린 코드&gt; 좋았던 내용 기록하기(7-12장)","text":"&lt; Clean Code &gt; 도서의 내용을 공부하며 요약 정리하였습니다. 7장오류 처리를 프로그램 논리와 분리하자. 프로그램 논리와 분리하면 독립적인 추론이 가능해지며 코드 유지보수성이 높아진다. 오류 코드보다 예외를 사용해라If 처리보다 오류가 발생하면 예외를 던지는 편이 코드도 간결하고 읽기쉽다. 감싸기 기법외부 api를 사용할 때는 감싸기 기법이 최선이다. LocalPort클래스에서 ACMEPort 클래스를 감싸고 있다. 12345678910111213141516public class LocalPort{ private ACMEPort innerPort; public LocalPort(int portNumber){ innerPort = new ACMEPort(portnumber); } public void open(){ try{ innerPort.open(); }catch(DeviceResponseException e){ throw new PortDeviceFailure(e); } ... }} 외부 api를 감싸면 외부 라이브러리와 프로그램 사이에서 의존성이 크게 줄어든다. 나중에 다른 라이브러리로 갈아타도 비용이 적다. 또한 감싸기 클래스에서 외부 api를 호출하는 대신 테스트 코드를 넣어주는 방법으로 프로그램을 테스트하기 쉬어진다. 9장 단위 테스트TDD법칙 3가지 실패하는 단위테스트를 작성할 때까지 실제 코드를 작성하지 않는다. 컴파일은 실패하지 않으면서 실행이 실패하는 정도로만 단위 테스트를 작성한다. 현재 실패하는 테스트를 통과할 정도로만 실제 코드를 작성한다. 깨끗한 테스트코드 유지하기테스트 코드는 실제코드 못지 않게 중요하다. 실제 코드 못지않게 깨끗하게 짜야한다. 코드에 유연성, 유지보수성, 재사용성을 제공하는 버팀목이 바로 단위테스트이다. 왜냐하면 테스트 케이스가 있으면 변경에 부담이 없기 때문이다. 깨끗한 테스트 코드깨끗한 테스트 코드를 만들때에는 가독성이 제일 중요하다. 중복되는 코드를 삭제하고 의도를 흐리지 않아야 한다. 테스트는 BUILD-OPERATE-CHECK 패턴으로 나눠진다. 첫 부분은 테스트 자료를 만든다. 두 번째는 테스트 자료를 조작하며, 세번 째 부분은 조작한 결과가 올바른지 확인한다. 이중 표준테스트 코드는 단순하고 간결하고 표현력이 풍부해야 하지만 실제 코드만큼 효율적일 필요는 없다. 테스트 당 assert 하나한 함수에서 assert문을 적용하려 하다보면, 중복되는 코드가 많아진다. 이때는 TEMPLATE METHOD 패턴을 사용하면 중복을 제거할 수 있다. ** template method : 변하지 않는 기능은 슈퍼 클래스에 넣어두고 자주 변경되며 확장할 기능은 서브 클래스에 만들도록 한다. 테스트 당 assert 함수 한개가 어렵다면, 테스트 함수마다 한 개념만 테스트하라는 규칙을 지키는 방법도 있겠다. FIRST 빠르게, 독립적으로, 반복가능하게, 자가검증하는(return bool), 적시에(실제 코드 이전에 작성) 10장 클래스클래스 체계Static public 상수, Private 변수, 비공개 인스턴스 변수, 공개 함수, 바로 위 공개 함수가 호출하는 비공개 함수 클래스는 작아야 한다!단일 책임 원칙(srp)단일 책임 원칙은 클래스나 모듈을 변경할 이유가 하나뿐이어야 한다는 원칙이다. 큰 클래스 몇개가 아니라 작은 클래스 여럿으로 이뤄진 시스템이 더 바람직하다. 작은 클래스는 각자 맡은 책임이 하나이며 다른 작은 클래스와 협력해 싯스템에 필요한 동작을 수행한다. 1234567public class SuperDashboard extends JFrame impletements MetaDataUser{ public Component getLastFocusedComponent(); public void setLastFocused(); public int getMajorVersionNumber(); public int getMinorVersionNumber(); public int getBuildNumber();} 응집도클래스는 인스턴스 변수 수가 작아야 한다. 각 클래스 메서드는 클래스 인스턴스 변수를 하나 이상 사용해야 한다. 메서드가 변수를 더 많이 사용할수록 메서드와 클래스는 응집도가 높다. 응집도가 높다는 말은 메서드와 변수가 서로 의존하며 논리적인 단위로 묶여있음을 의미한다. 클래스가 응집력을 잃는다면 쪼개라!메서드가 많아지고 인스턴스 변수가 많아지면, 응집도를 고려하여 변수와 메서드를 적절히 분리해 새로운 두세개 클래스로 쪼개야한다. 다시 말해, 응집도를 유지하면 작은 클래스 여럿이 나오게 된다. 변경하기 쉬운 클래스깨끗한 시스템은 클래스를 체계적으로 정리해 변경에 수반하는 위험을 낮춘다. 변경으로부터 격리외부 api를 사용해 코드를 작성하는데, 5분마다 api 값이 달라진다면 테스트 코드를 짜기란 쉽지 않다. 이럴 때에는, 함수 내에서 api를 직접 호출하는 대신 클래스로 따로 뺀 후 mocking을 사용해 테스트한다. 이처럼 결합도를 낮추면 유연성과 재사용성도 더욱 높아지며 DIP를 따르는 클래스가 나온다. 12장 창발성단순한 설계 규칙은 설계 품질을 높여주며, 다음 규칙을 따르면 설계가 단순하다고 말한다. 모든 테스트를 실행한다. 중복을 없앤다. 프로그래머 의도를 표현한다. 클래스 수와 메서드 수를 최소로 줄인다.","link":"/2020/07/04/study2-2/"},{"title":"IPC - 프로세스간 통신","text":"프로세스는 독립적으로 실행한다. 다른 프로세스의 데이터에 접근하려 해도 memory protection에서 접근하지 못하게 한다. 이처럼 독립적인 프로세스가 서로 통신하기 위한 방법이 무엇인지 살펴보자. 통신 방식프로세스가 서로 통신하는 방식은 크게 2가지이다. Shared Memory Message Passing Shared Memory두 개 이상의 프로세스 들이 주소 공간의 일부를 공유하여 읽기 쓰기를 수행한다. 공유 메모리가 설정되면 커널의 관여없이 직접 읽고 쓸 수 있기 때문에 속도가 빠르다. 다른 프로세스의 변경 사항을 알기 위해 동기화가 필요하며, 한 번에 한 프로세스가 접근하는 접근 제어가 필요하다. 접근 제어 방식으로는 semaphore 등이 있다. Message Passing한 프로세스에서 협력하는 다른 프로세스로 커널을 통해 메시지를 주고(send) 받는(receive) 방식이다. Message Passing 방식으로는 PIPE, Message Queue, Socket, Signal 등이 있다. 파이프(PIPE) 파이프는 통신을 위한 메모리 공간(버퍼)를 생성하고 버퍼를 통해 데이터를 전달하는데, 한 방향으로만 전달 가능하다. 다시 말해, 한 쪽 프로세스(A)는 보내기만 다른 한 쪽(B)은 받기만 가능한 것이다. 데이터를 서로 주고 받기 위해서는 A → B방향 파이프, B → A 방향 파이프 2개 연결해야 한다. 또한 여러 개 프로세스가 접근하지 못한다. 그렇기 때문에 프로세스가 많을수록 파이프 수도 증가하며 메모리 공간을 많이 차지하게 된다. 파이프는 Anonymous PIPE와 Named PIPE로 나뉜다. Anonymous PIPE 관련없는 외부 프로세스에서는 사용하지 못하는, 부모 프로세스와 자식 프로세스 간에 사용하는 PIPE Named PIPE 외부 프로세스에 간 통신에서 사용하는 PIPE 메세지 큐(Message Queue) 고정된 크기의 메시지를 연결 리스트를 이용하여 통신하는 방법이다. Message Queue에는 여러 프로세스가 접근 가능하며 동기화가 필요하다. 소켓(Socket) 상대 프로세스의 소켓으로 통신하며, 포트 번호를 통해 소켓을 찾아간다. 다른 IPC는 로컬에서만 사용 가능한 반면, 소켓은 로컬과 리모트 서버 모두 통신 가능하다. 시그널(Signal) 특정 이벤트가 발생했을 때 프로세스에게 시그널을 전달할 수 있다. 예를 들어, 자식 프로세스가 종료되었거나 오류가 발생했을 때, 인터럽트가 발생했을 때 그 정보를 알리는 시그널을 전달한다. 시그널은 여러 종류가 있으며 시그널 별로 번호가 붙어있다. 시그널 핸들러를 통해 특정 시그널에 대한 함수를 실행할 수 있다.","link":"/2020/08/23/study3/"},{"title":"메모리 관리","text":"메모리 관리에 대해 알아보자. 메모리 관리?프로세스를 실행할 때는 프로그램이 메모리에 적재 되어야 한다. 운영체제는 프로세스를 다중으로 운영하므로 메모리를 어떻게 사용하고, 배치할지, 메모리가 부족할 때는 어떻게 해야 하는지 등의 관리가 필요해진다. 주소 지정 시점메모리 주소는 논리적 주소와 물리적 주소로 나뉜다. 논리적 주소는 프로세스 실행 시 생성되는 독자적인 가상의 주소 공간이며 물리적 주소는 실제 메모리 상의 위치를 의미한다. CPU가 논리적 주소를 통해 물리적 주소로 접근할 수 있어야 하는데, 논리적 주소를 물리적 주소로 매핑하는 것을 바인딩이라고 한다. 주소가 지정 되는 시점, 바인딩 되는 시점은 3가지로 나뉜다. 컴파일 시점 바인딩 프로그램이 메모리의 어느 위치에 적재될 지 컴파일 시점에 알 수 있다면 메모리 물리 주소를 지정할 수 있다. 로드 시점 바인딩 프로그램의 실행이 시작될 때 물리 주소가 결정되는 방식으로 프로그램이 종료될 때까지 물리적 메모리 상의 위치가 고정된다. 실행 시점 바인딩 프로그램 실행 중에 메모리 주소가 변경되는 방식이다. 하드웨어가 주소를 변경 해주는 하드웨어의 지원이 필요하다. ⇒ MMU ** MMU 논리 주소를 물리 주소로 변환하는 하드웨어이다. CPU에서 특정 논리 주소 위치에 저장된 데이터를 요청할 때 MMU가 자동으로 물리적 주소로 변환하여 해당 위치에 접근하는 것을 지원한다. 프로그램의 주소 공간이 메모리의 연속적인 공간에 적재되어 있다고 가정한다. 메모리 할당법 연속 할당 메모리를 다수의 메모리로 분할하고 각 프로세스는 메모리의 연속적인 공간에 적재된다. 메모리 분할 방식으로는 고정 분할 방식과 가변 분할 방식이 있다. 고정 분할 방식 고정된 크기의 분할로 미리 나눔 가변 분할 방식 최초 적합 : 첫번째로 찾은 공간에 할당하는 방법, 시간 최적화 최적 적합 : 모든 공간 중에 수용 가능한 가장 작은 곳을 선택, 공간을 최적화 최악 적합 : 모든 공간 중에 수용 가능한 가장 큰 곳을 선택, 공간 낭비 발생 프로세스 실행 시, 프로세스에 필요한 메모리보다 같거나 큰 메모리 공간을 찾아 프로세스가 사용할 수 있도록 배정한다. 연속 할당에는 단편화라는 문제가 발생하는데, 단편화란 프로세스의 반복적인 실행과 종료로 인해 복수의 사용하지 않는 메모리 공간, 즉 구멍이 메모리 상에 발생하는 것을 의미한다. 여유 메모리 공간이 하나의 할당 요청을 만족시키기에는 충분하지만 구멍이 연속적이지 않아 할당할 수 없는 문제를 외부 단편화라고 한다. 그리고 할당된 메모리가 요청한 메모리 크기보다 커 남는 공간을 내부 단편화라고 한다. 이 문제를 해결하기 위해 남은 구멍들을 합치는 압축 기능을 사용하여 연속적인 메모리 공간을 만들고 프로세스에 할당한다. 불연속 할당 연속적인 메모리 공간이 아닌 불연속적인 메모리 공간을 사용함으로써 압축에 드는 시간을 없앤다. 불연속 할당 기법으로는 페이징 기법과 세그먼트 기법이 있다. 페이징 기법 프로세스의 주소 공간을 동일한 크기의 페이지 단위로 나누어 불연속적인 메모리 공간에 할당하는 방식이다. 물리적 메모리를 프로세스의 페이지 크기와 동일한 크기로 나누고 메모리에 페이지를 할당한다. 프로세스의 몇번째 페이지가 물리적 메모리에 몇번째 위치에 들어있다는 정보가 필요한데, 이 정보를 페이지 테이블이 갖고 있다. 페이지 테이블을 사용하여 논리주소를 물리주소로 매핑한다. 각 프로세스의 메모리 영역 전체를 물리적 공간에 적재할 필요없으며 일부는 backing store에 일시적으로 보관하는 것이 가능하다. 페이지 크기에 맞춰 메모리를 나누기 때문에 외부 단편화 문제가 발생하지 않지만 내부 단편화는 발생한다. 세그먼트 기법 페이징 기법에서는 가상 메모리를 같은 크기의 페이지로 분리했다면, 세그먼트 기법은 서로 다른 크기의 논리적 단위인 세그먼트로 분할하고 메모리를 할당하며 주소를 반환한다. 세그먼트들은 크기가 각각 다르며 연속적인 메모리 공간에 저장되어 있다. 세그먼트 가상의 주소는 세그먼트 번호와 블록 내 세그먼트의 길이를 나타낸다. 페이징 기법에는 페이징 테이블이 있는 것처럼 세그먼트 기법에는 세그먼트 테이블이 있어 실제 주소를 매핑하는 저장 정보를 포함하고 있다. 세그먼트 테이블에는 항목별로 Base(세그먼트 시작 주소)와 Limit(세그먼트 길이)의 정보를 가지고 있다.","link":"/2020/08/17/study4/"},{"title":"python asnyc 함수","text":"python async 함수를 알아보자.","link":"/2021/05/31/study7/"},{"title":"헤더와 바디","text":"&lt;리얼월드 HTTP&gt; 도서의 내용을 요약 정리하고 관련 내용을 추가하였습니다. HTTPHTTP는 웹 브라우저와 웹 서버가 통신하는 절차와 형식을 규정한 것이다. 더 나아가 번역 api나, 데이터 저장 api등 다양한 서비스의 인터페이스로 사용되면서 인터넷의 기초가 됐다. 다양한 프로토콜이 RFC로 정의됐다. RFC는 통신의 상호접속성 유지를 위한 공통화된 사양서 모음을 의미한다. HTTP 헤더헤더는 파일명:값 형식으로 본문 앞에 부가된다. 헤더 이름은 대, 소문자를 구별하지 않는다. http에도 이 전자메일과 같은 똑같은 형식의 헤더가 도입됐다. 1. 클라이언트가 서버에 보내는 헤더• User-Agent : 클라이언트가 자신의 애플리케이션 정보를 나타내는 곳. 스마트폰, pc의 브라우저 종류나 버전을 구분할 수 있다. • Referer : 서버에서 참고하는 추가 정보. 클라이언트가 요청을 보낼 때 보고 있던 페이지의 url을 보낸다. 페이지의 참조원을 서버가 참조하하는데 이용한다. • Authorization: 특별한 클라이언트에만 통신을 허가할 때, 인증 정보를 서버에 전달한다. aws나 git api등에서는 웹 서비스 자체 표기를 요구하기도 한다(?) 2. 서버에서 클라이언트로 보낼 때 부여하는 헤더• Contet-Type : 파일 종류를 지정. mime 타입이라는 식별자를 기술한다. • Content-Length : 바디 크기. 만약 압축이 이루어지는 경우 압축 후의 크기가 들어간다. • Content-Encoding : 압축이 이루어진 경우, 압축 형식을 설명한다. • Date : 문서 날짜 • 또한 이 밖에 X-로 시작되는 헤더는 각 애플리케이션이 자유롭게 사용해도 된다. 헤더의 전송curl 커맨드로 실제 헤더를 보낼 수 있다. 헤더는 —header=헤더행 or -H옵션을 사용한다. 1curl —http1.0 -H “X-test: hello” http//localhost:8000 MIME 타입파일의 종류를 구분하는 문자열. 인터넷 옵션에 따라 mime타입이 아닌 내용을 보고 파일 형식을 추측하려 하는데 이런 동작을 콘텐츠 스니핑이라고 한다. 그런데 만약 text파일에 html, js가 써있으면 파일을 실행해버리는 문제가 생길 수도 있다. 이런 문제를 해결하기 위해서 다음과 같이 옵션을 추가한다. 1X-content-type-option: nosniff 메서드http/1.0으로 통신할 때 전송되는 get부분은 메서드로 불린다. 다음 3가지가 흔히 쓰이는 메서드이다. • get : 서버에 헤더와 콘텐츠 요청 • head: 서버에 헤더만 요청 • post : 새로운 문서 투고 html의 폼에서는 get과 post만 지원된다. 스테이터스 코드3자리 숫자를 보고 서버가 어떻게 응답했는지 파악한다. • 100번대 : 처리가 계속됨을 나타낸다. • 200번대 : 성공했을 때의 응답. • 300번대 : 서버에서 클라이언트로의 명령. 정상 처리의 범주이며 리디렉트나 캐시 이용을 지시한다. • 400번대 : 클라이언트가 보낸 요청에 오류가 있다. • 500번대 : 서버 내부에서 오류가 발생했다. 리디렉트서버는 브라우저에 대해 리디렉트하도록 지시할 수 있다. 300이외의 경우는 location헤더를 사용해 리디렉트할 곳을 서버에서 클라이언트로 전달한다. 리디렉트에는 다섯 가지 종류가 있다. • 301 moved permanently : 도메인 전송, 웹사이트 이전, https • 302 found : 일시적 관리, 모바일 기반 전송 • 303 see other : 로그인 후 페이지 전환 • 307 temporary redirect: .. 영구적인지 일시적인지는 이동하는 이전 페이지가 이후에도 존재하는지로 분류한다. http → https 로의 전환은 http를 볼 일이 없으므로 영구적이다. 클라이언트는 Location헤더 값을 보고 다시 요청한다. UrlUri에는 urn이라는 이름 부여 규칙도 포함된다. url은 장소로 문서 등의 리소스를 특정하는 수단을 제공한다. 다시 말해, url은 주소이며, urn은 이름 그 자체이다. urn 예시는 다음과 같다. 웹 시스템을 다루는 한 urn이 등장할 일은 없으므로 uri와 url은 거의 같다. url의 구조스키마://호스트명/경로 • 스키마 : https • 호스트명: www.oreilly.co.jp • 경로: index.html Url 사양에 포함되는 모든 요소가 들어간다면, 다음과 같은 형식이 된다. 1스키마://사용자:패스워드@호스트명:포트/경로#프래그먼트?쿼리 사용자 이름과 패스워드는 FTP등에서 사용되곤 하는데, 여기서 기술하는 방식은 basic인증으로, 패스워드가 그대로 노출되어 웹 시스템에서 사용되는 일은 없다. 프래그먼트는 html에서는 페이지 내 링크의 앵커를 지정하는 데 쓰인다. 쿼리는 검색 용어를 지정하거나 표시하고 싶은 웹페이지에 대해서 특정 파라미터를 부여하는 데 쓰인다. 처음에는 url의 도메인 이름을 영숫자와 하이픈만 쓸 수 있었지만, 국제화 도메인 네임을 표현하는 인코딩 규칙 퓨니코드가 정해져 다국어를 사용할 수 있게 되었다. 바디헤더 마지막 줄에 빈 줄을 넣으면 그 이후는 모두 바디가 된다. 한 번 응답할 때마다 한 파일만 반환한다. 폼이나 xmlhttprequest를 사용해 클라이언트에서 서버로 데이터를 전송하는 경우도 있다.","link":"/2020/05/22/book3-1/"},{"title":"CH5. 신경망 학습하기-2 (경사하강법)","text":"지난 챕터에서는 데이터를 예측하고 예측 값에 대한 손실함수 구하기를 살펴보았다. 지난 챕터 바로가기 : https://myphiloprogramming.tistory.com/22 다음 순서를 계속 진행해보자. 경사하강법으로 가중치 값 개선하기 우리는 손실 함수 값을 줄여나감으로써 최적의 매개변수를 찾는다. 손실 함수 값을 줄이는 방법으로는 경사하강법을 사용하는데, 적용하기 전에 그 방법을 이해해보자. 먼저, 손실 함수값을 좌표 위에 찍어서 현재 위치를 확인한다. 적기로는 좌표 위에 점을 찍는다고 했지만, 실제로 차원은 가중치 매개변수 개수 만큼 있기 때문에 그릴수도, 그래프의 모양을 확인할 수도 없다. 적당히 이해하기로는 x축은 가중치 매개변수 개수 만큼있고 y축은 손실함수 값이 된다. 그림으로 나타내보면 다음과 같다.(이 그림은 이해를 돕기 위할 뿐이며 실제로는 그림으로 나타낼 수도 없다.) 전체 그래프를 모르기 때문에 어디가 손실함수 값의 최솟값인지 짐작할 수 없다. 이런 상황에서 기울기를 이용해 최솟값을 찾으려는 것이 경사법이다. 기울어진 방향에 꼭 최솟값이 있는 것은 아니지만 그 방향으로 갔을 때 손실함수 값을 줄일 수 있다. 그래서 기울기를 단서로 나아갈 방향을 정하게 된다. 기울기는 아래 그림처럼 방향을 가진 벡터로 그려진다. 기울기화살표를 보면 한 곳을 향하고 있는데, 이 때 가리키는 위치가 가장 최솟값이 된다. 정리하면 현재 위치에서 기울기를 구한 후, 손실함수 값이 낮아지는 방향으로 이동한다. 경사하강법은 현 위치에서 기울어진 방향으로 일정 거리만큼이동한다. 그런 다음 이동한 곳에서 기울기를 한번 더 구하고 또 기울어진 방향으로 나아가기를 반복함으로써 최솟값을 찾아나간다. 경사하강법을 구현하면 다음과 같다. 12345678910111213141516171819202122232425def numerical_gradient(f, x): h = 1e-4 grad = np.zeros_like(x) for idx in range(x.size): tmp_val = x[idx] x[idx] = tmp_val + h fxh1 = f(x) x[idx] = tmp_val - h fxh2 = f(x) grad[idx] = (fxh1 - fxh2) / (2*h) x[idx] = tmp_val return graddef gradient_descent(f, init_x, lr=0.01, step_num=100): x = init_x for i in range(step_num): grad = numerical_gradient(f,x) x -= lr * grad return x gradient_descent함수의 파라미터를 살펴보면, f는 최적화하려는 함수, init_x는 초깃값, lr은 학습률, step_num은 반복 횟수를 의미한다. 그리고 numerical_gradient 함수는 기울기를 구한다. init_x = np.array([-3.0, 4.0])gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100) gradient_descent 함수 실행 결과gradient_descent함수를 사용하면 step_num만큼 반복하면서 찾은 최솟값의 위치를 리턴한다. 다시 말해, 손실함수가 최솟값이 되는 매개변수 값을 리턴한다. 위 예시에서는 초기 매개변수로 [-3.0, 4.0]을 넣었더니, [-6.11e-10, 8.14e-10] 결과가 반환됐다. 2,3,4 반복하며 최적값 찾기 gradient_descent 함수가 리턴한 값은 개선된 가중치 값이다. 이제 이 값을 가지고 다시 숫자 이미지를 맞춘다. 다시 배치 데이터를 뽑고 새로 갱신된 가중치 값으로 예측한 후, 새로운 손실함수 값을 또 최소화도록 경사하강법을 적용한다. 이렇게 이 과정을 반복하면서 가중치 최적값을 찾아나간다. 1번부터 5번까지에 대한 전체 코드는 다음과 같다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117class TwoLayerNet: def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01): #가중치 초기화 self.params = {} self.params['W1'] = weight_init_std * \\ np.random.randn(input_size, hidden_size) self.params['b1'] = np.zeros(hidden_size) self.params['W2'] = weight_init_std * \\ np.random.randn(hidden_size, output_size) self.params['b2'] = np.zeros(output_size) def predict(self, x): W1, W2 = self.params['W1'], self.params['W2'] b1, b2 = self.params['b1'], self.params['b2'] a1 = np.dot(x, W1) + b1 z1 = sigmoid(a1) a2 = np.dot(z1, W2) + b2 y = softmax(a2) return y def loss(self, x, t): y = self.predict(x) return cross_entropy_error(y, t) def accuracy(self, x, t): y = self.predict(x) y = np.argmax(y, axis=1) t = np.argmax(t, axis=1) accuracy = np.sum(y==t) / float(x.shape[0]) return accuracy def numerical_gradient(self, x, t): loss_W = lambda W: self.loss(x,t) grads = {} grads['W1'] = numerical_gradient(loss_W, self.params['W1']) grads['b1'] = numerical_gradient(loss_W, self.params['b1']) grads['W2'] = numerical_gradient(loss_W, self.params['W2']) grads['b2'] = numerical_gradient(loss_W, self.params['b2']) return grads#미니 배치(x_train, t_train), (x_test, t_test) = \\ load_mnist(normalize=True, one_hot_label=True)train_loss_list = []iters_num = 10000train_size = x_train.shape[0]batch_size = 100learning_rate = 0.1network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)for i in range(iters_num): batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[batch_mask] grad = network.numerical_gradient(x_batch, t_batch) for key in ('W1','b1','W2','b2'): network.params[key] -= learning_rate * grad[key] loss = network.loss(x_batch, t_batch) train_loss_list.append(loss)``` 6. 테스트 데이터로 성능 테스트 해보기이로써 신경망 구현이 끝났다. 이제 테스트 데이터를 적용해서 정확도를 확인해보자.테스트 코드는 다음과 같다.``` bash(x_train, t_train), (x_test, t_test) = \\ load_mnist(normalize=True, one_hot_label=True)network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)iters_num = 10000train_size = x_train.shape[0]batch_size = 100learning_rate = 0.1train_loss_list = []train_acc_list = []test_acc_list = []iters_per_epoch = max(train_size / batch_size, 1)for i in range(iters_num): batch_mask = np.random.choice(train_size, batch_size) x_batch = x_train[batch_mask] t_batch = t_train[bathc_mask] grad = network.numerical_gradient(x_bathc, t_batch) for key in ('W1','b1','W2','b2'): network.params[key] -= learning_rate * grad[key] loss = network.loss(x_batch, t_batch) train_loss_list.append(loss) if i % iter_per_epoch == 0: train_acc = network.accuracy(x_train, t_train) test_acc = network.accuracy(x_test, t_test) train_acc_list.append(train_acc) test_acc_list.append(test_acc) print(\"train acc, test acc |\" + str(train_acc) + \", \" + str(test_acc))","link":"/2020/04/11/book1-4/"},{"title":"python 비트연산과 시프트 연산 방법 및 적용 예시","text":"python 비트(bit) 연산과 시프트 연산(shift)의 사용 방법과 활용법에 대해 알아보자. 비트 연산비트 연산은 이진수로 논리 연산을 한다. 논리 연산에는 AND, OR, XOR, NAND가 있다. 하나씩 살펴보자. AND( &amp; ) 연산 아래와 같이 두 비트의 연산에서 둘 다 1인 경우에만 1을 반환한다. 123456&gt;&gt;&gt; 1 &amp; 11&gt;&gt;&gt; 1 &amp; 00&gt;&gt;&gt; 0 &amp; 00 이진수가 한자리 수가 아닌 경우 각 자리수를 보고 연산한다. 예를 들어,이진수 1001과 1101가 있으면, 첫째자리와 넷째자리 수만 둘 다 1이므로, 1을 반환하고 나머지는 0을 반환한다.그러므로 결과는 1001이된다. 십진수의 경우, 이진수로 변환 후에 계산한다. 예를 들어,9는 이진수로 1001, 13는 이진수로 1101인데, 이 둘을 비트연산하면 1001이므로 리턴값은 9가 된다. 1234&gt;&gt;&gt; 9 &amp; 139&gt;&gt;&gt; 0b1001 &amp; 0b1101 #이진수로 계산하고 싶은 경우, 0b를 앞에 붙이면 된다.9 정리하면, 두 개의 이진수를 각자리 별로 진리표에 따라 계산하는 것이다! 간단하다. 계속 살펴보자. OR( | ) 연산 OR 연산은 둘 중 하나면 1이면 1을 반환한다. 마찬가지로 9와 13을 연산해보자. 1234&gt;&gt;&gt; 9 | 1313&gt;&gt;&gt; 0b1001 | 0b110113 XOR( ^ ) 연산 XOR 연산은 비교 값이 서로 달라야 1을 반환한다. 123456&gt;&gt;&gt; 9 ^ 134&gt;&gt;&gt; 0b1001 ^ 0b11014&gt;&gt;&gt; bin(4) #4는 100이다.'0b100' 비트연산 적용 예시비트 연산으로 복수 개 값의 포함 여부를 알 수 있다.예를 들어 사용자가 요일을 선택하면 해당 요일에 알람을 보내는 기능이 있다고 해보자.이진수 계산을 위해 월요일을 1(20 ), 화요일을 2(21 ), 수요일을 4(22 ),,, 일요일을 64(26 )라고 둔다.만악 사용자가 월, 수를 골랐다면 1+4 이므로 5이다. 오늘이 월요일이라고 했을 때, 해당 유저에게 알람을 보낼지 확인하려면 AND 비트 연산을 하면된다! 123456&gt;&gt;&gt; 1 &amp; 5 #월요일은 1이다.1&gt;&gt;&gt; 2 &amp; 5 #화요일은 2이며, 유저는 화요일을 선택하지 않았다!0&gt;&gt;&gt; 4 &amp; 5 #수요일은 4이며, 유저는 수요일을 선택했다.4 권한을 지정할 때도 비트연산은 좋은 방법이다. 보통 쓰기 권한이 있으면 읽기 권한도 있는 것이므로, 읽기 권한이 1이면 쓰기 권한은 읽기 권한 값 1과 쓰기 권한 2를 더해 3으로 둘 수 있다. 이 때에는 메뉴의 권한 값과 일치하는 결과를 리턴해야 권한이 있다고 보면된다.만약 읽기 권한의 유저가 쓰기 권한용 메뉴를 접근하면 아래와 같이 1을 반환할 것이고 이는 쓰기 권한용 값이 아니므로 유저가 접근할 수 없다. 1234&gt;&gt;&gt; 1 &amp; 3 #읽기 권한 유저1&gt;&gt;&gt; 3 &amp; 3 # 쓰기 권한 유저3 만약 읽기 + 쓰기 + 알림 기능을 가진 슈퍼어드민은 1 + 2+ 4 = 7이라면, 쓰기 메뉴에 접근할 수 있다. 12&gt;&gt;&gt; 7 &amp; 3 #슈퍼어드민3 비트 시프트(shift) 연산시프트 연산은 지정한 숫자만큼 값을 이동하는 것이다. &lt;&lt; 왼쪽 shift지정한 숫자만큼 왼쪽으로 비트를 이동한다. 앞으로 n개만큼 생기는 것이기 때문에, n개만큼 자릿수가 늘어난다. 1234&gt;&gt;&gt; bin(0b1000 &lt;&lt; 1) #bin()은 10진수를 2진수로 바꿔준다.'0b10000'&gt;&gt;&gt; bin(0b1001 &lt;&lt; 2)'0b100100' &gt;&gt; 오른쪽 shift지정한 숫자만큼 오른쪽으로 비트를 이동한다. 뒤로 이동하는 것이기 때문에, n개 만큼 자릿수가 줄어든다. 1234&gt;&gt;&gt; bin(0b1000 &gt;&gt; 1)'0b100'&gt;&gt;&gt; bin(0b1001 &gt;&gt; 2)'0b10' 시프트 연산 서비스 적용 예시위에서 살펴본 요일 별 알림 서비스를 다시 가져와보자.이번에는 차례대로 월요일이 0, 화요일이 1, 수요일이 2,,, 일요일이 6이다.아래와 같이 오른쪽 shift 연산을 통해 2의 n승을 구할 수 있다. 만약 토요일(5)을 예로들면 25인 32란 값이 나온다. 121 &lt;&lt; 532 요일을 2의 n승으로 바꿀 필요없이 순서대로 숫자를 매기고 시프트 연산을 통해 계산을 할 수 있다.사용자가 월, 수, 금요일(1 + 4 + 16 = 21)을 골랐다고 했을 때 아래와 같이 연산할 수 있다. 123456&gt;&gt;&gt; 21 &amp; 1 &lt;&lt; 0 #월요일1&gt;&gt;&gt; 21 &amp; 1 &lt;&lt; 1 #화요일0&gt;&gt;&gt; 21 &amp; 1 &lt;&lt; 2 #수요일4 참고로 시프트 연산자와 비트 연산자가 같이 있으면 시프트 연산부터 계산한다!","link":"/2021/05/29/study6/"},{"title":"push 방식, poll 방식","text":"push, poll 방식을 알아보자.","link":"/2021/06/03/study8/"},{"title":"nginx.conf 파일 기본 구조와 지시어 살펴보기","text":"nginx.conf는 낯설어! nginx.conf nginx 모듈을 설치하고 나면 prefix 경로 하위에 nginx.conf 파일이 생성된다.처음 설정되는 nginx.conf 파일을 살펴보자. ✏️ prefix 경로는 nginx -V 명령어로 확인할 수 있다. nginx.conf 구조 12345678910111213141516171819202122232425262728293031user nginx;worker_processes 1;error_log /var/log/nginx/error.log notice;pid /var/run/nginx.pid;events { worker_connections 1024;}http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf;} 중괄호로 감싸고 있는 것이 하나의 블럭이다. 이 파일에서 바로 보이는 블럭은 http 블럭과 events 블럭이다.블럭 안에서 선언한 지시어는 해당 블럭에서만 사용할 수 있다. work_connections 지시어는 events 블럭에서만 의미를 가진다.또한, 블럭은 중첩될 수 있으며 자식 블럭은 부모 블럭의 지시어에 영향을 받는다. http 블럭 안에는 보통 server 블럭이 있는데 http 블럭에서 선언한 keepalive_timeout은 server 블럭에도 영향을 준다. 파일의 최상단은 메인 블럭이라고 부른다. 현재 메인 블럭에는 user, work_process , error_log, pid 지시어가 있다. nginx.conf 기본 지시어 정리 가장 처음 세팅 되는 지시어를 블럭 단위 기준으로 정리해보았다.user와 worker_process처럼 main 블럭에서만 선언해야 하는 지시어도 있고, include 여러 블럭에도 사용할 수 있는 지시어도 있다. 참고 구문의 대괄호는 필수값이 아님을 의미합니다. 구문의 콤마는 또는을 의미합니다. main 블럭 user 구문 : user username [groupname]; 설명 : 엔진엑스의 worker process를 시작시키는 사용자 계정과 그룹을 지정한다. 지정하지 않으면 master proceess 사용자인 root가 worker process 사용자가 된다. 현재 파일의 user는 nginx로, worker process의 user가 nginx인 것을 확인할 수 있다.1234# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 106 0.0 0.1 10496 3008 ? Ss 06:34 0:00 nginx: master process nginxnginx 131 0.0 0.1 10936 3476 ? S 06:55 0:00 nginx: worker process worker_process 구문 : worker_process 숫자,auto; 설명 : worker process의 수를 지정한다. 엔진엑스가 프로세스 수를 적절히 설정하도록 auto를 사용할 수도 있다. error_log 구문 : error_log file/path/error_log.log level: 설명 : 에러 로그의 파일 경로를 지정한다. level은 debug, info, notice, warn, error 등이 있다. pid 구문 : pid logs/nginx.pid 설명 : 엔진엑스 데몬의 pid 파일 경로를 지정한다. events 블럭 worker_connections 구문 : worker_connections 숫자; 설명 : worker_process가 동시에 처리할 수 있는 연결 수를 지정한다. 서버의 성능에 따라 줄이거나 늘릴 수 있다. http 블럭 include 구문 : include 파일 경로(와일드 카드 * 가능) 설명 : 지정된 파일의 내용을 해당 블럭에 포함시킨다. default_type 구문 : default_type MIME타입 설명 : 응답 헤더 값의 적절한 MIME 타입을 types 블럭에서 찾고 없으면 default_type 값을 사용한다. log_format 구문 : log_format name 설명 : 로그파일의 로그 포맷 형식을 지정한다. 로그 포맷을 여러개 생성할 수 있으며, name을 통해 어떤 포맷을 적용할지 지정할 수 있다. 현재 선언된 log_format의 name은 main이며, access_log에서 아래와 같이 선언하여 포맷을 적용하고 있다.1access_log /var/log/nginx/access.log main; #main is log_format name access_log 구문 : access_log file/path/access_log.log log_format_name 설명 : access 로그 파일의 경로와 로그 형식을 지정한다. sendfile 구문 : sendfile on,off 설명 : 활성화되면 엔진엑스는 sendfile 커널 호출을 사용해서 파일을 전송하고, 비활성화되면 스스로 파일을 전송한다. keepalive_timeout 구문 : keepalive_timeout 숫자 설명 : 서버가 유지되는 연결을 몇 초를 기다릴지 정의한다. nginx.conf 웹 서버용 세팅 웹 서버 역할을 하기 위해서 사용되는 server 블럭과 location 블럭을 살펴보자. server 블럭server 블럭은 웹 사이트 하나를 선언할 수 있다.http 블럭 하위에 정의하며, 하나의 http 블럭 안에 여러개의 server 블럭을 둘 수 있다. 12345678910111213141516171819http { server { listen 80; server_name example.org www.example.org; ... } server { listen 80; server_name example.net www.example.net; ... } server { listen 80; server_name example.com www.example.com; ... }} listen 구문 : listen [주소][:포트][추가 옵션] 설명 : 웹 사이트를 제공하는 소켓을 여는데 사용하는 IP 주소나 포트를 지정한다. 추가 옵션 : default_server : 해당 주소, 포트로 들어온 모든 요청의 기본 웹 사이트로 지정 ssl : 웹 사이트가 ssl을 통해 제공되도록 지정 http2 : HTTP/2 프로토콜을 지원하도록 활성화 proxy_protocol : 포트로 접속된 모든 네트워크 연결에 프로토콜을 활성화 server_name 구문 : server_name 호스트명1 [호스트명2] 설명 : server_name과 맞는 첫 번째 server 블럭이 선택된다. 아무로 server 블럭도 요청 호스트명과 맞지 않다면, listen 지시어의 매개변수와 맞는 server 블럭을 선택한다. listen 지시어에 default 옵션이 활성화된 블럭에 우선권이 주어진다. location 블럭server 블럭이 호스트명과 포트로 정의했다면, location 블럭은 요청 값의 path 및 파일을 기준으로 정의한다.하나의 server 블럭 안에는 여러 개의 location 블럭을 설정할 수 있다. 123456789101112131415161718192021222324server { listen 80; server_name example.org www.example.org; root /data/www; location / { index index.html index.php; } location = /doc { index index.html index.php; } location ~* \\.(gif|jpg|png)$ { expires 30d; } location ~ \\.php$ { fastcgi_pass localhost:9000; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; }} 조정부호 location 블럭 별로 path를 지정한다. path는 정규표현식 사용이 가능하다. 우선 부호를 살펴보자. = 조정부호 : path가 지정된 패턴과 정확히 일치한다. 여기서는 정규식을 사용할 수 없다. 조정부호 생략 : 지정된 패턴으로 시작해야 한다. 정규식을 사용할 수 없다. ~ 조정부호 : 정규식이 일치하고 대소문자를 구분한다. ~* 조정부호 : 정규식이 일치하고 대소문자를 구분하지 않는다. index 구문 : index file1 [file2] 설명 : 요청에 아무런 path도 없을 때, 기본으로 제공할 페이지를 정의한다. exprires 구문 : expires 숫자+날짜 기호 설명 : 파일의 캐시 유효 기간을 설정한다. 다음에는… nginx 서버 운영 시, 가장 먼저 해야 할 nginx.conf 파일 내용을 살펴보았다.다음 포스팅에서는 서버를 직접 세팅해보며 해당 지시어들이 어떻게 적용되는지 살펴보자!","link":"/2021/06/30/study9/"},{"title":"로그인 상태 유지 원리","text":"Stateless한 HTTP 통신에서 로그인 유지는 어떻게 가능할까? 로그인 후 로그인 상태를 유지하기 위해서는 쿠키와 세션이 필요한데, 그 이유는 HTTP 프로토콜의 특성 때문이다. HTTP 프로토콜은 비연결성(Connectless)을 특성으로 갖는데, 이는 클라이언트의 요청에 대한 응답 이후 클라이언트와의 관계를 끊어버리는 것을 의미한다. 서버와 클라이언트 간의 관계를 끊어버리기 때문에 서버는 클라이언트의 상태를 알 수 없으며 이전에 했던 요청 정보도 알 수 없다. 이를 무상태(Stateless) 특성이라고 말한다.그러나 로그인 상태를 유지한다는 것은 이전의 정보를 기억하는 것을 의미하므로 HTTP 통신만으로는 구현이 불가능하다. 쿠키와 세션을 사용하여 HTTP 통신 과정에서 클라이언트와 서버 간의 정보를 공유하고 기억하는 것을 가능하게 한다. 동작 원리는 다음과 같다. 로그인을 시도한 사용자가 유효한 사용자인 경우, 응답 헤더의 Set-Cookie에 유저를 식별할 수 있는 세션 아이디 값을 포함하여 응답한다. 사용자 입력한 아이디와 패스워드를 확인하여 우리 사이트의 사용자인지 확인한다. 회원이 아니라면, 권한이 없다는 401응답 등과 함께 로그인을 실패한다. 그리고 회원이라면, 헤더의 Set-Cookie 필드에 유저를 식별할 수 있는 세션 아이디 값을 포함하여 응답하고 서버에는 해당 세션 아이디 값을 저장한다. 클라이언트는\u001d 이후 요청부터 현재 브라우저에 저장된 모든 쿠키 값을 Cookie에 포함하여 요청하게 된다. 로그인에 성공하여 Set-Cookie가 포함된 헤더를 응답받은 클라이언트는 해당 값을 브라우저의 쿠키에 저장한다. 그리고 페이지 이동하여 재 요청하게 되는 경우, 브라우저의 쿠키롤 포함하여 요청한다. 이 때 브라우저 쿠키는 헤더의 Cookie 값에 포함된다. 서버는 클라이언트 요청 헤더에 포함된 세션 아이디 값을 확인하여 사용자를 식별하고 새로운 세션 아이디 값을 발급하여 응답한다. 클라이언트 요청 헤더의 쿠키 값에 세션 아이디를 서버의 세션 값과 비교하여 유효한 값인지 확인한다. 해당 세션 아이디가 유효하다면, 사용자가 요청한 값과 함께 새로운 세션 아이디를 발급하여 응답한다. 이처럼 주고 받는 세션 아이디를 통해 해당 사용자의 로그인 상태를 계속 유지할 수 있게 된다. 클라이언트 종료 시 브라우저의 세션 아이디가 제거되며, 서버에서 세션도 제거 된다.\u001c 클라이언트 종료 시, 다시 말해 브라우저 종료하거나 로그아웃 시 브라우저의 세션 아이디는 제거되며 서버에서 세션도 제거된다.","link":"/2021/05/26/study5/"},{"title":"Nginx에 SSL 인증서 설정하기","text":"테스트 환경 구성부터 Nginx에 SSL 인증서 적용까지 공인 인증기관 CA가 아닌 테스트용으로 사용할 수 있는 SSL 인증서 생성과 적용을 살펴보겠습니다.openssl을 통해 SSL 인증서를 직접 생성하는 것이기 때문에 브라우저에서의 통신은 불가능합니다.대신에 curl 명령어로 검증할 인증서를 전달하여 테스트하도록 하겠습니다. 인증서 적용하기1. 테스트 환경 구성 도커의 centos7 이미지로 테스트 환경을 구성하겠습니다.centos7 버전 이미지를 다운 받은 후, 포트를 연결하여 컨테이너를 띄웁니다. 12$ docker pull centos:7$ docker run -it --name ssl-test -p 8443:443 -p 8080:80 centos:7 /bin/bash 컨테이너에 접근하여 nginx와 openssl을 설치합니다. openssl 설치1$ yum install -y openssl.aarch64 nginx 설치 nginx 레포지토리를 추가해야 합니다. 12345678$ vi /etc/yum.repos.d/nginx.repo# 아래 내용 추가 후 저장[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/7/$basearch/gpgcheck=0enabled=1 nginx를 설치 후 실행시킵니다. 12$ yum install -y nginx$ nginx 127.0.0.1:8080으로 접근 시, nginx 화면이 나타나는 것을 확인할 수 있습니다. 2. 인증서 생성 인증서로는 개인키, 인증요청서, 인증서 순으로 생성한다. 개인키 생성아래와 같이 RSA 2048 비트의 비밀키를 생성합니다. 1$ openssl genrsa -des3 -out server.key 2048 RSA 이외에도 ECDSA 등이 있지만 보통 RSA를 사용합니다. 인증 요청서 생성인증서 요청 파일(CSR)을 아래와 같이 작성합니다. 1$ openssl req -new -key server.key -out server.csr 인증서 생성인증서를 자신의 비밀 키로 서명해서 생성합니다. 1$ openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt 인증서 생성까지 마친 후 아래 3개의 파일을 확인 할 수 있습니다. 123-rw-r--r-- 1 root root 1184 Jul 9 05:41 server.crt-rw-r--r-- 1 root root 997 Jul 9 05:40 server.csr-rw-r--r-- 1 root root 1675 Jul 9 05:41 server.key 3. nginx 설정 파일 수정 12345678910111213141516171819202122232425262728293031323334353637383940#/etc/nginx/conf.d/default.confserver { listen 80; server_name localhost; rewrite ^(.*) https://localhost$1 permanent; location / { root html; index index.html; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; }}server { listen 443 ssl; server_name localhost; #access_log /var/log/nginx/host.access.log main; ssl_certificate /tmp/server.crt; ssl_certificate_key /tmp/server.key; ssl_protocols TLSv1.2 TLSv1.3; location / { root /usr/share/nginx/html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; }} 4. 테스트 우선 80 포트로 접근 시, 301로 리다이렉트되는 것을 확인할 수 있습니다. 1234567891011121314151617$ curl -i localhostHTTP/1.1 301 Moved PermanentlyServer: nginx/1.20.1Date: Fri, 09 Jul 2021 06:44:40 GMTContent-Type: text/htmlContent-Length: 169Connection: keep-aliveLocation: https://localhost:8443/&lt;html&gt;&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;301 Moved Permanently&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.20.1&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 그리고 443 포트로 접근 시, nginx html을 확인할 수 있습니다.cacert 옵션으로 직접 인증서를 건내줍니다. 12345678910111213141516171819202122232425262728293031323334353637$ curl --cacert server.crt https://localhost:443HTTP/1.1 200 OKServer: nginx/1.20.1Date: Fri, 09 Jul 2021 06:46:23 GMTContent-Type: text/htmlContent-Length: 612Last-Modified: Tue, 25 May 2021 13:39:39 GMTConnection: keep-aliveETag: \"60acfe1b-264\"Accept-Ranges: bytes&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; }&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=\"http://nginx.org/\"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=\"http://nginx.com/\"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;","link":"/2021/07/09/study11/"},{"title":"[TIL] 전략 패턴, 옵저버 패턴","text":"2021-07-17 TIL 디자인 원칙 애플리케이션에서 달라지는 부분을 찾아내고, 달라지지 않는 부분으로부터분리시킨다. 구현이 아닌 인터페이스에 맞춰 프로그래밍한다. 상속보다는 구성을 활용한다. 사로 상호작용을 하는 객체 사이에서는 가능하면 느슨하게 결합하는 디자인을 사용해야 한다. 전략패턴 (Strategy Pattern)알고리즘 군을 정의하고 각각을 캡슐화하여 상호 교체 가능하도록 만든다. 전략 패턴을 이용하면 알고리즘을 활용하는 클라이언트와 독립적으로 알고리즘을 변경할 수 있다. 옵저버 패턴 (Observer Pattern)한 객체(Object)의 상태가 바뀌면 그 객체에 의존하는 다른 객체들(Observer)한테 알리고 자동으로 내용이 갱신된다. 객체와 옵저버의 관계는 1대 다 관계이며 느슨한 결합성을 가진다.","link":"/2021/07/17/study12/"}],"tags":[{"name":"딥러닝","slug":"딥러닝","link":"/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/"},{"name":"study","slug":"study","link":"/tags/study/"},{"name":"js","slug":"js","link":"/tags/js/"},{"name":"project","slug":"project","link":"/tags/project/"},{"name":"roadmap","slug":"roadmap","link":"/tags/roadmap/"},{"name":"book","slug":"book","link":"/tags/book/"},{"name":"http","slug":"http","link":"/tags/http/"},{"name":"pytest","slug":"pytest","link":"/tags/pytest/"},{"name":"logparser","slug":"logparser","link":"/tags/logparser/"},{"name":"역전파","slug":"역전파","link":"/tags/%EC%97%AD%EC%A0%84%ED%8C%8C/"},{"name":"모델학습","slug":"모델학습","link":"/tags/%EB%AA%A8%EB%8D%B8%ED%95%99%EC%8A%B5/"},{"name":"모델링","slug":"모델링","link":"/tags/%EB%AA%A8%EB%8D%B8%EB%A7%81/"},{"name":"순전파","slug":"순전파","link":"/tags/%EC%88%9C%EC%A0%84%ED%8C%8C/"},{"name":"django","slug":"django","link":"/tags/django/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"view","slug":"view","link":"/tags/view/"},{"name":"프론트엔드","slug":"프론트엔드","link":"/tags/%ED%94%84%EB%A1%A0%ED%8A%B8%EC%97%94%EB%93%9C/"},{"name":"백엔드","slug":"백엔드","link":"/tags/%EB%B0%B1%EC%97%94%EB%93%9C/"},{"name":"static","slug":"static","link":"/tags/static/"},{"name":"domain","slug":"domain","link":"/tags/domain/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"dns","slug":"dns","link":"/tags/dns/"},{"name":"programming","slug":"programming","link":"/tags/programming/"},{"name":"ipc","slug":"ipc","link":"/tags/ipc/"},{"name":"backend","slug":"backend","link":"/tags/backend/"},{"name":"memory","slug":"memory","link":"/tags/memory/"},{"name":"sutdy","slug":"sutdy","link":"/tags/sutdy/"},{"name":"async","slug":"async","link":"/tags/async/"},{"name":"push","slug":"push","link":"/tags/push/"},{"name":"poll","slug":"poll","link":"/tags/poll/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"server","slug":"server","link":"/tags/server/"},{"name":"login","slug":"login","link":"/tags/login/"},{"name":"session","slug":"session","link":"/tags/session/"},{"name":"cookie","slug":"cookie","link":"/tags/cookie/"},{"name":"authentication","slug":"authentication","link":"/tags/authentication/"},{"name":"conf","slug":"conf","link":"/tags/conf/"},{"name":"CGI","slug":"CGI","link":"/tags/CGI/"},{"name":"FastCGI","slug":"FastCGI","link":"/tags/FastCGI/"},{"name":"uWSGI","slug":"uWSGI","link":"/tags/uWSGI/"},{"name":"https","slug":"https","link":"/tags/https/"},{"name":"ssl","slug":"ssl","link":"/tags/ssl/"},{"name":"TIL","slug":"TIL","link":"/tags/TIL/"},{"name":"디자인패턴","slug":"디자인패턴","link":"/tags/%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4/"}],"categories":[{"name":"Study","slug":"Study","link":"/categories/Study/"},{"name":"Algorithm","slug":"Study/Algorithm","link":"/categories/Study/Algorithm/"},{"name":"Book","slug":"Book","link":"/categories/Book/"},{"name":"밑바닥부터 시작하는 딥러닝","slug":"Book/밑바닥부터-시작하는-딥러닝","link":"/categories/Book/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D/"},{"name":"인사이드 자바스크립트","slug":"Book/인사이드-자바스크립트","link":"/categories/Book/%EC%9D%B8%EC%82%AC%EC%9D%B4%EB%93%9C-%EC%9E%90%EB%B0%94%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/"},{"name":"리얼월드 HTTP","slug":"Book/리얼월드-HTTP","link":"/categories/Book/%EB%A6%AC%EC%96%BC%EC%9B%94%EB%93%9C-HTTP/"},{"name":"Project","slug":"Project","link":"/categories/Project/"},{"name":"DeepLearningFromForR","slug":"Project/DeepLearningFromForR","link":"/categories/Project/DeepLearningFromForR/"},{"name":"Roadmap2020","slug":"Project/Roadmap2020","link":"/categories/Project/Roadmap2020/"},{"name":"Deep Django","slug":"Project/Deep-Django","link":"/categories/Project/Deep-Django/"},{"name":"Network","slug":"Study/Network","link":"/categories/Study/Network/"},{"name":"ETC","slug":"Study/ETC","link":"/categories/Study/ETC/"},{"name":"운영체제","slug":"Study/운영체제","link":"/categories/Study/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/"},{"name":"TIL","slug":"Study/TIL","link":"/categories/Study/TIL/"}]}